{"meta":{"version":1,"warehouse":"3.0.2"},"models":{"Asset":[{"_id":"source/robots.txt","path":"robots.txt","modified":1,"renderable":0},{"_id":"source/images/597C072D-AA0B-46A4-99D6-D910BAF08D90.png","path":"images/597C072D-AA0B-46A4-99D6-D910BAF08D90.png","modified":1,"renderable":0},{"_id":"source/images/LuceneSearch.jpg","path":"images/LuceneSearch.jpg","modified":1,"renderable":0},{"_id":"source/images/fig1.png","path":"images/fig1.png","modified":1,"renderable":0},{"_id":"source/images/fig6.png","path":"images/fig6.png","modified":1,"renderable":0},{"_id":"source/images/vsm.jpg","path":"images/vsm.jpg","modified":1,"renderable":0},{"_id":"source/images/2017-05-30-12-17-43.jpg","path":"images/2017-05-30-12-17-43.jpg","modified":1,"renderable":0},{"_id":"source/images/fig2.png","path":"images/fig2.png","modified":1,"renderable":0},{"_id":"source/images/fig3.png","path":"images/fig3.png","modified":1,"renderable":0},{"_id":"source/images/table4.png","path":"images/table4.png","modified":1,"renderable":0},{"_id":"source/images/2017-05-30-12-16-17.jpg","path":"images/2017-05-30-12-16-17.jpg","modified":1,"renderable":0},{"_id":"source/images/fig5.png","path":"images/fig5.png","modified":1,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"source/images/2017-05-30-12-16-55.jpg","path":"images/2017-05-30-12-16-55.jpg","modified":1,"renderable":0},{"_id":"source/images/2017-05-30-11-30-06.jpg","path":"images/2017-05-30-11-30-06.jpg","modified":1,"renderable":0},{"_id":"source/images/fig4.png","path":"images/fig4.png","modified":1,"renderable":0},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.jpg","path":"images/avatar.jpg","modified":1,"renderable":1},{"_id":"source/images/2017-05-30-11-38-30.jpg","path":"images/2017-05-30-11-38-30.jpg","modified":1,"renderable":0},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"source/images/Summary-recommendation-metrics.png","path":"images/Summary-recommendation-metrics.png","modified":1,"renderable":0},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"source/images/2017-05-30-12-05-17.jpg","path":"images/2017-05-30-12-05-17.jpg","modified":1,"renderable":0},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":1,"renderable":1},{"_id":"source/images/各种分布.png","path":"images/各种分布.png","modified":1,"renderable":0},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"c380fdfe020fcb0d7bf858a9d5e696a1494752ac","modified":1585410330536},{"_id":"source/.md_configs.data","hash":"8842f205e55d4dee88e990327ceeebfc55470fe5","modified":1506595978727},{"_id":"source/.me_configs.data","hash":"0f58e9fd766e6e8f08c3cb66c098333ebfb98723","modified":1506595978728},{"_id":"source/robots.txt","hash":"ffe717b0850b95a19aba1618bd1fd4c2b17d7a06","modified":1506595978727},{"_id":"themes/next/.DS_Store","hash":"499459117599f3898be430683ec407e8352a89c1","modified":1506596177563},{"_id":"themes/next/README.en.md","hash":"4ece25ee5f64447cd522e54cb0fffd9a375f0bd4","modified":1506596177561},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1506596177563},{"_id":"themes/next/README.md","hash":"500b5606eb6a09c979d16128f8b00f4bf9bc95ac","modified":1506596177762},{"_id":"themes/next/_config copy.yml","hash":"3b166faf0b65e4b7410f7133945516e7e8aab2ed","modified":1506596177770},{"_id":"themes/next/bower.json","hash":"5abc236d9cc2512f5457ed57c1fba76669eb7399","modified":1506596177753},{"_id":"themes/next/_config.yml","hash":"b0d744c8d1724fff7ca35fd4b76cd4c3bcea0634","modified":1506596177763},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1506596177614},{"_id":"themes/next/package.json","hash":"7e87b2621104b39a30488654c2a8a0c6a563574b","modified":1506596177762},{"_id":"source/_posts/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1506595978656},{"_id":"source/_posts/.md_configs.data","hash":"8842f205e55d4dee88e990327ceeebfc55470fe5","modified":1506595978658},{"_id":"source/_posts/.me_configs.data","hash":"65f09b99475d152a6e9f0bb6fe935aa0013c06b7","modified":1506595978659},{"_id":"source/_posts/ElasticSearch.md","hash":"b027a499f83ebe5b5ef207978ca29f3c4a0d8b52","modified":1585451162353},{"_id":"source/_posts/Lucene-打分算法.md","hash":"b8cceb466f70a53992a32d6e2a2ab52b807799cd","modified":1506595978658},{"_id":"source/_posts/hexo写博客.md","hash":"4497ae513a05f63048bd2a85543fe51f23558708","modified":1506595978657},{"_id":"source/_posts/nifi-简介.md","hash":"fdef8ed38dffa3d6ceb0e6c9b63f7973bbb5348f","modified":1506595978659},{"_id":"source/_posts/nifi架构.md","hash":"6e24afe3e75aba843ce9e47d823da1c41fd5da34","modified":1506595978657},{"_id":"source/_posts/oozie调度sqoop问题.md","hash":"a24491b6fadbe23f208d4011fd83c6ee1b473dc0","modified":1517579199540},{"_id":"source/_posts/pilosa-data-mode.md","hash":"12112279539a19393aa9180ec444e7d1f7f287be","modified":1549081724706},{"_id":"source/_posts/tf-idf-计算查询语句和文档的相关性.md","hash":"c0c1e4c7e909bb5e58d77380047ad08f2201cea0","modified":1506595978658},{"_id":"source/_posts/各种分布.md","hash":"8d478b3667145cdddb14646426d9ceb9337d8d02","modified":1506680519648},{"_id":"source/_posts/推荐系统2.md","hash":"f2766d2b056a8fd8ed1888254cd45b28457cbf43","modified":1585410931633},{"_id":"source/_posts/推荐系统.md","hash":"9d0f8a67f1bc0b127d95dbd981a59810a7f977ab","modified":1506742381076},{"_id":"source/_drafts/.DS_Store","hash":"8543a441b1bb906bc064db4fb212bc7b5c175a4e","modified":1585410200103},{"_id":"source/_drafts/.md_configs.data","hash":"8842f205e55d4dee88e990327ceeebfc55470fe5","modified":1506595978724},{"_id":"source/_drafts/.me_configs.data","hash":"65f09b99475d152a6e9f0bb6fe935aa0013c06b7","modified":1506595978726},{"_id":"source/_drafts/jce问题.md","hash":"cf54e75e28346b494a8fc04c350965bf825ad25c","modified":1506595978725},{"_id":"source/_drafts/kibana-timestamp问题.md","hash":"8ec16a058d1e659c4d852ca380fb59c9300aceb7","modified":1506595978723},{"_id":"source/_drafts/maxwell同步binlog.md","hash":"a5565b24ce2bab203f0bd170997447469cc04e14","modified":1506595978725},{"_id":"source/_drafts/nifi部署.md","hash":"8bf192eaa879b742c86b749a6651e77ed341af68","modified":1506595978724},{"_id":"source/_drafts/superset简介.md","hash":"5ed6b4ed65c2d833c75b2b048baaf76b9df9fbe8","modified":1506595978723},{"_id":"source/_drafts/复杂网络简介.md","hash":"b416373fe119a98a5413e51a052e6c5a9878cd83","modified":1506595978724},{"_id":"source/about/index.md","hash":"1f3076742616878a98f75aaf5101b40f0827a391","modified":1506595978659},{"_id":"source/categories/index.md","hash":"05e0fdb8284ff0fa8ddda0aeaa6046afc28c736d","modified":1506595978728},{"_id":"source/tags/index.md","hash":"779db8b04777c191ccfa8defb6db7e9dd5bc0e43","modified":1506595978727},{"_id":"source/images/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1506680465506},{"_id":"source/images/597C072D-AA0B-46A4-99D6-D910BAF08D90.png","hash":"9b0a4f4ddb1b1916538ba3c38b6a0ffe6b09290b","modified":1506595978615},{"_id":"source/images/LuceneSearch.jpg","hash":"6ed85ac3790cded3a736c5cfb7c6d8dfc8cbbbea","modified":1506595978620},{"_id":"source/images/fig1.png","hash":"f05255be66a641f2b9443e299659bef9a58aef23","modified":1506595978619},{"_id":"source/images/fig6.png","hash":"85647a69492e793a67cf905a445363e3556e7c18","modified":1507866630729},{"_id":"source/images/vsm.jpg","hash":"6253d14f1c26c5feada9e644b4d46b1da745ecdc","modified":1506595978624},{"_id":"themes/next/languages/de.yml","hash":"306db8c865630f32c6b6260ade9d3209fbec8011","modified":1506596177757},{"_id":"themes/next/languages/default.yml","hash":"4cc6aeb1ac09a58330e494c8771773758ab354af","modified":1506596177754},{"_id":"themes/next/languages/en.yml","hash":"e7def07a709ef55684490b700a06998c67f35f39","modified":1506596177758},{"_id":"themes/next/languages/fr-FR.yml","hash":"24180322c83587a153cea110e74e96eacc3355ad","modified":1506596177760},{"_id":"themes/next/languages/id.yml","hash":"2835ea80dadf093fcf47edd957680973f1fb6b85","modified":1506596177756},{"_id":"themes/next/languages/ja.yml","hash":"1c3a05ab80a6f8be63268b66da6f19da7aa2c638","modified":1506596177758},{"_id":"themes/next/languages/ko.yml","hash":"be150543379150f78329815af427bf152c0e9431","modified":1506596177756},{"_id":"themes/next/languages/pt-BR.yml","hash":"958e49571818a34fdf4af3232a07a024050f8f4e","modified":1506596177754},{"_id":"themes/next/languages/pt.yml","hash":"36c8f60dacbe5d27d84d0e0d6974d7679f928da0","modified":1506596177757},{"_id":"themes/next/languages/ru.yml","hash":"7462c3017dae88e5f80ff308db0b95baf960c83f","modified":1506596177760},{"_id":"themes/next/languages/zh-Hans.yml","hash":"3c0c7dfd0256457ee24df9e9879226c58cb084b5","modified":1506596177755},{"_id":"themes/next/languages/zh-hk.yml","hash":"1c917997413bf566cb79e0975789f3c9c9128ccd","modified":1506596177759},{"_id":"themes/next/languages/zh-tw.yml","hash":"0b2c18aa76570364003c8d1cd429fa158ae89022","modified":1506596177761},{"_id":"themes/next/layout/_layout.swig","hash":"909d68b164227fe7601d82e2303bf574eb754172","modified":1506596177571},{"_id":"themes/next/layout/archive.swig","hash":"b5b59d70fc1563f482fa07afd435752774ad5981","modified":1506596177591},{"_id":"themes/next/layout/category.swig","hash":"6422d196ceaff4220d54b8af770e7e957f3364ad","modified":1506596177570},{"_id":"themes/next/layout/index.swig","hash":"427d0b95b854e311ae363088ab39a393bf8fdc8b","modified":1506596177578},{"_id":"themes/next/layout/page.swig","hash":"3727fab9dadb967e9c2204edca787dc72264674a","modified":1506596177577},{"_id":"themes/next/layout/post.swig","hash":"e2e512142961ddfe77eba29eaa88f4a2ee43ae18","modified":1506596177576},{"_id":"themes/next/layout/schedule.swig","hash":"234dc8c3b9e276e7811c69011efd5d560519ef19","modified":1506596177568},{"_id":"themes/next/layout/tag.swig","hash":"07cf49c49c39a14dfbe9ce8e7d7eea3d4d0a4911","modified":1506596177567},{"_id":"themes/next/scripts/merge-configs.js","hash":"13c8b3a2d9fce06c2488820d9248d190c8100e0a","modified":1506596177765},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1506596177764},{"_id":"themes/next/source/.DS_Store","hash":"a7f2d710fea6eed11c0e041d7abab2874c2e2889","modified":1506596177616},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1506596177565},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1506596177566},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1506596177564},{"_id":"source/images/2017-05-30-12-17-43.jpg","hash":"dbc3441f77d3c64302d0931ac8efab05926858b5","modified":1506595978624},{"_id":"source/images/fig2.png","hash":"c6793b7b3b346a5df99ed4689f3646e732758d6d","modified":1506595978620},{"_id":"source/images/fig3.png","hash":"88086c337ce175f8e2764a048ad6edec85ec6d26","modified":1506595978619},{"_id":"source/images/table4.png","hash":"d44f83d2cbb496c993f178243e95f34fddcaeeb1","modified":1507884683633},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1506596177752},{"_id":"source/images/2017-05-30-12-16-17.jpg","hash":"6fc13a939382da0435b8466e5166be519e41c78a","modified":1506595978624},{"_id":"source/images/fig5.png","hash":"69bf0d431ea3120ea10ffa0e16e49a10188953d6","modified":1506742483234},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1506596177569},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1506596177569},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"5864f5567ba5efeabcf6ea355013c0b603ee07f2","modified":1506596177613},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"b16fcbf0efd20c018d7545257a8533c497ea7647","modified":1506596177613},{"_id":"themes/next/layout/_macro/post.swig","hash":"640b431eccbbd27f10c6781f33db5ea9a6e064de","modified":1506596177611},{"_id":"themes/next/layout/_macro/reward.swig","hash":"37e5b7c42ec17b9b6b786c5512bcc481a21c974e","modified":1506596177612},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"911b99ba0445b2c07373128d87a4ef2eb7de341a","modified":1506596177612},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"14e785adeb0e671ba0ff9a553e6f0d8def6c670c","modified":1506596177610},{"_id":"themes/next/layout/_partials/comments.swig","hash":"1c7d3c975e499b9aa3119d6724b030b7b00fc87e","modified":1506596177585},{"_id":"themes/next/layout/_partials/footer.swig","hash":"7172c6053118b7c291a56a7860128a652ae66b83","modified":1506596177586},{"_id":"themes/next/layout/_partials/head.swig","hash":"a0eafe24d1dae30c790ae35612154b3ffbbd5cce","modified":1506596177587},{"_id":"themes/next/layout/_partials/header.swig","hash":"a1ffbb691dfad3eaf2832a11766e58a179003b8b","modified":1506596177586},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1506596177587},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1506596177579},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1506596177583},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1506596177573},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1506596177575},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"9de352a32865869e7ed6863db271c46db5853e5a","modified":1506596177574},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1506596177600},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1506596177596},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1506596177597},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1506596177596},{"_id":"themes/next/scripts/tags/button.js","hash":"62e6dbeb53d07627a048132c79630b45d9a8f2cc","modified":1506596177767},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1506596177766},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1506596177769},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1506596177768},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1506596177768},{"_id":"themes/next/scripts/tags/note.js","hash":"6752925eedbdb939d8ec4d11bdfb75199f18dd70","modified":1506596177766},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1506596177659},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1506596177684},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1506596177681},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1506596177690},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1506596177685},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1506596177682},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1506596177680},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1506596177689},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1506596177685},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1506596177690},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1506596177687},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1506596177679},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1506596177686},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1506596177689},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1506596177683},{"_id":"source/_drafts/_image/2017-05-30-12-17-43.jpg","hash":"dbc3441f77d3c64302d0931ac8efab05926858b5","modified":1506595978665},{"_id":"source/images/2017-05-30-12-16-55.jpg","hash":"933f2beedf1ad8a2bc410438b6f5fe78e5174ad8","modified":1506595978621},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1506596177572},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1506596177573},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1506596177676},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1506596177677},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1506596177676},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1506596177658},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1506596177656},{"_id":"source/_posts/.Archive/hexo写博客.md/2017-05-30 12-43-58.md","hash":"896973a9813e2df2be20b5d4b65e8ec77648ae84","modified":1506595978628},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-24 23-05-12.md","hash":"2b223012d2f1735443e75249a7594f252c5c4bb3","modified":1506595978636},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-24 23-06-12.md","hash":"c09382057e9fd98bd2d522015cea7e641721580a","modified":1506595978643},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-24 23-08-36.md","hash":"de54fb369d3081ed39ffdaacfc3a189e5e005b11","modified":1506595978646},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-24 23-12-12.md","hash":"706a6f585a4881d7806bb323720ed2e38559e8c4","modified":1506595978653},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-24 23-36-48.md","hash":"06f239e038a12df806ccd568ec65ed6e1a5285bc","modified":1506595978648},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-24 23-39-18.md","hash":"4cea2d17458edc84418ea3bd143967eef73f8c51","modified":1506595978635},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-24 23-41-28.md","hash":"ead4cb2ebe562483a94783c3b273a5626e015a7b","modified":1506595978637},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-24 23-43-01.md","hash":"3e884361a244fefa84bcc19fee77e2375a4ef7fc","modified":1506595978646},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-24 23-47-08.md","hash":"8c942c54894dc461a036a5ef2995ad5ca18e06b1","modified":1506595978632},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-24 23-50-28.md","hash":"b293acc74db03da1372e736945c8f5c5d4db7795","modified":1506595978656},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-24 23-55-28.md","hash":"4c71d9410b5f9892a655374d9a1e1d15bb600207","modified":1506595978647},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-24 23-57-04.md","hash":"e5eeccfa5f375755976f0b9d9ac425147ef8e84c","modified":1506595978633},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-25 00-04-48.md","hash":"bde82656a96719b70c2abac49806a0a9ed169928","modified":1506595978647},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-25 00-06-48.md","hash":"8c8b6583b51592b858efc3ffd07ba98af234eaaa","modified":1506595978644},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-25 00-11-48.md","hash":"b1b1165dec672e5334f1da4cc0632c91f174b72c","modified":1506595978642},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-25 00-12-58.md","hash":"6b4b4fb534225145ce7192188269ef54bcfe6605","modified":1506595978636},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-25 00-17-41.md","hash":"58b65884bed6a41647d3719b296ba8ed20269250","modified":1506595978653},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-25 00-18-58.md","hash":"310239740b3c7b9b4da999e3489772855d76b226","modified":1506595978656},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-25 00-20-08.md","hash":"7d25b77aae09a02dd4c0779e4260b8965325d007","modified":1506595978647},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-25 00-21-08.md","hash":"b5675f151aff5718bb8268a36b8717bec14cd65e","modified":1506595978654},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-25 00-22-08.md","hash":"a3f3686090eb5567dd5e82a2c3cef1439f00476d","modified":1506595978650},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-25 00-25-48.md","hash":"deb5f3b4b730b99d078ade074748cf051eff3bb4","modified":1506595978655},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-25 00-36-28.md","hash":"c1816182f4bc13266f12356ebcf36b9a193cc33d","modified":1506595978630},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-25 00-37-38.md","hash":"b403262b7040a4ab49d2602ffce3b374c85c41c1","modified":1506595978641},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-25 00-39-17.md","hash":"ee6bc41f9b071c94efe9743b896e45d5d45899f0","modified":1506595978651},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-25 00-40-18.md","hash":"63dabd9181ea9218fb59aacddfbb0a1be5497ab3","modified":1506595978655},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-25 00-41-28.md","hash":"ad8edcecb056fc1edd710389fe25d5da75738eb2","modified":1506595978649},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-25 00-42-32.md","hash":"23d2b9de6da0236ca0ce5c1cc33ef252186f640c","modified":1506595978649},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 20-18-30.md","hash":"2da14a74eb5756114401878b119e51acb8254273","modified":1506595978650},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 20-33-50.md","hash":"266ab58a34f2b86fe8aca244b4c15e29c8d8a18f","modified":1506595978635},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 20-35-10.md","hash":"b626f5a73aef07eac12077193199c2838d076b4c","modified":1506595978637},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 20-48-50.md","hash":"6eab1de9e874e230a9e24bbc03224cfe349ca5a6","modified":1506595978642},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 20-56-30.md","hash":"3fab5ce8dc57ca06da8320cd52877c8e61607e44","modified":1506595978636},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 20-57-30.md","hash":"c799dfd56420afe35f4772f0c03414e31e84f29b","modified":1506595978642},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 21-00-02.md","hash":"6ab6dad8a9093554fc5e73294e741fa11bacec24","modified":1506595978635},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 21-01-40.md","hash":"9b7219721b189523e81c997713954ee7a0b31cc3","modified":1506595978647},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 22-22-40.md","hash":"cfa35aba2da1ce1e4498a804b74b7a6aad15ddb5","modified":1506595978640},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 22-24-47.md","hash":"d0636fafb08ef12cd0761442008433376a2f2555","modified":1506595978644},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 22-29-36.md","hash":"4143a3656a2362c080c2ccc32e07f976d20be4b5","modified":1506595978637},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 22-32-20.md","hash":"196ef453dda1c50170f58c298bae67e579a2cb4d","modified":1506595978654},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 22-33-20.md","hash":"6489f1171042f59d051fbbcf94b9ff3d8ec4eb50","modified":1506595978649},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 22-34-50.md","hash":"615b742797af9fc3607d2d9af36dcf5f12900e8d","modified":1506595978654},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 22-36-10.md","hash":"757b9f243c5a5c39aeb530772d043e93954c61b4","modified":1506595978652},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 22-37-50.md","hash":"895e9603d697d40d81d7427c6d3ba60c423c2c6d","modified":1506595978648},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 22-40-20.md","hash":"804af5a95a1d47f7a6ca0bdb28e7197053fb557a","modified":1506595978636},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 22-42-29.md","hash":"b664b5f82129dacc68d70d3860da7043fb5f01ac","modified":1506595978645},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 22-44-10.md","hash":"f539cfe5608b3e8be418a5bf62ea2ec092d06eaf","modified":1506595978634},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 22-45-20.md","hash":"14cac347d0b6f5c4c12c0a3cdfb6925453aad16c","modified":1506595978642},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 22-47-50.md","hash":"16dae24dd3b41669759d97025e43ae3a603b4e2d","modified":1506595978643},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 22-49-50.md","hash":"7175776b70415492a245292a76441ad5748ee56a","modified":1506595978645},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-01-10.md","hash":"75edf38ef8f91b0cf1d4c02d4c6f78d81095e99a","modified":1506595978634},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-02-10.md","hash":"afa7b325a2d5254d3e2e34fc7743d45e9f038f67","modified":1506595978640},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-04-50.md","hash":"566085492446ecb3adef3b0db9960d6e522a36c0","modified":1506595978638},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-06-40.md","hash":"3752ad0cf45ae0f4beb5844061763719edf21256","modified":1506595978641},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-08-00.md","hash":"1bf99c3bf0b9ae680e9765e56012b5c5ccc2dc5f","modified":1506595978644},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-09-14.md","hash":"e0569d348944b23a517e0b96e6c5b262fa8fe5f6","modified":1506595978652},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-10-30.md","hash":"08ff6def91e6aa98b6d11ec5604b771a0ff2db1d","modified":1506595978652},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-13-00.md","hash":"fee94aa43db89030c494c6b7bce58cd8cd89777d","modified":1506595978646},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-14-40.md","hash":"ae496aa26bdf7d27fef3e51cf511d73e15acaa16","modified":1506595978653},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-18-20.md","hash":"d32e8d6aa07f9a33d6a997a115f34f58870de75c","modified":1506595978630},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-19-40.md","hash":"cb4e2ee924200678ffbee29fb063c8cc5d9953fe","modified":1506595978643},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-21-50.md","hash":"ed3b6f2728e9933368bec11bcf4e981aae01af00","modified":1506595978632},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-24-20.md","hash":"2dec67559ba226e788f94f83645c9badd053de57","modified":1506595978640},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-27-10.md","hash":"d886e6fd4ddf33c2380770413b97d465c8bbe95c","modified":1506595978631},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-28-16.md","hash":"2dbb27e88c9c5443d2ec8d5c3ac56b10297f9e17","modified":1506595978643},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-33-20.md","hash":"bfc6feae0ee2bd443e0fb9bdd908ac6363fce1de","modified":1506595978650},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-34-20.md","hash":"0de395cfe96ed9300023641723a73d6a83c60408","modified":1506595978652},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-35-30.md","hash":"9ecf1fb1e3e29490cc489cbeee2d58bda2e86db9","modified":1506595978646},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-37-30.md","hash":"8c396beee2b3e45a8d424572a80f6f848a52604c","modified":1506595978645},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-38-50.md","hash":"89ab36ff214d67d3c8c79ea33376e004727b781e","modified":1506595978634},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-40-40.md","hash":"e090cb4d672ccf2b3bc0f8628bf343e85f9ec23e","modified":1506595978633},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-41-44.md","hash":"c03230dea903f1353d244905c41100daf6861bcf","modified":1506595978641},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-42-50.md","hash":"97c8cd9772f86923a2a8486486eaf698d271f863","modified":1506595978629},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-44-36.md","hash":"8173e2732ae3980ffdd79234851b30385ad4e0df","modified":1506595978651},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-45-56.md","hash":"143b4058e5716f8e85fa6a0fa2b244616fbae524","modified":1506595978648},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-47-30.md","hash":"f375d4194c07160ecdd65c105b96c17dae8eabf3","modified":1506595978639},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-26 23-56-49.md","hash":"86391164e1b7bd483b85db74b9ebc01776cb6848","modified":1506595978631},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-27 00-10-49.md","hash":"9463540df6bf9c7739666394a1e21ff3a23d062f","modified":1506595978651},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-27 00-18-49.md","hash":"729b81086d951651aabe199d1f6d9738b442a270","modified":1506595978630},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-27 00-20-29.md","hash":"d6029111fd81b2d04a689b15dae7862dfb098d78","modified":1506595978639},{"_id":"source/_posts/.Archive/nifi-简介.md/2017-05-27 00-22-29.md","hash":"360a6aaff2f23f3ec1948547879529ab4090f142","modified":1506595978639},{"_id":"source/_posts/.Archive/nifi架构.md/2017-06-06 23-45-53.md","hash":"9bd1e27fc421a05544b7c5bc026821fd72138999","modified":1506595978627},{"_id":"source/_posts/.Archive/nifi架构.md/2017-06-06 23-46-57.md","hash":"6dfcc047edd195b9b7cfbf2741303fbec043d9b2","modified":1506595978627},{"_id":"source/_posts/.Archive/nifi架构.md/2017-06-06 23-48-27.md","hash":"b4ea69ae81278f25861c054d6178a754fb3641b6","modified":1506595978627},{"_id":"source/_posts/.Archive/nifi架构.md/2017-06-06 23-54-55.md","hash":"b740aa69d735e764b8aad8d871a48454674f5505","modified":1506595978626},{"_id":"source/_posts/.Archive/各种分布.md/2017-09-06 14-16-20.md","hash":"d8f1452d8ba917289ba8c89c16a1861b6701d7fd","modified":1506595978626},{"_id":"source/_drafts/.Archive/hexo解决ci和本地渲染不一致.md/2017-05-27 17-06-32.md","hash":"82105e91a3ad91800b52e6a773f2785bf139c156","modified":1506595978666},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 00-31-25.md","hash":"69761d244379780e0602d836a564c6ad4e17ea35","modified":1506595978716},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 00-45-52.md","hash":"2e35f59d2294f2140c9f18bc15bb534b8448897e","modified":1506595978708},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 00-51-32.md","hash":"b681552d7a1c1e7759e5146c91fa6a93ede861ae","modified":1506595978693},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 00-54-59.md","hash":"830fb55899201668f5d39c4c77a711472bc933a0","modified":1506595978700},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 00-56-42.md","hash":"ab263a299691e94c7280e4c14f0803d09cd200f0","modified":1506595978689},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 00-57-42.md","hash":"661615877a30cf13a468185706e8437a39699b2d","modified":1506595978694},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 00-58-42.md","hash":"2622a4ff9c0dc6ac772d6a2deb8d1b72412660e5","modified":1506595978721},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 01-08-52.md","hash":"9eb50cb1f2a695a1d7de0d60c19dc00517665ea2","modified":1506595978687},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 01-13-52.md","hash":"1b9b2f9af06ce1ae13db09146f94efc253bf8280","modified":1506595978688},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 01-25-32.md","hash":"de3848d0748dfa7c811d3b9831a87cd2d8a679ee","modified":1506595978707},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 01-30-32.md","hash":"db86e9f3a636d3516864557e649208706f74f64a","modified":1506595978695},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 01-31-32.md","hash":"0b9804e9ebfa55633eb68f98da56ac62bcf6352c","modified":1506595978689},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 01-35-12.md","hash":"9a3ef54dc4ab217466eff93746b82d6ff7d440d8","modified":1506595978693},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 01-40-12.md","hash":"3dc4c9e9702584f73acdaca76736ae2356c655cb","modified":1506595978703},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 01-59-23.md","hash":"f183535ca87dc619f40cf3e1a05df6bec19d3b9c","modified":1506595978707},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 02-31-13.md","hash":"8e6377671170b55efc2be568a5297c2d2b48a6a4","modified":1506595978702},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 02-32-23.md","hash":"dabb05637568d07ff3d04b3eb890353c057933f5","modified":1506595978713},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 02-38-33.md","hash":"b95a7dd26279e2ec20a2c5a6db0c5bd8843afb2e","modified":1506595978687},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 02-45-13.md","hash":"4553387234138aa4966710fceeb2258979c5fb0a","modified":1506595978701},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 03-00-48.md","hash":"050723ba9a4aec8f30aff1273c6030c4b42f486f","modified":1506595978693},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 03-01-48.md","hash":"d669bee00fddb7b3ede7d70fbb23c3dddf113216","modified":1506595978698},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 03-02-48.md","hash":"6d1b1d4a8c2a3c63fbd40d10e28390ef8792e985","modified":1506595978691},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 03-03-48.md","hash":"99f07978c4605cdffe52a39e3a9fe0786be4994b","modified":1506595978699},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 03-04-48.md","hash":"779b3c96a4410d876b9c856c38f5af467e7363ee","modified":1506595978686},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 03-05-51.md","hash":"4ccc22ac035e046c3b4ba8654324222aac774904","modified":1506595978720},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 03-21-38.md","hash":"e4c9255e1e7bd721bb5f7f46b96e32e698f692a5","modified":1506595978699},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 03-23-48.md","hash":"e5267073a1a265540b41f04652f8160609157141","modified":1506595978694},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 03-37-04.md","hash":"9f537a36bd7746a0d8effc3643ac019cf530f722","modified":1506595978696},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 18-10-04.md","hash":"7ff6d2098df7a1156d929dc7599dbb8c1797fc42","modified":1506595978695},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 18-16-14.md","hash":"deed12d87ddd0647d6efbeaccc75b2e9feb0e72c","modified":1506595978697},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 18-17-28.md","hash":"622b70f97467c720e3be9afbcd07b038426ac98c","modified":1506595978704},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 18-18-28.md","hash":"62624a608b3695c200c94f29ee39ec39ea00010d","modified":1506595978688},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 18-29-28.md","hash":"0a54711b1e5b34028c321a0931850b6f36920090","modified":1506595978717},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 18-30-28.md","hash":"25c69f7b1c57768dbf83b327456907e7ba1529a1","modified":1506595978715},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 18-31-28.md","hash":"9db97b0b86044b3f0fc3806827bf2bd344b77a09","modified":1506595978706},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 18-33-36.md","hash":"06e8a938899eaba5b90f9353dba6bd9fe8bdf3e7","modified":1506595978718},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 19-50-56.md","hash":"5ca18fe8e891262c196f9e8d7c3add4552e5961c","modified":1506595978709},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-29 19-54-24.md","hash":"5afc5e0c2ac1eca33fc1bf6d8f205245a9509db9","modified":1506595978686},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 09-18-50.md","hash":"a7c47a5fb355f38985bf1119cbfdb7f12d7d6a46","modified":1506595978710},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 09-20-04.md","hash":"163fcddc96fdcede0ec94c15fb10699913138443","modified":1506595978704},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 09-21-40.md","hash":"24cab580ade1048d04eb507a570d2c146dabb682","modified":1506595978714},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 09-24-16.md","hash":"b0364af96247fdbcf5f0f431d823e9c196327b56","modified":1506595978701},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 09-25-20.md","hash":"399ce8aa84d2ddef1a3989608c3abf955c302d24","modified":1506595978719},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 09-26-22.md","hash":"cfaf27c0c5dca68d2c08ea252a90281ca7a9acad","modified":1506595978696},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 09-27-50.md","hash":"98cd2aaf2b7623e5f4b735bb85eb93e044ec68f8","modified":1506595978709},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 09-29-40.md","hash":"f53b51925a7d249e8051cd6edfe77e6e202a3705","modified":1506595978690},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 09-32-40.md","hash":"f870ce5ceebe28764199a374ab0d6877c7896eaa","modified":1506595978692},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 09-34-10.md","hash":"eb0289faca1148fe2f943a1a14fa52de7eb3c49f","modified":1506595978690},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 09-35-40.md","hash":"88b16c0f9024e18fa1e9f04fc59d09f7147a8ef0","modified":1506595978694},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 09-37-34.md","hash":"aebba95685dca548f7c9e07699bdba861f7bcb3d","modified":1506595978697},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 09-39-00.md","hash":"d9529020ba2d3042064490e73d0a6efc26d0355b","modified":1506595978702},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 09-42-00.md","hash":"043597a90498526a04cb74692aca6501b16b9526","modified":1506595978710},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 09-46-32.md","hash":"14ff7224ebe9de9b5c49d0cab87bd8f2ee82c82d","modified":1506595978693},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 09-59-10.md","hash":"e4e57b5b296bc4287b97d96ccfa4031b4ea206b1","modified":1506595978711},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-01-00.md","hash":"3bdb5fa8d2f9b60bcd248ec720a0548234a87e1c","modified":1506595978688},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-02-20.md","hash":"6150060c4f4cdc1b8502a3cc77720b1f2f5bbfd4","modified":1506595978696},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-06-39.md","hash":"cba598703e7d83975949d3163d8f5834d8ab6f17","modified":1506595978710},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-07-53.md","hash":"afdaf4e88c8011e017fffd6a4d4ea8c7af4101fa","modified":1506595978720},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-09-10.md","hash":"92f9e43e8de3392aac2a531306836ba369c51990","modified":1506595978708},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-12-20.md","hash":"b90c9d45f8eb476057d8c2f637ef09c7b8424607","modified":1506595978708},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-13-20.md","hash":"d7943643812aef51131d422b27f366dac89fc3de","modified":1506595978703},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-15-10.md","hash":"7f43fb8f1093ae2fe078c99e36639b10ffffcb69","modified":1506595978705},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-16-34.md","hash":"140f3cdaa3c039f036eb9f1f345819812b1764d0","modified":1506595978715},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-21-00.md","hash":"e656319b83d95ea756b584410063855430245677","modified":1506595978693},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-22-03.md","hash":"c55328c8a42f29336ecbafc6e0e2d6e0c4aa2094","modified":1506595978703},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-29-36.md","hash":"b5b2c7c0546614e293233960a38d1b5788e33bc2","modified":1506595978691},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-32-44.md","hash":"c7c9551fca91d118c51370734ccb40f90ec93832","modified":1506595978708},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-33-51.md","hash":"625e3210fdc798e0637b1afdba1a8f0b78183086","modified":1506595978707},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-36-33.md","hash":"bd6fc985d5a848197150530f008cd7d10a9cdf5d","modified":1506595978690},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-37-40.md","hash":"71e7903877b107cc85139f74f2cab67567510275","modified":1506595978707},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-39-50.md","hash":"0159fe9d887680df4e8e39a32ae3f63429b3767c","modified":1506595978696},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-42-14.md","hash":"6b72401d0d4270d49a3fe77440cb2a026587db5b","modified":1506595978692},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-43-20.md","hash":"bfe98411c51c7e84872072dec1289d2878945cf1","modified":1506595978698},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-44-23.md","hash":"5741af76e10811dedc3d73fdc22635c545b2acab","modified":1506595978717},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-45-35.md","hash":"47b3ed5628721c0ace4e0b355d82e7fa0bf4fee7","modified":1506595978698},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-48-20.md","hash":"3fb59ddb361a615fff01e75e41a4b6526651ec19","modified":1506595978716},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-49-30.md","hash":"4535995159ebd0c4a91422c6eb3efa91fb5ce47d","modified":1506595978706},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-50-50.md","hash":"a27c38a6eb116e60812f384555be1f0a3873e0b8","modified":1506595978703},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-51-50.md","hash":"a0884a32e2a53fdbcfe5d6d84de06eaa067bb507","modified":1506595978709},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-53-59.md","hash":"376e694cfcebf9f56bacfa49aa1d3bb9adb2bcf5","modified":1506595978699},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-55-30.md","hash":"2245fe79162f87eb8ae45ccb1e43c0242b8eeda1","modified":1506595978712},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-56-40.md","hash":"608dcd39bfc6dd8c7c8025faa3016f45b5120581","modified":1506595978706},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 10-57-40.md","hash":"f31064c919e89866e3c1e8b41abcca3978a0f3f1","modified":1506595978715},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-02-40.md","hash":"fd5e0e0b8646acc09bf8acbbef8d6920ba14ff7b","modified":1506595978701},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-03-40.md","hash":"d14e66e7fd7f3cfa8fc0235b76e0a75fa615c730","modified":1506595978691},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-05-54.md","hash":"378ca51ccab816fdbf7f192992d32bf79b6356f8","modified":1506595978688},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-07-10.md","hash":"ed9b0eb9eaae5ff17770c2e8aecc9cc9a5c85cf1","modified":1506595978690},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-10-40.md","hash":"f0acb0e655f6dccbfa2d025749b981c6aafc6683","modified":1506595978718},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-12-00.md","hash":"d636e3ad80a115c78091866ccc3209e703c889db","modified":1506595978712},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-24-40.md","hash":"944b272f286b52a0cbeceb88a4c099084aa81185","modified":1506595978699},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-26-00.md","hash":"af3c95b34dbc5579735ce035f895840195524a3c","modified":1506595978695},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-27-10.md","hash":"cef62f97f22432ab6a7d7bd6356747f0201ac829","modified":1506595978688},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-30-20.md","hash":"f060a701e362e1e68bdc3dc7deef7e9e8ef9b705","modified":1506595978717},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-32-50.md","hash":"6b7c1c2ff5e9bd6fa981d1f9eabea5fc6e3c3b79","modified":1506595978713},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-33-50.md","hash":"af08217670f8cf81ead481e02f7caa50dffcdb9e","modified":1506595978702},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-34-50.md","hash":"2dd4a1be2dfd08602095baa0687196e2f66b3744","modified":1506595978719},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-37-00.md","hash":"771115cfeb808b38ad113a34b8063f8e8dd53134","modified":1506595978701},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-38-35.md","hash":"5770b312eee12626e44075f5493a2a2ee8302913","modified":1506595978686},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-40-00.md","hash":"143546a1f071662336501eb34c2c9004d7de39a9","modified":1506595978692},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-41-00.md","hash":"fc923cdd1b1dc3d4b10468dda12e2999f8acb7ad","modified":1506595978698},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-43-00.md","hash":"acafc53e14aa461605a3a69effd1b4e82a8a5845","modified":1506595978700},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-44-00.md","hash":"ae1db83a6fdd666da57a6384d720f61c531e41b8","modified":1506595978687},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-45-00.md","hash":"fbbfdf41df97352bf848bc96976d653273f786bb","modified":1506595978696},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-46-50.md","hash":"b375102c966d6063ec4971ac4b0a13ed4919c5d4","modified":1506595978691},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-49-00.md","hash":"9f5b8014b40eb2243701c20e112cd83da32ab52f","modified":1506595978704},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-50-00.md","hash":"f6355bf9d3dd429ba86d61858033208de1a15a84","modified":1506595978705},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-51-00.md","hash":"f3890586f5df662bb1cb5e5e38a6f07153414511","modified":1506595978720},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-52-00.md","hash":"0d814624b62ff66dd45db8391e4de80f511bb50e","modified":1506595978707},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-53-00.md","hash":"b2c46333f77d7ecfbf0caf0140ec66e036e03d32","modified":1506595978713},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-54-00.md","hash":"8e4f2b9d608dc43f683771dac1986e4ded7f1d22","modified":1506595978702},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-55-00.md","hash":"e9cd60a6a42d8c12b9f1cc6667d1c217efe1e288","modified":1506595978709},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-57-16.md","hash":"422e82b02b6cb9945e99530995f1f2bb971ecb60","modified":1506595978689},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 11-59-40.md","hash":"17bd0de51b745ab040a7070f325ec4876dceebe6","modified":1506595978686},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-00-41.md","hash":"12b1d1032bde25a6d58223830221c9a700a52849","modified":1506595978714},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-03-10.md","hash":"23a6c16260b9e878552367eb480b9c0b8b8437a2","modified":1506595978705},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-05-20.md","hash":"80a9ea2e4298421f184d7798c8f905bb6d1da107","modified":1506595978704},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-06-50.md","hash":"28b2acd36a8218afc6709276bd8f7091be7ed67f","modified":1506595978719},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-07-50.md","hash":"fdbfc3b0a422d324432232bfe89bcc7ab5d1320c","modified":1506595978706},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-08-50.md","hash":"25339729ecada90a660c4e816fc904c9f01f2551","modified":1506595978689},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-09-50.md","hash":"871972a2327bb277aeb140962c8cc034e585ac32","modified":1506595978695},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-12-10.md","hash":"db906b169fa726091b50c054edf7716da6f48594","modified":1506595978697},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-13-10.md","hash":"a105d6fd58b6673c209e21d0f94fe70d17ff412a","modified":1506595978692},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-14-10.md","hash":"1459fba2605038c211fc8286eb380afce7735fed","modified":1506595978694},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-16-00.md","hash":"36249dab45c8fc9cb879785b60b03312dc3a6734","modified":1506595978695},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-17-00.md","hash":"0af4358235dd318a3f161e9a8ef9a6bbc35d1d65","modified":1506595978687},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-18-00.md","hash":"141a49cc2800b91c801bd2cecc1771f16b66d41c","modified":1506595978706},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-19-00.md","hash":"7606276fe885997e1530d0f22727258c290da053","modified":1506595978716},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-20-00.md","hash":"17c9811a59059dc304652953ade86d7a199f45c3","modified":1506595978712},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-21-00.md","hash":"f2eb22a0e1d83a4d67ba971b334aa5aa919ad614","modified":1506595978702},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-22-30.md","hash":"e824630f9ff347d9e7fb880dd4e360590bb6ddab","modified":1506595978711},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-36-20.md","hash":"b916d40f098f2a4777fb11148f7d57fca4bcdd84","modified":1506595978700},{"_id":"source/_drafts/.Archive/hexo写博客.md/2017-05-30 12-37-20.md","hash":"c4415b9e31d35f948e915dcafabe04b6a648af57","modified":1506595978691},{"_id":"source/_drafts/.Archive/jce问题.md/2017-06-25 21-48-07.md","hash":"89251d02160b2497825e4e2ddfbf6f2b4018e6f3","modified":1506595978722},{"_id":"source/_drafts/.Archive/jce问题.md/2017-06-25 21-49-37.md","hash":"63ce3928592bc1caa2f024af66a8524d5fa412fe","modified":1506595978722},{"_id":"source/_drafts/.Archive/jce问题.md/2017-06-25 21-50-37.md","hash":"c3cca7b078ab0e6f560f2083d4ffc2766aac3842","modified":1506595978722},{"_id":"source/_drafts/.Archive/jce问题.md/2017-06-25 21-51-37.md","hash":"1e43c8ddf160633d02f273ad10fbf5266255bf62","modified":1506595978721},{"_id":"source/_drafts/.Archive/kibana-timestamp问题.md/2017-05-27 16-42-19.md","hash":"1bf348266797e882ba4a3f6074124ca909189e2e","modified":1506595978667},{"_id":"source/_drafts/.Archive/kibana-timestamp问题.md/2017-05-27 16-43-39.md","hash":"ed3a342e432595b1b9ebe0e038a4275ec4260b36","modified":1506595978668},{"_id":"source/_drafts/.Archive/kibana-timestamp问题.md/2017-05-27 16-44-39.md","hash":"cdbb731f153a233e953e3bea0678ed87d273e18c","modified":1506595978666},{"_id":"source/_drafts/.Archive/kibana-timestamp问题.md/2017-05-27 16-45-39.md","hash":"eb731fdb1ec1b7262e014ac4a6b9b0a3d681adca","modified":1506595978668},{"_id":"source/_drafts/.Archive/kibana-timestamp问题.md/2017-05-27 16-46-39.md","hash":"e9403a2a6b5ce35f5881807271b5ffc5793b6e6d","modified":1506595978667},{"_id":"source/_drafts/.Archive/kibana-timestamp问题.md/2017-05-27 16-47-39.md","hash":"db10747f072916838a0c5b20601dd095d102bafc","modified":1506595978667},{"_id":"source/_drafts/.Archive/kibana-timestamp问题.md/2017-05-27 17-08-36.md","hash":"f18bbc48d2e89a22ab963ec05fddd448c3645068","modified":1506595978668},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 20-56-18.md","hash":"ec80fc94ae7bc26db235902ffab92b7eb1eeb107","modified":1506595978670},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-02-58.md","hash":"bec50f566db01fa94bfaaf00dc540e26e861b031","modified":1506595978684},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-05-48.md","hash":"0f7b383d15d67608a7c24a544d1c4646ec3669bc","modified":1506595978682},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-08-38.md","hash":"e85b79454f57fcf530b98a1d4b086a3b986b46da","modified":1506595978672},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-11-58.md","hash":"ed15b99c3f9d889aac5f3de26ba47ae3c805f584","modified":1506595978675},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-12-58.md","hash":"42ec320e56bdf68bcf2db670110e8ee46ce32b9b","modified":1506595978679},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-23-58.md","hash":"43340a092ae87ba3e06af910a60b70f87ffee9a5","modified":1506595978680},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-24-58.md","hash":"2045eca9a2d0e9378f814d0bfc2bd5f478732fbd","modified":1506595978685},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-27-08.md","hash":"da5c9eec56ddb9fe736d0ce74089a691c03bda8a","modified":1506595978681},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-28-08.md","hash":"798cdd5af6989d98151647ad52082e6cd1ff9d3d","modified":1506595978675},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-29-08.md","hash":"c74e08c7436173111a08038c4440c98d69ca4c5e","modified":1506595978678},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-30-08.md","hash":"8b9275dd6bbad9ee3a69cd2adad91d4aceddc495","modified":1506595978678},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-31-38.md","hash":"901d142e51a16674518d4c1a419c84c46fe48014","modified":1506595978675},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-33-58.md","hash":"54b276cd8441069a2d2a162942ba5b3032eeacca","modified":1506595978673},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-35-28.md","hash":"2426c5bd32dd3f3aee7db98fff19d91886890c33","modified":1506595978671},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-36-38.md","hash":"865135bcd7acdbc13e8563fc96dfad925cb1a699","modified":1506595978677},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-39-08.md","hash":"d80bd40f723318c2a36f7fc8acc588e880f51073","modified":1506595978685},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-40-38.md","hash":"71580f63deaaef4d207f0f33663d939185982b97","modified":1506595978683},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-41-38.md","hash":"cc5eba4dc4ec075b33e8e7a30d0e1764c1ca4218","modified":1506595978684},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-42-48.md","hash":"5ea5767617bc095e5bfda1cd5a9155516fedfce0","modified":1506595978680},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-44-28.md","hash":"b20598b6958264d057f0090031dae92f020a338c","modified":1506595978681},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 21-57-28.md","hash":"7188a44c4432723e64b75b593eab402e239bf090","modified":1506595978677},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 22-00-08.md","hash":"ee7cbd3fa46302a0873b4072d01b009b7ba90de5","modified":1506595978679},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 22-04-36.md","hash":"7f5660ac33fff8e4b9e17c87295395d3ac6fb4b0","modified":1506595978669},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 22-17-48.md","hash":"9d1b751c8ef052bfd7b9e300d46f716855bb366b","modified":1506595978683},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 22-20-08.md","hash":"6371474ee3b3001283c522e9d69036c5b6654f23","modified":1506595978676},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 22-21-08.md","hash":"1a31a525f67cb71bc3363c18a903c349ba6a5bff","modified":1506595978674},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 22-23-38.md","hash":"99108c8bf48274717726532cc404bd4ec501c386","modified":1506595978672},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 22-24-48.md","hash":"4746e0c3883bbce86861a3f32031bcea13138421","modified":1506595978676},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 22-28-28.md","hash":"8a2085ef20f3928f2cd4956206f3198c578e8ae7","modified":1506595978682},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 22-32-48.md","hash":"6c6fa83e5ba4c85b58f1e0a05a09590d005c335d","modified":1506595978685},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 22-51-44.md","hash":"2c9ef9d584a5b5fb3da647e9b4f0ae1bf0f39991","modified":1506595978678},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 23-04-04.md","hash":"0f2a16c7a17c87f55ba26d0e747f2493b7a3a323","modified":1506595978683},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 23-23-14.md","hash":"572f27e92399b9c2db26a4aecbe5410a27e6be4d","modified":1506595978681},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 23-26-14.md","hash":"903725497bfd5f731a5952301a3fe22de8eeaec1","modified":1506595978684},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 23-28-14.md","hash":"289c3b595b32b1f95a5e91de8141c96db04c8462","modified":1506595978669},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 23-31-14.md","hash":"da8037d0a23ec9eca098336e43ab691f5ab6aad9","modified":1506595978670},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 23-32-15.md","hash":"e364022ec82a6d9caac9a14c4c8b8a452acadb2b","modified":1506595978679},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 23-33-45.md","hash":"095fdf642e87fb6d691cf1394c629bbdd93132d6","modified":1506595978671},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 23-35-15.md","hash":"82613e832c8368c57639116a1dc7a15c6b035014","modified":1506595978670},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 23-36-15.md","hash":"1f887518de54a307e11f74cf74c77cb01ecb93df","modified":1506595978677},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 23-37-15.md","hash":"0b27847a57bb5bd86d007df131896f2003ab92cd","modified":1506595978674},{"_id":"source/_drafts/.Archive/nifi架构.md/2017-06-06 23-38-55.md","hash":"bae0750f82d9889256e1f6dabbabcf418ac87cec","modified":1506595978682},{"_id":"source/_drafts/_image/2017-05-30-12-16-17.jpg","hash":"6fc13a939382da0435b8466e5166be519e41c78a","modified":1506595978663},{"_id":"source/images/2017-05-30-11-30-06.jpg","hash":"244403b988bba7939973a9bc2297fde3fbeba5ee","modified":1506595978618},{"_id":"source/images/fig4.png","hash":"dadbc2a43f23babbda8f5e492a04dca3ce873b33","modified":1506595978616},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1506596177582},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1506596177582},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"2d1075f4cabcb3956b7b84a8e210f5a66f0a5562","modified":1506596177581},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1506596177580},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1506596177580},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1506596177590},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1506596177589},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1506596177590},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"63315fcf210799f894208c9f512737096df84962","modified":1506596177590},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1506596177576},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1506596177572},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1506596177605},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1506596177608},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1506596177605},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1506596177610},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"394d008e5e94575280407ad8a1607a028026cbc3","modified":1506596177607},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1506596177604},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"3358d11b9a26185a2d36c96049e4340e701646e4","modified":1506596177606},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"92dc60821307fc9769bea9b2d60adaeb798342af","modified":1506596177609},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1506596177607},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"a652f202bd5b30c648c228ab8f0e997eb4928e44","modified":1506596177608},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1506596177603},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1506596177594},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1506596177592},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1506596177594},{"_id":"themes/next/layout/_third-party/comments/gentie.swig","hash":"03592d1d731592103a41ebb87437fe4b0a4c78ca","modified":1506596177595},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1506596177592},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"abb92620197a16ed2c0775edf18a0f044a82256e","modified":1506596177593},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"7240f2e5ec7115f8abbbc4c9ef73d4bed180fdc7","modified":1506596177595},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"af9dd8a4aed7d06cf47b363eebff48850888566c","modified":1506596177593},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1506596177598},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1506596177598},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"f4dbd4c896e6510ded8ebe05394c28f8a86e71bf","modified":1506596177599},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1506596177602},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1506596177617},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"715d5b40dc52f319fe4bff0325beb874774d9bd9","modified":1506596177677},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"78a83c38f69a8747bb74e420e6c9eeef1ea76525","modified":1506596177676},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"c8d35a6b9e3bff6d8fdb66de853065af9d37562d","modified":1506596177657},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"06f432f328a5b8a9ef0dbd5301b002aba600b4ce","modified":1506596177658},{"_id":"themes/next/source/css/_variables/base.styl","hash":"28a7f84242ca816a6452a0a79669ca963d824607","modified":1506596177657},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1506596177696},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1506596177694},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"aab7be0a6e2724b3faa9338db93c19556c559625","modified":1506596177692},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1506596177695},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1506596177692},{"_id":"themes/next/source/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1506596177695},{"_id":"themes/next/source/js/src/post-details.js","hash":"af7a417dd1cb02465a7b98211653e7c6192e6d55","modified":1506596177693},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1506596177693},{"_id":"themes/next/source/js/src/utils.js","hash":"e13c9ccf70d593bdf3b8cc1d768f595abd610e6e","modified":1506596177694},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1506596177704},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1506596177720},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1506596177716},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1506596177717},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1506596177699},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1506596177697},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1506596177699},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1506596177698},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1506596177743},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1506596177742},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1506596177738},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1506596177743},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1506596177741},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1506596177719},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1506596177737},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1506596177736},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1506596177735},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1506596177735},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1506596177737},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1506596177734},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"5b38ae00297ffc07f433c632c3dbf7bde4cdf39a","modified":1506596177728},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1506596177725},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1506596177724},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1506596177722},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1506596177724},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1506596177725},{"_id":"themes/next/source/images/avatar.jpg","hash":"410ce33c9e76d0d5b984006bca00dad4cb73146f","modified":1506596177688},{"_id":"source/_drafts/_image/2017-05-30-12-16-55.jpg","hash":"933f2beedf1ad8a2bc410438b6f5fe78e5174ad8","modified":1506595978661},{"_id":"source/images/2017-05-30-11-38-30.jpg","hash":"5d127c307542345e46c134cea5d52c393292da73","modified":1506595978623},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1506596177599},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1506596177600},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"59ad08bcc6fe9793594869ac2b4c525021453e78","modified":1506596177641},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"ef089a407c90e58eca10c49bc47ec978f96e03ba","modified":1506596177646},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"0dfb4b3ba3180d7285e66f270e1d3fa0f132c3d2","modified":1506596177641},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1506596177642},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1506596177622},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1506596177642},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1506596177646},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1506596177656},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"7804e31c44717c9a9ddf0f8482b9b9c1a0f74538","modified":1506596177619},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1506596177619},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1506596177620},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"013619c472c7e4b08311c464fcbe9fcf5edde603","modified":1506596177621},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1506596177620},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1506596177670},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1506596177673},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1506596177674},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1506596177675},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"fda14bc35be2e1b332809b55b3d07155a833dbf4","modified":1506596177671},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1506596177673},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1506596177670},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1506596177661},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1506596177663},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"82bbaa6322764779a1ac2e2c8390ce901c7972e2","modified":1506596177664},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1506596177662},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1506596177662},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1506596177667},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"1eb34b9c1f6d541605ff23333eeb133e1c4daf17","modified":1506596177666},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1506596177668},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1506596177665},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"e3e23751d4ad24e8714b425d768cf68e37de7ded","modified":1506596177667},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1506596177666},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1506596177691},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1506596177711},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1506596177712},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1506596177708},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1506596177707},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1506596177710},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1506596177712},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1506596177708},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1506596177706},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1506596177709},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1506596177700},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1506596177701},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1506596177739},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1506596177740},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1506596177718},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1506596177741},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1506596177733},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1506596177732},{"_id":"source/_drafts/_image/2017-05-30-11-38-30.jpg","hash":"5d127c307542345e46c134cea5d52c393292da73","modified":1506595978663},{"_id":"source/_drafts/_image/2017-05-30-11-30-06.jpg","hash":"244403b988bba7939973a9bc2297fde3fbeba5ee","modified":1506595978660},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1506596177751},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1506596177748},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1506596177727},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1506596177630},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1506596177654},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1506596177655},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1506596177653},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1506596177653},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1506596177654},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1506596177640},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"755b04edbbfbdd981a783edb09c9cc34cb79cea7","modified":1506596177639},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1506596177640},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"7778920dd105fa4de3a7ab206eeba30b1a7bac45","modified":1506596177652},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1506596177652},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1506596177651},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1506596177651},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1506596177650},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"beccb53dcd658136fb91a0c5678dea8f37d6e0b6","modified":1506596177636},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"8fae54591877a73dff0b29b2be2e8935e3c63575","modified":1506596177638},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1506596177637},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1506596177637},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"b25132fe6a7ad67059a2c3afc60feabb479bdd75","modified":1506596177638},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1506596177633},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"b9a2e76f019a5941191f1263b54aef7b69c48789","modified":1506596177632},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1506596177632},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"e792c8dc41561c96d128e9b421187f1c3dc978a0","modified":1506596177631},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1506596177634},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"963105a531403d7aad6d9e5e23e3bfabb8ec065a","modified":1506596177633},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1506596177635},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"8c0276883398651336853d5ec0e9da267a00dd86","modified":1506596177631},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"2e7ec9aaa3293941106b1bdd09055246aa3c3dc6","modified":1506596177623},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1506596177626},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"5f6ea57aabfa30a437059bf8352f1ad829dbd4ff","modified":1506596177624},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1506596177628},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1506596177625},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"7690b9596ec3a49befbe529a5a2649abec0faf76","modified":1506596177627},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"a2ec22ef4a6817bbb2abe8660fcd99fe4ca0cc5e","modified":1506596177629},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"234facd038f144bd0fe09a31ed1357c5d74c517f","modified":1506596177627},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1506596177626},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1506596177645},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1506596177643},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1506596177644},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"74d0ba86f698165d13402670382a822c8736a556","modified":1506596177645},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"dd310c2d999185e881db007360176ee2f811df10","modified":1506596177644},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"b8969e1654eec89a0fd10d88b337fee9cb03cd44","modified":1506596177643},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1506596177648},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1506596177647},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1506596177647},{"_id":"themes/next/source/css/_common/components/third-party/gentie.styl","hash":"586a3ec0f1015e7207cd6a2474362e068c341744","modified":1506596177649},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1506596177648},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1506596177647},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"173490e21bece35a34858e8e534cf86e34561350","modified":1506596177649},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"42348219db93a85d2ee23cb06cebd4d8ab121726","modified":1506596177648},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1506596177669},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1506596177672},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1506596177660},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1506596177713},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1506596177716},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1506596177715},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1506596177714},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1506596177715},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1506596177714},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1506596177747},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1506596177750},{"_id":"source/images/Summary-recommendation-metrics.png","hash":"80449a188356d035c6bf0b906a9a734b28f25401","modified":1506595978615},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1506596177752},{"_id":"source/images/2017-05-30-12-05-17.jpg","hash":"e0c36b016c4405ea6d17c3af23436aeef92c312b","modified":1506595978622},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1506596177704},{"_id":"source/_drafts/_image/2017-05-30-12-05-17.jpg","hash":"e0c36b016c4405ea6d17c3af23436aeef92c312b","modified":1506595978662},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1506596177731},{"_id":"source/images/各种分布.png","hash":"da6019b5449fa9dc35bf5b925e9ae64f7a6783dc","modified":1506680420793},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1506596177745},{"_id":"public/baidusitemap.xml","hash":"fc78367f17d0695124e1ae230809027ef903c2f3","modified":1585451252393},{"_id":"public/sitemap.xml","hash":"6ed7580eb6cc655391718a6a945ebe7ba00a0070","modified":1585451252393},{"_id":"public/about/index.html","hash":"cabe03ea160d3cd40e2521d8982d72cf9d3d4421","modified":1585451252393},{"_id":"public/categories/index.html","hash":"bb25b41d9f2d02917a23a01380b1fbbfac4679cb","modified":1585451252393},{"_id":"public/tags/index.html","hash":"2cdab9d75f44838e6354e1bf93c563a3e65e4056","modified":1585451252393},{"_id":"public/2017/09/06/各种分布/index.html","hash":"a5ea3773d7072af4ff3ff7e5970ecc647b1e3342","modified":1585451252393},{"_id":"public/archives/2017/index.html","hash":"6069e7bafe39d29a34660c2549d832253d77f48b","modified":1585451252393},{"_id":"public/archives/2017/04/index.html","hash":"53b7869e113af3374719af56e35ef44d8a89389a","modified":1585451252393},{"_id":"public/archives/2017/03/index.html","hash":"758c110848d7793b78d65c7161bfc24523fd38a2","modified":1585451252393},{"_id":"public/archives/2017/05/index.html","hash":"e78fba90423986d3c1bc0476b587cd802973c0af","modified":1585451252393},{"_id":"public/archives/2017/06/index.html","hash":"f8ba29998c4582502e34695150ada7dbf72baef1","modified":1585451252393},{"_id":"public/archives/2017/09/index.html","hash":"d2a1dde3ca446f9c3e49650ef8ddb29966b59914","modified":1585451252393},{"_id":"public/archives/2018/index.html","hash":"0037eecb77f1b23ae9e828b170abb071a8e7a066","modified":1585451252393},{"_id":"public/archives/2018/01/index.html","hash":"80893f828d26d753efa1ff8147d672d3484b40c1","modified":1585451252393},{"_id":"public/archives/2019/index.html","hash":"e1090c0f588927271b55c0f0fdd708ee3c01cb61","modified":1585451252393},{"_id":"public/archives/2019/02/index.html","hash":"36313453888229e32ed4e859025413f2c21333e0","modified":1585451252393},{"_id":"public/archives/2020/index.html","hash":"341b0f3ca087ff1014f75f47062614313ac5001a","modified":1585451252393},{"_id":"public/archives/2020/03/index.html","hash":"82068f0a221cea2e725f973c203e47d5d64cc119","modified":1585451252393},{"_id":"public/categories/算法/index.html","hash":"ef5f9712b46441e0eed3123622884a7a04f0433a","modified":1585451252393},{"_id":"public/categories/apache-nifi/index.html","hash":"7647f77db5a4a11108b63bfa95074cb58c61b02e","modified":1585451252393},{"_id":"public/categories/hexo/index.html","hash":"73126eb259d5bda4a25110e947d1b0f95ae02f72","modified":1585451252393},{"_id":"public/tags/Lucene/index.html","hash":"71932d3452641bf5be52ca922ed9e66fa49a3cf8","modified":1585451252393},{"_id":"public/tags/笔记/index.html","hash":"49d9aa51c5a405f42ece7440966a5955b8ec3a92","modified":1585451252393},{"_id":"public/tags/pilosa/index.html","hash":"0cee1d663f1996888dd2f4e01d3926e173227916","modified":1585451252393},{"_id":"public/tags/推荐系统/index.html","hash":"b0b41da44c23d39e16b366b07ec620e67238275b","modified":1585451252393},{"_id":"public/tags/翻译/index.html","hash":"8b5ed5ede58579065dcd161a72299141d0ccf800","modified":1585451252393},{"_id":"public/2020/03/28/推荐系统2/index.html","hash":"031637b27bf9d15d6acc9f470b58574aa60d29f4","modified":1585451252393},{"_id":"public/2019/02/02/pilosa-data-mode/index.html","hash":"5c11c2f4f3fcf2fbcfa03f1db651b3247c1bb30a","modified":1585451252393},{"_id":"public/2018/01/27/oozie调度sqoop问题/index.html","hash":"4988840d01169af5d5196928f01b217087861280","modified":1585451252393},{"_id":"public/2017/09/28/推荐系统/index.html","hash":"776b97efdf1bde9c4e4a86ec661a5210344e2ca2","modified":1585451252393},{"_id":"public/2017/06/06/nifi架构/index.html","hash":"195b62d13a7fae8e55617ef6d527c55e813d64a4","modified":1585451252393},{"_id":"public/2017/05/27/hexo写博客/index.html","hash":"f205a55fef01f7ba65f2b4628d912432df8301d4","modified":1585451252393},{"_id":"public/2017/04/20/Lucene-打分算法/index.html","hash":"e9aec2f525883df777dd9d8b3283d5208e608cbd","modified":1585451252393},{"_id":"public/2017/04/20/tf-idf-计算查询语句和文档的相关性/index.html","hash":"345017a423d9642aa8508915cb622ed03d014a6d","modified":1585451252393},{"_id":"public/archives/index.html","hash":"8f9a710a4eb240f8ee9d675ec7198d41e3456b0d","modified":1585451252393},{"_id":"public/2017/03/30/nifi-简介/index.html","hash":"34898d425020d4d7ff667c6c497e4a4b60574cf8","modified":1585451252393},{"_id":"public/index.html","hash":"a362598344919a9e6379105ee970e27993a8b0bf","modified":1585451252393},{"_id":"public/2020/03/29/ElasticSearch/index.html","hash":"86abd05dc9af92192788d09b2ed1ef459216b6c8","modified":1585451252393},{"_id":"public/archives/page/2/index.html","hash":"08b692a49882c5f6f541496b795be978bba102b4","modified":1585451252393},{"_id":"public/page/2/index.html","hash":"20f6c9bb451dd37c86270d46440fc00b54bbe0a4","modified":1585451252393},{"_id":"public/robots.txt","hash":"ffe717b0850b95a19aba1618bd1fd4c2b17d7a06","modified":1585451252393},{"_id":"public/images/fig1.png","hash":"f05255be66a641f2b9443e299659bef9a58aef23","modified":1585451252393},{"_id":"public/images/fig6.png","hash":"85647a69492e793a67cf905a445363e3556e7c18","modified":1585451252393},{"_id":"public/images/vsm.jpg","hash":"6253d14f1c26c5feada9e644b4d46b1da745ecdc","modified":1585451252393},{"_id":"public/images/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1585451252393},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1585451252393},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1585451252393},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1585451252393},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1585451252393},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1585451252393},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1585451252393},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1585451252393},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1585451252393},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1585451252393},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1585451252393},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1585451252393},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1585451252393},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1585451252393},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1585451252393},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1585451252393},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1585451252393},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1585451252393},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1585451252393},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1585451252393},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1585451252393},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1585451252393},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1585451252393},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1585451252393},{"_id":"public/images/597C072D-AA0B-46A4-99D6-D910BAF08D90.png","hash":"9b0a4f4ddb1b1916538ba3c38b6a0ffe6b09290b","modified":1585451252393},{"_id":"public/images/LuceneSearch.jpg","hash":"6ed85ac3790cded3a736c5cfb7c6d8dfc8cbbbea","modified":1585451252393},{"_id":"public/images/2017-05-30-12-17-43.jpg","hash":"dbc3441f77d3c64302d0931ac8efab05926858b5","modified":1585451252393},{"_id":"public/images/fig2.png","hash":"c6793b7b3b346a5df99ed4689f3646e732758d6d","modified":1585451252393},{"_id":"public/images/fig3.png","hash":"88086c337ce175f8e2764a048ad6edec85ec6d26","modified":1585451252393},{"_id":"public/images/table4.png","hash":"d44f83d2cbb496c993f178243e95f34fddcaeeb1","modified":1585451252393},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1585451252393},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1585451252393},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1585451252393},{"_id":"public/js/src/bootstrap.js","hash":"aab7be0a6e2724b3faa9338db93c19556c559625","modified":1585451252393},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1585451252393},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1585451252393},{"_id":"public/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1585451252393},{"_id":"public/js/src/post-details.js","hash":"af7a417dd1cb02465a7b98211653e7c6192e6d55","modified":1585451252393},{"_id":"public/js/src/utils.js","hash":"e13c9ccf70d593bdf3b8cc1d768f595abd610e6e","modified":1585451252393},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1585451252393},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1585451252393},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1585451252393},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1585451252393},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1585451252393},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1585451252393},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1585451252393},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1585451252393},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1585451252393},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1585451252393},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1585451252393},{"_id":"public/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1585451252393},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1585451252393},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1585451252393},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1585451252393},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1585451252393},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1585451252393},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1585451252393},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1585451252393},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1585451252393},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1585451252393},{"_id":"public/css/main.css","hash":"d40d21b0641052ae1860433d1393205c80900167","modified":1585451252393},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1585451252393},{"_id":"public/lib/three/three-waves.min.js","hash":"5b38ae00297ffc07f433c632c3dbf7bde4cdf39a","modified":1585451252393},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1585451252393},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1585451252393},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1585451252393},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1585451252393},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1585451252393},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1585451252393},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1585451252393},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1585451252393},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1585451252393},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1585451252393},{"_id":"public/images/fig5.png","hash":"69bf0d431ea3120ea10ffa0e16e49a10188953d6","modified":1585451252393},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1585451252393},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1585451252393},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1585451252393},{"_id":"public/images/2017-05-30-12-16-17.jpg","hash":"6fc13a939382da0435b8466e5166be519e41c78a","modified":1585451252393},{"_id":"public/images/2017-05-30-12-16-55.jpg","hash":"933f2beedf1ad8a2bc410438b6f5fe78e5174ad8","modified":1585451252393},{"_id":"public/images/2017-05-30-11-30-06.jpg","hash":"244403b988bba7939973a9bc2297fde3fbeba5ee","modified":1585451252393},{"_id":"public/images/fig4.png","hash":"dadbc2a43f23babbda8f5e492a04dca3ce873b33","modified":1585451252393},{"_id":"public/images/avatar.jpg","hash":"410ce33c9e76d0d5b984006bca00dad4cb73146f","modified":1585451252393},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"f828dbc90e164bd9b94574894fbcf810a38e6a0c","modified":1585451252393},{"_id":"public/lib/jquery_lazyload/README.html","hash":"04c3ea974d38a27acad5f5153f9e73ae58390f40","modified":1585451252393},{"_id":"public/images/2017-05-30-11-38-30.jpg","hash":"5d127c307542345e46c134cea5d52c393292da73","modified":1585451252393},{"_id":"public/lib/fastclick/README.html","hash":"66bb72754c4eb51113219c23935a5a917ab6d035","modified":1585451252393},{"_id":"public/images/Summary-recommendation-metrics.png","hash":"80449a188356d035c6bf0b906a9a734b28f25401","modified":1585451252393},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1585451252393},{"_id":"public/images/2017-05-30-12-05-17.jpg","hash":"e0c36b016c4405ea6d17c3af23436aeef92c312b","modified":1585451252393},{"_id":"public/images/各种分布.png","hash":"da6019b5449fa9dc35bf5b925e9ae64f7a6783dc","modified":1585451252393}],"Category":[{"name":"算法","_id":"ck8cgqo7f00043szydcxbc84l"},{"name":"apache nifi","_id":"ck8cgqo7l000a3szy2pg111pj"},{"name":"hexo","_id":"ck8cgqo7o000g3szy510bdt0i"},{"name":"ELK","_id":"ck8cgqo7y000v3szy5nh25iaf"}],"Data":[],"Page":[{"title":"about","date":"2017-04-20T09:10:55.000Z","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2017-04-20 17:10:55\n---\n","updated":"2017-09-28T10:52:58.659Z","path":"about/index.html","comments":1,"layout":"page","_id":"ck8cgqo7c00013szy1jcy9os2","content":"\n","site":{"data":{}},"excerpt":"","more":"\n"},{"title":"categories","date":"2017-04-20T09:08:52.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2017-04-20 17:08:52\ntype: \"categories\"\n---\n","updated":"2017-09-28T10:52:58.728Z","path":"categories/index.html","comments":1,"layout":"page","_id":"ck8cgqo7f00033szygqla79bt","content":"\n","site":{"data":{}},"excerpt":"","more":"\n"},{"title":"tags","date":"2017-04-20T09:08:48.000Z","type":"tags","_content":"\n","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2017-04-20 17:08:48\ntype: \"tags\"\n---\n\n","updated":"2017-09-28T10:52:58.727Z","path":"tags/index.html","comments":1,"layout":"page","_id":"ck8cgqo7i00073szyftce889u","content":"\n","site":{"data":{}},"excerpt":"","more":"\n"}],"Post":[{"title":"Lucene 打分算法","date":"2017-04-20T09:27:34.000Z","_content":"## Lucene是什么\n\nLucene 是一个基于 Java 的全文信息检索工具包，它不是一个完整的搜索应用程序，而是为你的应用程序提供索引和搜索功能。Lucene 目前是 Apache Jakarta 家族中的一个开源项目。也是目前最为流行的基于 Java 开源全文检索工具包。\n\nLucene总的来说是：\n\n* 一个高效的，可扩展的，全文检索库。\n* 全部用Java实现，同时提供python接口（pylucene)。\n* 仅支持纯文本文件的索引(Indexing)和搜索(Search)。\n\n## Lucene数学模型\n\n### 文档，域(字段)，词元\n\n文档是Lucene搜索和索引的原子单位，文档为包含一个或者多个域(字段)的容器，而域(字段)则是依次包含“真正的”被搜索的内容，域(字段)值通过分词技术处理，得到多个词元。\n\n举个栗子，一篇小说（斗破苍穹）信息可以称为一个文档，小说信息又包含多个域(字段)，例如：标题（斗破苍穹）、作者、简介、最后更新时间等等，对标题这个域(字段)采用分词技术又可以得到一个或者多个词元（斗、破、苍、穹）。\n\n## Lucene检索过程\n\n![](/images/LuceneSearch.jpg)\n\n## 打分算法\n\n### BIR（布尔模型）\n\n布尔逻辑将是建立最早的模型，也是目前应用最广泛的检索技术。它是通过布尔逻辑运算符：逻辑与（AND），逻辑或（OR），逻辑非（NOT）的组合来表达用户的检索需求。布尔逻辑是乔治·布尔在19 世纪中期定义的代数系统。1957 年，巴·希列尔最先探讨了将布尔逻辑应用到计算机检索的可能性。上世界 6，70 年代，布尔检索模型被正式用于各类文献系统并且逐步成为商业标准，这种模型并不提供任何的文档相关性测度，对于文档与查询的评价就只有“匹配”，“不匹配”两种而已，用户必须详细的规划自己的查询。\n\n### TF-IDF（词频-反词频）\n\n本质上，TF-IDF通过确定特定文档中的单词的相对频率与该单词在整个文档语料库中的反比例相比较起作用。 直观地，该计算确定给定单词在特定文档中的相关性。 在一个单一或一小组文件中不常见的单词往往比普通单词（如冠词和介词）具有更高的TF-IDF值。不同的情景下实现的TF-IDF有一些微小不同的地方，但是总体上计算的方式如下：\n给定一个稳定集合$D$，一个单词 $w$ 和一个文档 $d \\in D$,我们计算$$\\mathcal{W}_d=f_{w,d}*log(\\frac{|D|}{f_{w,D}})$$其中 $f_{w,d}$ 等于词 $w$ 在文档 $d$ 中出现的次数，$|D|$是文档全集的大小, $f_{w,D}$ 是词 $w$ 在全集中出现的次数(Salton & Buckley, 1988, Berger, et al, 2000)。假设$|D|\\thicksim f_{w,d}$,即语料库的大小大接近于$w$在集合$D$的频率，对于一些非常小的常数$c$，满足 $1 < log(\\frac{|D|}{f_{w,D}}) < c$ ,那么$w$将会比$f_{w,d}$小但是仍然是正的,这意味着$w$在整个语料库中比较常见，但在整个$D$句中仍然保持一定的重要性，例如TF-IDF在《新约》中的测试“Jesus”，就会是这种情况，与我们更加相关的例子在联合国文档的语料中“united”的结果可以预期到也是这种情况。对于非常常见的词语也是如此，例如冠词，代词和介词，它们本身在查询中没有任何相关的含义（除非用户明确要求含有这样的常用单词的文档）。 因此，这样的常用词得到非常低的TF-IDF分数，使得它们在搜索中基本上可以忽略不计。假设$f_{w,d}$非常大，$f_{w,D}$很小，那么$log(\\frac{|D|}{f_{w,D}})$将会变得相当大，所以$w_d$同样会很大，因为具有高$w_d$的词意味着$w$是$d$中的重要词，而在$D$中不常见。这个词被认为具有很大的有辨识力的。\n\n\n### VSM（向量空间模型）\n\n![](/images/vsm.jpg)\n向量空间模型 (VSM：Vector Space Model) 是一个应用于信息过滤, 信息撷取, 索引以及评估相关性的代数模型。由Salton等人于60年代提出，并成功地应用于著名的SMART文本检索系统。文件(语料)被视为索引词(关键字)形成的多次元向量空间， 索引词的集合通常为文件中至少出现过一次的词组。在文本检索中，文档与查询词可以表示为以下向量空间模型[1] :$$d_j = (w_{1,j},w_{2,j},…,w_{t,j})$$$$\nq = (w_{1,q},w_{2,q},…,w_{t,q})$$\n \n据文档相似度理论的假设，如要在一次关键词查询中计算各文档间的相关排序，只需比较每个文档向量和原先查询向量（跟文档向量的类型是相同的）之间的角度偏差。\n实际上，计算向量之间夹角的余弦比直接计算夹角本身要简单。\n$${\\displaystyle \\cos {\\theta }={\\frac {\\mathbf {d} \\cdot \\mathbf {q} }{\\left\\|\\mathbf {d} \\right\\|\\left\\|\\mathbf {q} \\right\\|}}}$$\n其中 ${\\displaystyle \\mathbf {d_{2}} \\cdot \\mathbf {q} }$是文档向量（即上 图中的d2）和查询向量（图中的q）的点乘。 ${\\displaystyle \\left\\|\\mathbf {d_{2}} \\right\\|}$是向量d2的模，而 ${\\displaystyle \\left\\|\\mathbf {q} \\right\\|}$是向量q的模。向量的模通过下面的公式来计算：\n$${\\displaystyle \\left\\|\\mathbf {v} \\right\\|={\\sqrt {\\sum _{i=1}^{n}v_{i}^{2}}}}$$\n由于这个模型所考虑的所有向量都是每个元素严格非负的，因此如果余弦值为零，则表示查询向量和文档向量是正交的，即不符合（换句话说，就是检索项在文档中没有找到）\n  \n\n### Lucene打分模型\nLucene计算公式是对BIR，TF-IDF和vsm的一个综合使用和改进。首先采用BIR的方法把所有匹配的文档取出作为一个匹配文档集合，然后再用改进的VSM算法对这些文档进行排序，事实上由于Lucene是基于域的，所以的检索过程都是基于域的计算，最后按照域的权重求和得到最终的文档分数。VSM构建词向量的方式有很多种，其中比较有名的就是通过TF-IDF来构建，$w_{i,j}$通过计算文档$d_j$中$i$词在的TF-IDF值,虽然获得了词向量构建方法,但是会遇到查询$q$的维度远远小于文档$d_j$的问题，只需要以$q$的维度作为标准，文档$d_j$只在该基中映射。\n\n按照原始的VSM模型，余弦的计算可以看做是2个归一化的向量内积，但是在实际应用中会遇到一些问题，显而易见的就是丢失了文档的长度信息，举个例子：\n\n文档1：i think that\n文档2：”I think it’s unlikely to be a real thing. I’m sure it’s an overreaction about an already-skittish party,” Roberts said. “They have looked at what happens in that circumstance.”, hello, i love the word.\n查询“think”，那么按照原始的VSM返回的相似度是一样的。但是显然搜索的目的应该是偏向文档1的，为了解决这个问题，Lucene引入了一个和长度相关的归一化方法 $f(\\mathbf{d}_f)$ 所以改进后的VSM如下：$${\\displaystyle sim(\\mathbf{q},\\mathbf{d}_f)={\\frac {\\mathbf {q} \\cdot \\mathbf {d}_f }{\\left\\|\\mathbf {q} \\right\\|}}}*f(\\mathbf{d}_f)$$\n接下来考虑一些更加定制化的内容：\n\n1. 我们可能会在系统中规定哪些文档是更加重要的，比如相对房地产平台销冠来说楼盘详细信息的文档就会比楼盘的小道消息重要，在查询楼盘的时候我们希望楼盘详细信息会出现在小道消息前面，我们可以通过给文档一个分数来定义文档的重要性计做$w_{d}$\n2. 同样的考虑到查询的关键字重要性定制化，我们引入查询权重向量计做$\\mathbf{w}_{q}$\n3. Lucene是基于域的,所有的检索过程都是在域的尺度进行的，所以不同的域可以有相应的权重计做$w_{f}$\n4. 最后考虑到查询和域的匹配度，引入函数 $f(\\mathbf{q},\\mathbf{d}_f)$ （关于查询向量$\\mathbf{q}$和文档$\\mathbf{d}$ 域 $f$ 向量的函数） \n\n于是我们得到计算分数公式如下：\n$$sim(\\mathbf{q}, \\mathbf{d}) = w_d \\cdot \\sum_{f \\in d}w_f \\cdot sim(\\mathbf{q},\\mathbf{d}_f)$$ $$sim(\\mathbf{q},\\mathbf{d}_f) = f(\\mathbf{q},\\mathbf{d}_f) \\cdot ( \\frac{(\\mathbf{w}_{q}\\circ\\mathbf{q}) \\bullet \\mathbf{d}_f}{||(\\mathbf{w}_{q}\\circ\\mathbf{q})||} \\cdot f(\\mathbf{d}_f)) $$\n\n其中：\n> $\\circ$ 是[“阿达马乘积”](https://zh.wikipedia.org/wiki/%E7%9F%A9%E9%99%A3%E4%B9%98%E6%B3%95#.E7.B4.94.E9.87.8F.E4.B9.98.E7.A9.8D), \n> $\\bullet$ 是矩阵的“点积”, \n> $\\mathbf{q}$是查询$q$词元的tf-idf单位向量, \n> $\\mathbf{d}_f$是文档 $d$ 的域 $f$ 以向量$\\mathbf{q}$为基的tf-idf值向量,\n> $||\\mathbf{q}||$是向量$\\mathbf{q}$欧几里德范数\n> $\\mathbf{w}_q$是向量$\\mathbf{q}$中各个词元的权重向量\n\n具体的\n$$f(\\mathbf{q},\\mathbf{d}_f) = \\frac{|\\mathbf{q} \\cap \\mathbf{d}_f|}{|\\mathbf{q}|}$$$$tf_{t,d} = f_{t,d} ^\\frac{1}{2}$$$$idf_{t,d}= 1+ log(\\frac{|D|+1}{f_{t,D}+1})$$$$f(\\mathbf{d}_f) = t^{\\frac{1}{2}} \\cdot w_f$$\n考虑到Lucene允许在同一个文档中写入多个同名的域，所以$$w_f = \\prod w_{f,t}  $$\n\n## 优缺点\n\n##Elasticsearch 5 (Lucene 6) 的 BM25 算法\n\n## 评价指标Lucece","source":"_posts/Lucene-打分算法.md","raw":"---\ntitle: Lucene 打分算法\ndate: 2017-04-20 17:27:34\ntags: Lucene\ncategories: 算法\n---\n## Lucene是什么\n\nLucene 是一个基于 Java 的全文信息检索工具包，它不是一个完整的搜索应用程序，而是为你的应用程序提供索引和搜索功能。Lucene 目前是 Apache Jakarta 家族中的一个开源项目。也是目前最为流行的基于 Java 开源全文检索工具包。\n\nLucene总的来说是：\n\n* 一个高效的，可扩展的，全文检索库。\n* 全部用Java实现，同时提供python接口（pylucene)。\n* 仅支持纯文本文件的索引(Indexing)和搜索(Search)。\n\n## Lucene数学模型\n\n### 文档，域(字段)，词元\n\n文档是Lucene搜索和索引的原子单位，文档为包含一个或者多个域(字段)的容器，而域(字段)则是依次包含“真正的”被搜索的内容，域(字段)值通过分词技术处理，得到多个词元。\n\n举个栗子，一篇小说（斗破苍穹）信息可以称为一个文档，小说信息又包含多个域(字段)，例如：标题（斗破苍穹）、作者、简介、最后更新时间等等，对标题这个域(字段)采用分词技术又可以得到一个或者多个词元（斗、破、苍、穹）。\n\n## Lucene检索过程\n\n![](/images/LuceneSearch.jpg)\n\n## 打分算法\n\n### BIR（布尔模型）\n\n布尔逻辑将是建立最早的模型，也是目前应用最广泛的检索技术。它是通过布尔逻辑运算符：逻辑与（AND），逻辑或（OR），逻辑非（NOT）的组合来表达用户的检索需求。布尔逻辑是乔治·布尔在19 世纪中期定义的代数系统。1957 年，巴·希列尔最先探讨了将布尔逻辑应用到计算机检索的可能性。上世界 6，70 年代，布尔检索模型被正式用于各类文献系统并且逐步成为商业标准，这种模型并不提供任何的文档相关性测度，对于文档与查询的评价就只有“匹配”，“不匹配”两种而已，用户必须详细的规划自己的查询。\n\n### TF-IDF（词频-反词频）\n\n本质上，TF-IDF通过确定特定文档中的单词的相对频率与该单词在整个文档语料库中的反比例相比较起作用。 直观地，该计算确定给定单词在特定文档中的相关性。 在一个单一或一小组文件中不常见的单词往往比普通单词（如冠词和介词）具有更高的TF-IDF值。不同的情景下实现的TF-IDF有一些微小不同的地方，但是总体上计算的方式如下：\n给定一个稳定集合$D$，一个单词 $w$ 和一个文档 $d \\in D$,我们计算$$\\mathcal{W}_d=f_{w,d}*log(\\frac{|D|}{f_{w,D}})$$其中 $f_{w,d}$ 等于词 $w$ 在文档 $d$ 中出现的次数，$|D|$是文档全集的大小, $f_{w,D}$ 是词 $w$ 在全集中出现的次数(Salton & Buckley, 1988, Berger, et al, 2000)。假设$|D|\\thicksim f_{w,d}$,即语料库的大小大接近于$w$在集合$D$的频率，对于一些非常小的常数$c$，满足 $1 < log(\\frac{|D|}{f_{w,D}}) < c$ ,那么$w$将会比$f_{w,d}$小但是仍然是正的,这意味着$w$在整个语料库中比较常见，但在整个$D$句中仍然保持一定的重要性，例如TF-IDF在《新约》中的测试“Jesus”，就会是这种情况，与我们更加相关的例子在联合国文档的语料中“united”的结果可以预期到也是这种情况。对于非常常见的词语也是如此，例如冠词，代词和介词，它们本身在查询中没有任何相关的含义（除非用户明确要求含有这样的常用单词的文档）。 因此，这样的常用词得到非常低的TF-IDF分数，使得它们在搜索中基本上可以忽略不计。假设$f_{w,d}$非常大，$f_{w,D}$很小，那么$log(\\frac{|D|}{f_{w,D}})$将会变得相当大，所以$w_d$同样会很大，因为具有高$w_d$的词意味着$w$是$d$中的重要词，而在$D$中不常见。这个词被认为具有很大的有辨识力的。\n\n\n### VSM（向量空间模型）\n\n![](/images/vsm.jpg)\n向量空间模型 (VSM：Vector Space Model) 是一个应用于信息过滤, 信息撷取, 索引以及评估相关性的代数模型。由Salton等人于60年代提出，并成功地应用于著名的SMART文本检索系统。文件(语料)被视为索引词(关键字)形成的多次元向量空间， 索引词的集合通常为文件中至少出现过一次的词组。在文本检索中，文档与查询词可以表示为以下向量空间模型[1] :$$d_j = (w_{1,j},w_{2,j},…,w_{t,j})$$$$\nq = (w_{1,q},w_{2,q},…,w_{t,q})$$\n \n据文档相似度理论的假设，如要在一次关键词查询中计算各文档间的相关排序，只需比较每个文档向量和原先查询向量（跟文档向量的类型是相同的）之间的角度偏差。\n实际上，计算向量之间夹角的余弦比直接计算夹角本身要简单。\n$${\\displaystyle \\cos {\\theta }={\\frac {\\mathbf {d} \\cdot \\mathbf {q} }{\\left\\|\\mathbf {d} \\right\\|\\left\\|\\mathbf {q} \\right\\|}}}$$\n其中 ${\\displaystyle \\mathbf {d_{2}} \\cdot \\mathbf {q} }$是文档向量（即上 图中的d2）和查询向量（图中的q）的点乘。 ${\\displaystyle \\left\\|\\mathbf {d_{2}} \\right\\|}$是向量d2的模，而 ${\\displaystyle \\left\\|\\mathbf {q} \\right\\|}$是向量q的模。向量的模通过下面的公式来计算：\n$${\\displaystyle \\left\\|\\mathbf {v} \\right\\|={\\sqrt {\\sum _{i=1}^{n}v_{i}^{2}}}}$$\n由于这个模型所考虑的所有向量都是每个元素严格非负的，因此如果余弦值为零，则表示查询向量和文档向量是正交的，即不符合（换句话说，就是检索项在文档中没有找到）\n  \n\n### Lucene打分模型\nLucene计算公式是对BIR，TF-IDF和vsm的一个综合使用和改进。首先采用BIR的方法把所有匹配的文档取出作为一个匹配文档集合，然后再用改进的VSM算法对这些文档进行排序，事实上由于Lucene是基于域的，所以的检索过程都是基于域的计算，最后按照域的权重求和得到最终的文档分数。VSM构建词向量的方式有很多种，其中比较有名的就是通过TF-IDF来构建，$w_{i,j}$通过计算文档$d_j$中$i$词在的TF-IDF值,虽然获得了词向量构建方法,但是会遇到查询$q$的维度远远小于文档$d_j$的问题，只需要以$q$的维度作为标准，文档$d_j$只在该基中映射。\n\n按照原始的VSM模型，余弦的计算可以看做是2个归一化的向量内积，但是在实际应用中会遇到一些问题，显而易见的就是丢失了文档的长度信息，举个例子：\n\n文档1：i think that\n文档2：”I think it’s unlikely to be a real thing. I’m sure it’s an overreaction about an already-skittish party,” Roberts said. “They have looked at what happens in that circumstance.”, hello, i love the word.\n查询“think”，那么按照原始的VSM返回的相似度是一样的。但是显然搜索的目的应该是偏向文档1的，为了解决这个问题，Lucene引入了一个和长度相关的归一化方法 $f(\\mathbf{d}_f)$ 所以改进后的VSM如下：$${\\displaystyle sim(\\mathbf{q},\\mathbf{d}_f)={\\frac {\\mathbf {q} \\cdot \\mathbf {d}_f }{\\left\\|\\mathbf {q} \\right\\|}}}*f(\\mathbf{d}_f)$$\n接下来考虑一些更加定制化的内容：\n\n1. 我们可能会在系统中规定哪些文档是更加重要的，比如相对房地产平台销冠来说楼盘详细信息的文档就会比楼盘的小道消息重要，在查询楼盘的时候我们希望楼盘详细信息会出现在小道消息前面，我们可以通过给文档一个分数来定义文档的重要性计做$w_{d}$\n2. 同样的考虑到查询的关键字重要性定制化，我们引入查询权重向量计做$\\mathbf{w}_{q}$\n3. Lucene是基于域的,所有的检索过程都是在域的尺度进行的，所以不同的域可以有相应的权重计做$w_{f}$\n4. 最后考虑到查询和域的匹配度，引入函数 $f(\\mathbf{q},\\mathbf{d}_f)$ （关于查询向量$\\mathbf{q}$和文档$\\mathbf{d}$ 域 $f$ 向量的函数） \n\n于是我们得到计算分数公式如下：\n$$sim(\\mathbf{q}, \\mathbf{d}) = w_d \\cdot \\sum_{f \\in d}w_f \\cdot sim(\\mathbf{q},\\mathbf{d}_f)$$ $$sim(\\mathbf{q},\\mathbf{d}_f) = f(\\mathbf{q},\\mathbf{d}_f) \\cdot ( \\frac{(\\mathbf{w}_{q}\\circ\\mathbf{q}) \\bullet \\mathbf{d}_f}{||(\\mathbf{w}_{q}\\circ\\mathbf{q})||} \\cdot f(\\mathbf{d}_f)) $$\n\n其中：\n> $\\circ$ 是[“阿达马乘积”](https://zh.wikipedia.org/wiki/%E7%9F%A9%E9%99%A3%E4%B9%98%E6%B3%95#.E7.B4.94.E9.87.8F.E4.B9.98.E7.A9.8D), \n> $\\bullet$ 是矩阵的“点积”, \n> $\\mathbf{q}$是查询$q$词元的tf-idf单位向量, \n> $\\mathbf{d}_f$是文档 $d$ 的域 $f$ 以向量$\\mathbf{q}$为基的tf-idf值向量,\n> $||\\mathbf{q}||$是向量$\\mathbf{q}$欧几里德范数\n> $\\mathbf{w}_q$是向量$\\mathbf{q}$中各个词元的权重向量\n\n具体的\n$$f(\\mathbf{q},\\mathbf{d}_f) = \\frac{|\\mathbf{q} \\cap \\mathbf{d}_f|}{|\\mathbf{q}|}$$$$tf_{t,d} = f_{t,d} ^\\frac{1}{2}$$$$idf_{t,d}= 1+ log(\\frac{|D|+1}{f_{t,D}+1})$$$$f(\\mathbf{d}_f) = t^{\\frac{1}{2}} \\cdot w_f$$\n考虑到Lucene允许在同一个文档中写入多个同名的域，所以$$w_f = \\prod w_{f,t}  $$\n\n## 优缺点\n\n##Elasticsearch 5 (Lucene 6) 的 BM25 算法\n\n## 评价指标Lucece","slug":"Lucene-打分算法","published":1,"updated":"2017-09-28T10:52:58.658Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8cgqo7200003szye8lnellf","content":"<h2 id=\"lucene是什么\">Lucene是什么</h2>\n<p>Lucene 是一个基于 Java 的全文信息检索工具包，它不是一个完整的搜索应用程序，而是为你的应用程序提供索引和搜索功能。Lucene 目前是 Apache Jakarta 家族中的一个开源项目。也是目前最为流行的基于 Java 开源全文检索工具包。</p>\n<p>Lucene总的来说是：</p>\n<ul>\n<li>一个高效的，可扩展的，全文检索库。</li>\n<li>全部用Java实现，同时提供python接口（pylucene)。</li>\n<li>仅支持纯文本文件的索引(Indexing)和搜索(Search)。</li>\n</ul>\n<h2 id=\"lucene数学模型\">Lucene数学模型</h2>\n<h3 id=\"文档域字段词元\">文档，域(字段)，词元</h3>\n<p>文档是Lucene搜索和索引的原子单位，文档为包含一个或者多个域(字段)的容器，而域(字段)则是依次包含“真正的”被搜索的内容，域(字段)值通过分词技术处理，得到多个词元。</p>\n<p>举个栗子，一篇小说（斗破苍穹）信息可以称为一个文档，小说信息又包含多个域(字段)，例如：标题（斗破苍穹）、作者、简介、最后更新时间等等，对标题这个域(字段)采用分词技术又可以得到一个或者多个词元（斗、破、苍、穹）。</p>\n<h2 id=\"lucene检索过程\">Lucene检索过程</h2>\n<div class=\"figure\">\n<img src=\"/images/LuceneSearch.jpg\" />\n\n</div>\n<h2 id=\"打分算法\">打分算法</h2>\n<h3 id=\"bir布尔模型\">BIR（布尔模型）</h3>\n<p>布尔逻辑将是建立最早的模型，也是目前应用最广泛的检索技术。它是通过布尔逻辑运算符：逻辑与（AND），逻辑或（OR），逻辑非（NOT）的组合来表达用户的检索需求。布尔逻辑是乔治·布尔在19 世纪中期定义的代数系统。1957 年，巴·希列尔最先探讨了将布尔逻辑应用到计算机检索的可能性。上世界 6，70 年代，布尔检索模型被正式用于各类文献系统并且逐步成为商业标准，这种模型并不提供任何的文档相关性测度，对于文档与查询的评价就只有“匹配”，“不匹配”两种而已，用户必须详细的规划自己的查询。</p>\n<h3 id=\"tf-idf词频-反词频\">TF-IDF（词频-反词频）</h3>\n<p>本质上，TF-IDF通过确定特定文档中的单词的相对频率与该单词在整个文档语料库中的反比例相比较起作用。 直观地，该计算确定给定单词在特定文档中的相关性。 在一个单一或一小组文件中不常见的单词往往比普通单词（如冠词和介词）具有更高的TF-IDF值。不同的情景下实现的TF-IDF有一些微小不同的地方，但是总体上计算的方式如下： 给定一个稳定集合<span class=\"math inline\">\\(D\\)</span>，一个单词 <span class=\"math inline\">\\(w\\)</span> 和一个文档 <span class=\"math inline\">\\(d \\in D\\)</span>,我们计算<span class=\"math display\">\\[\\mathcal{W}_d=f_{w,d}*log(\\frac{|D|}{f_{w,D}})\\]</span>其中 <span class=\"math inline\">\\(f_{w,d}\\)</span> 等于词 <span class=\"math inline\">\\(w\\)</span> 在文档 <span class=\"math inline\">\\(d\\)</span> 中出现的次数，<span class=\"math inline\">\\(|D|\\)</span>是文档全集的大小, <span class=\"math inline\">\\(f_{w,D}\\)</span> 是词 <span class=\"math inline\">\\(w\\)</span> 在全集中出现的次数(Salton &amp; Buckley, 1988, Berger, et al, 2000)。假设<span class=\"math inline\">\\(|D|\\thicksim f_{w,d}\\)</span>,即语料库的大小大接近于<span class=\"math inline\">\\(w\\)</span>在集合<span class=\"math inline\">\\(D\\)</span>的频率，对于一些非常小的常数<span class=\"math inline\">\\(c\\)</span>，满足 <span class=\"math inline\">\\(1 &lt; log(\\frac{|D|}{f_{w,D}}) &lt; c\\)</span> ,那么<span class=\"math inline\">\\(w\\)</span>将会比<span class=\"math inline\">\\(f_{w,d}\\)</span>小但是仍然是正的,这意味着<span class=\"math inline\">\\(w\\)</span>在整个语料库中比较常见，但在整个<span class=\"math inline\">\\(D\\)</span>句中仍然保持一定的重要性，例如TF-IDF在《新约》中的测试“Jesus”，就会是这种情况，与我们更加相关的例子在联合国文档的语料中“united”的结果可以预期到也是这种情况。对于非常常见的词语也是如此，例如冠词，代词和介词，它们本身在查询中没有任何相关的含义（除非用户明确要求含有这样的常用单词的文档）。 因此，这样的常用词得到非常低的TF-IDF分数，使得它们在搜索中基本上可以忽略不计。假设<span class=\"math inline\">\\(f_{w,d}\\)</span>非常大，<span class=\"math inline\">\\(f_{w,D}\\)</span>很小，那么<span class=\"math inline\">\\(log(\\frac{|D|}{f_{w,D}})\\)</span>将会变得相当大，所以<span class=\"math inline\">\\(w_d\\)</span>同样会很大，因为具有高<span class=\"math inline\">\\(w_d\\)</span>的词意味着<span class=\"math inline\">\\(w\\)</span>是<span class=\"math inline\">\\(d\\)</span>中的重要词，而在<span class=\"math inline\">\\(D\\)</span>中不常见。这个词被认为具有很大的有辨识力的。</p>\n<h3 id=\"vsm向量空间模型\">VSM（向量空间模型）</h3>\n<p><img src=\"/images/vsm.jpg\" /> 向量空间模型 (VSM：Vector Space Model) 是一个应用于信息过滤, 信息撷取, 索引以及评估相关性的代数模型。由Salton等人于60年代提出，并成功地应用于著名的SMART文本检索系统。文件(语料)被视为索引词(关键字)形成的多次元向量空间， 索引词的集合通常为文件中至少出现过一次的词组。在文本检索中，文档与查询词可以表示为以下向量空间模型[1] :<span class=\"math display\">\\[d_j = (w_{1,j},w_{2,j},…,w_{t,j})\\]</span><span class=\"math display\">\\[\nq = (w_{1,q},w_{2,q},…,w_{t,q})\\]</span></p>\n<p>据文档相似度理论的假设，如要在一次关键词查询中计算各文档间的相关排序，只需比较每个文档向量和原先查询向量（跟文档向量的类型是相同的）之间的角度偏差。 实际上，计算向量之间夹角的余弦比直接计算夹角本身要简单。 <span class=\"math display\">\\[{\\displaystyle \\cos {\\theta }={\\frac {\\mathbf {d} \\cdot \\mathbf {q} }{\\left\\|\\mathbf {d} \\right\\|\\left\\|\\mathbf {q} \\right\\|}}}\\]</span> 其中 <span class=\"math inline\">\\({\\displaystyle \\mathbf {d_{2}} \\cdot \\mathbf {q} }\\)</span>是文档向量（即上 图中的d2）和查询向量（图中的q）的点乘。 <span class=\"math inline\">\\({\\displaystyle \\left\\|\\mathbf {d_{2}} \\right\\|}\\)</span>是向量d2的模，而 <span class=\"math inline\">\\({\\displaystyle \\left\\|\\mathbf {q} \\right\\|}\\)</span>是向量q的模。向量的模通过下面的公式来计算： <span class=\"math display\">\\[{\\displaystyle \\left\\|\\mathbf {v} \\right\\|={\\sqrt {\\sum _{i=1}^{n}v_{i}^{2}}}}\\]</span> 由于这个模型所考虑的所有向量都是每个元素严格非负的，因此如果余弦值为零，则表示查询向量和文档向量是正交的，即不符合（换句话说，就是检索项在文档中没有找到）</p>\n<h3 id=\"lucene打分模型\">Lucene打分模型</h3>\n<p>Lucene计算公式是对BIR，TF-IDF和vsm的一个综合使用和改进。首先采用BIR的方法把所有匹配的文档取出作为一个匹配文档集合，然后再用改进的VSM算法对这些文档进行排序，事实上由于Lucene是基于域的，所以的检索过程都是基于域的计算，最后按照域的权重求和得到最终的文档分数。VSM构建词向量的方式有很多种，其中比较有名的就是通过TF-IDF来构建，<span class=\"math inline\">\\(w_{i,j}\\)</span>通过计算文档<span class=\"math inline\">\\(d_j\\)</span>中<span class=\"math inline\">\\(i\\)</span>词在的TF-IDF值,虽然获得了词向量构建方法,但是会遇到查询<span class=\"math inline\">\\(q\\)</span>的维度远远小于文档<span class=\"math inline\">\\(d_j\\)</span>的问题，只需要以<span class=\"math inline\">\\(q\\)</span>的维度作为标准，文档<span class=\"math inline\">\\(d_j\\)</span>只在该基中映射。</p>\n<p>按照原始的VSM模型，余弦的计算可以看做是2个归一化的向量内积，但是在实际应用中会遇到一些问题，显而易见的就是丢失了文档的长度信息，举个例子：</p>\n<p>文档1：i think that 文档2：”I think it’s unlikely to be a real thing. I’m sure it’s an overreaction about an already-skittish party,” Roberts said. “They have looked at what happens in that circumstance.”, hello, i love the word. 查询“think”，那么按照原始的VSM返回的相似度是一样的。但是显然搜索的目的应该是偏向文档1的，为了解决这个问题，Lucene引入了一个和长度相关的归一化方法 <span class=\"math inline\">\\(f(\\mathbf{d}_f)\\)</span> 所以改进后的VSM如下：<span class=\"math display\">\\[{\\displaystyle sim(\\mathbf{q},\\mathbf{d}_f)={\\frac {\\mathbf {q} \\cdot \\mathbf {d}_f }{\\left\\|\\mathbf {q} \\right\\|}}}*f(\\mathbf{d}_f)\\]</span> 接下来考虑一些更加定制化的内容：</p>\n<ol style=\"list-style-type: decimal\">\n<li>我们可能会在系统中规定哪些文档是更加重要的，比如相对房地产平台销冠来说楼盘详细信息的文档就会比楼盘的小道消息重要，在查询楼盘的时候我们希望楼盘详细信息会出现在小道消息前面，我们可以通过给文档一个分数来定义文档的重要性计做<span class=\"math inline\">\\(w_{d}\\)</span></li>\n<li>同样的考虑到查询的关键字重要性定制化，我们引入查询权重向量计做<span class=\"math inline\">\\(\\mathbf{w}_{q}\\)</span></li>\n<li>Lucene是基于域的,所有的检索过程都是在域的尺度进行的，所以不同的域可以有相应的权重计做<span class=\"math inline\">\\(w_{f}\\)</span></li>\n<li>最后考虑到查询和域的匹配度，引入函数 <span class=\"math inline\">\\(f(\\mathbf{q},\\mathbf{d}_f)\\)</span> （关于查询向量<span class=\"math inline\">\\(\\mathbf{q}\\)</span>和文档<span class=\"math inline\">\\(\\mathbf{d}\\)</span> 域 <span class=\"math inline\">\\(f\\)</span> 向量的函数）</li>\n</ol>\n<p>于是我们得到计算分数公式如下： <span class=\"math display\">\\[sim(\\mathbf{q}, \\mathbf{d}) = w_d \\cdot \\sum_{f \\in d}w_f \\cdot sim(\\mathbf{q},\\mathbf{d}_f)\\]</span> <span class=\"math display\">\\[sim(\\mathbf{q},\\mathbf{d}_f) = f(\\mathbf{q},\\mathbf{d}_f) \\cdot ( \\frac{(\\mathbf{w}_{q}\\circ\\mathbf{q}) \\bullet \\mathbf{d}_f}{||(\\mathbf{w}_{q}\\circ\\mathbf{q})||} \\cdot f(\\mathbf{d}_f)) \\]</span></p>\n<p>其中： &gt; <span class=\"math inline\">\\(\\circ\\)</span> 是<a href=\"https://zh.wikipedia.org/wiki/%E7%9F%A9%E9%99%A3%E4%B9%98%E6%B3%95#.E7.B4.94.E9.87.8F.E4.B9.98.E7.A9.8D\" target=\"_blank\" rel=\"noopener\">“阿达马乘积”</a>, &gt; <span class=\"math inline\">\\(\\bullet\\)</span> 是矩阵的“点积”, &gt; <span class=\"math inline\">\\(\\mathbf{q}\\)</span>是查询<span class=\"math inline\">\\(q\\)</span>词元的tf-idf单位向量, &gt; <span class=\"math inline\">\\(\\mathbf{d}_f\\)</span>是文档 <span class=\"math inline\">\\(d\\)</span> 的域 <span class=\"math inline\">\\(f\\)</span> 以向量<span class=\"math inline\">\\(\\mathbf{q}\\)</span>为基的tf-idf值向量, &gt; <span class=\"math inline\">\\(||\\mathbf{q}||\\)</span>是向量<span class=\"math inline\">\\(\\mathbf{q}\\)</span>欧几里德范数 &gt; <span class=\"math inline\">\\(\\mathbf{w}_q\\)</span>是向量<span class=\"math inline\">\\(\\mathbf{q}\\)</span>中各个词元的权重向量</p>\n<p>具体的 <span class=\"math display\">\\[f(\\mathbf{q},\\mathbf{d}_f) = \\frac{|\\mathbf{q} \\cap \\mathbf{d}_f|}{|\\mathbf{q}|}\\]</span><span class=\"math display\">\\[tf_{t,d} = f_{t,d} ^\\frac{1}{2}\\]</span><span class=\"math display\">\\[idf_{t,d}= 1+ log(\\frac{|D|+1}{f_{t,D}+1})\\]</span><span class=\"math display\">\\[f(\\mathbf{d}_f) = t^{\\frac{1}{2}} \\cdot w_f\\]</span> 考虑到Lucene允许在同一个文档中写入多个同名的域，所以<span class=\"math display\">\\[w_f = \\prod w_{f,t}  \\]</span></p>\n<h2 id=\"优缺点\">优缺点</h2>\n<h2 id=\"elasticsearch-5-lucene-6-的-bm25-算法\">Elasticsearch 5 (Lucene 6) 的 BM25 算法</h2>\n<h2 id=\"评价指标lucece\">评价指标Lucece</h2>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"lucene是什么\">Lucene是什么</h2>\n<p>Lucene 是一个基于 Java 的全文信息检索工具包，它不是一个完整的搜索应用程序，而是为你的应用程序提供索引和搜索功能。Lucene 目前是 Apache Jakarta 家族中的一个开源项目。也是目前最为流行的基于 Java 开源全文检索工具包。</p>\n<p>Lucene总的来说是：</p>\n<ul>\n<li>一个高效的，可扩展的，全文检索库。</li>\n<li>全部用Java实现，同时提供python接口（pylucene)。</li>\n<li>仅支持纯文本文件的索引(Indexing)和搜索(Search)。</li>\n</ul>\n<h2 id=\"lucene数学模型\">Lucene数学模型</h2>\n<h3 id=\"文档域字段词元\">文档，域(字段)，词元</h3>\n<p>文档是Lucene搜索和索引的原子单位，文档为包含一个或者多个域(字段)的容器，而域(字段)则是依次包含“真正的”被搜索的内容，域(字段)值通过分词技术处理，得到多个词元。</p>\n<p>举个栗子，一篇小说（斗破苍穹）信息可以称为一个文档，小说信息又包含多个域(字段)，例如：标题（斗破苍穹）、作者、简介、最后更新时间等等，对标题这个域(字段)采用分词技术又可以得到一个或者多个词元（斗、破、苍、穹）。</p>\n<h2 id=\"lucene检索过程\">Lucene检索过程</h2>\n<div class=\"figure\">\n<img src=\"/images/LuceneSearch.jpg\" />\n\n</div>\n<h2 id=\"打分算法\">打分算法</h2>\n<h3 id=\"bir布尔模型\">BIR（布尔模型）</h3>\n<p>布尔逻辑将是建立最早的模型，也是目前应用最广泛的检索技术。它是通过布尔逻辑运算符：逻辑与（AND），逻辑或（OR），逻辑非（NOT）的组合来表达用户的检索需求。布尔逻辑是乔治·布尔在19 世纪中期定义的代数系统。1957 年，巴·希列尔最先探讨了将布尔逻辑应用到计算机检索的可能性。上世界 6，70 年代，布尔检索模型被正式用于各类文献系统并且逐步成为商业标准，这种模型并不提供任何的文档相关性测度，对于文档与查询的评价就只有“匹配”，“不匹配”两种而已，用户必须详细的规划自己的查询。</p>\n<h3 id=\"tf-idf词频-反词频\">TF-IDF（词频-反词频）</h3>\n<p>本质上，TF-IDF通过确定特定文档中的单词的相对频率与该单词在整个文档语料库中的反比例相比较起作用。 直观地，该计算确定给定单词在特定文档中的相关性。 在一个单一或一小组文件中不常见的单词往往比普通单词（如冠词和介词）具有更高的TF-IDF值。不同的情景下实现的TF-IDF有一些微小不同的地方，但是总体上计算的方式如下： 给定一个稳定集合<span class=\"math inline\">\\(D\\)</span>，一个单词 <span class=\"math inline\">\\(w\\)</span> 和一个文档 <span class=\"math inline\">\\(d \\in D\\)</span>,我们计算<span class=\"math display\">\\[\\mathcal{W}_d=f_{w,d}*log(\\frac{|D|}{f_{w,D}})\\]</span>其中 <span class=\"math inline\">\\(f_{w,d}\\)</span> 等于词 <span class=\"math inline\">\\(w\\)</span> 在文档 <span class=\"math inline\">\\(d\\)</span> 中出现的次数，<span class=\"math inline\">\\(|D|\\)</span>是文档全集的大小, <span class=\"math inline\">\\(f_{w,D}\\)</span> 是词 <span class=\"math inline\">\\(w\\)</span> 在全集中出现的次数(Salton &amp; Buckley, 1988, Berger, et al, 2000)。假设<span class=\"math inline\">\\(|D|\\thicksim f_{w,d}\\)</span>,即语料库的大小大接近于<span class=\"math inline\">\\(w\\)</span>在集合<span class=\"math inline\">\\(D\\)</span>的频率，对于一些非常小的常数<span class=\"math inline\">\\(c\\)</span>，满足 <span class=\"math inline\">\\(1 &lt; log(\\frac{|D|}{f_{w,D}}) &lt; c\\)</span> ,那么<span class=\"math inline\">\\(w\\)</span>将会比<span class=\"math inline\">\\(f_{w,d}\\)</span>小但是仍然是正的,这意味着<span class=\"math inline\">\\(w\\)</span>在整个语料库中比较常见，但在整个<span class=\"math inline\">\\(D\\)</span>句中仍然保持一定的重要性，例如TF-IDF在《新约》中的测试“Jesus”，就会是这种情况，与我们更加相关的例子在联合国文档的语料中“united”的结果可以预期到也是这种情况。对于非常常见的词语也是如此，例如冠词，代词和介词，它们本身在查询中没有任何相关的含义（除非用户明确要求含有这样的常用单词的文档）。 因此，这样的常用词得到非常低的TF-IDF分数，使得它们在搜索中基本上可以忽略不计。假设<span class=\"math inline\">\\(f_{w,d}\\)</span>非常大，<span class=\"math inline\">\\(f_{w,D}\\)</span>很小，那么<span class=\"math inline\">\\(log(\\frac{|D|}{f_{w,D}})\\)</span>将会变得相当大，所以<span class=\"math inline\">\\(w_d\\)</span>同样会很大，因为具有高<span class=\"math inline\">\\(w_d\\)</span>的词意味着<span class=\"math inline\">\\(w\\)</span>是<span class=\"math inline\">\\(d\\)</span>中的重要词，而在<span class=\"math inline\">\\(D\\)</span>中不常见。这个词被认为具有很大的有辨识力的。</p>\n<h3 id=\"vsm向量空间模型\">VSM（向量空间模型）</h3>\n<p><img src=\"/images/vsm.jpg\" /> 向量空间模型 (VSM：Vector Space Model) 是一个应用于信息过滤, 信息撷取, 索引以及评估相关性的代数模型。由Salton等人于60年代提出，并成功地应用于著名的SMART文本检索系统。文件(语料)被视为索引词(关键字)形成的多次元向量空间， 索引词的集合通常为文件中至少出现过一次的词组。在文本检索中，文档与查询词可以表示为以下向量空间模型[1] :<span class=\"math display\">\\[d_j = (w_{1,j},w_{2,j},…,w_{t,j})\\]</span><span class=\"math display\">\\[\nq = (w_{1,q},w_{2,q},…,w_{t,q})\\]</span></p>\n<p>据文档相似度理论的假设，如要在一次关键词查询中计算各文档间的相关排序，只需比较每个文档向量和原先查询向量（跟文档向量的类型是相同的）之间的角度偏差。 实际上，计算向量之间夹角的余弦比直接计算夹角本身要简单。 <span class=\"math display\">\\[{\\displaystyle \\cos {\\theta }={\\frac {\\mathbf {d} \\cdot \\mathbf {q} }{\\left\\|\\mathbf {d} \\right\\|\\left\\|\\mathbf {q} \\right\\|}}}\\]</span> 其中 <span class=\"math inline\">\\({\\displaystyle \\mathbf {d_{2}} \\cdot \\mathbf {q} }\\)</span>是文档向量（即上 图中的d2）和查询向量（图中的q）的点乘。 <span class=\"math inline\">\\({\\displaystyle \\left\\|\\mathbf {d_{2}} \\right\\|}\\)</span>是向量d2的模，而 <span class=\"math inline\">\\({\\displaystyle \\left\\|\\mathbf {q} \\right\\|}\\)</span>是向量q的模。向量的模通过下面的公式来计算： <span class=\"math display\">\\[{\\displaystyle \\left\\|\\mathbf {v} \\right\\|={\\sqrt {\\sum _{i=1}^{n}v_{i}^{2}}}}\\]</span> 由于这个模型所考虑的所有向量都是每个元素严格非负的，因此如果余弦值为零，则表示查询向量和文档向量是正交的，即不符合（换句话说，就是检索项在文档中没有找到）</p>\n<h3 id=\"lucene打分模型\">Lucene打分模型</h3>\n<p>Lucene计算公式是对BIR，TF-IDF和vsm的一个综合使用和改进。首先采用BIR的方法把所有匹配的文档取出作为一个匹配文档集合，然后再用改进的VSM算法对这些文档进行排序，事实上由于Lucene是基于域的，所以的检索过程都是基于域的计算，最后按照域的权重求和得到最终的文档分数。VSM构建词向量的方式有很多种，其中比较有名的就是通过TF-IDF来构建，<span class=\"math inline\">\\(w_{i,j}\\)</span>通过计算文档<span class=\"math inline\">\\(d_j\\)</span>中<span class=\"math inline\">\\(i\\)</span>词在的TF-IDF值,虽然获得了词向量构建方法,但是会遇到查询<span class=\"math inline\">\\(q\\)</span>的维度远远小于文档<span class=\"math inline\">\\(d_j\\)</span>的问题，只需要以<span class=\"math inline\">\\(q\\)</span>的维度作为标准，文档<span class=\"math inline\">\\(d_j\\)</span>只在该基中映射。</p>\n<p>按照原始的VSM模型，余弦的计算可以看做是2个归一化的向量内积，但是在实际应用中会遇到一些问题，显而易见的就是丢失了文档的长度信息，举个例子：</p>\n<p>文档1：i think that 文档2：”I think it’s unlikely to be a real thing. I’m sure it’s an overreaction about an already-skittish party,” Roberts said. “They have looked at what happens in that circumstance.”, hello, i love the word. 查询“think”，那么按照原始的VSM返回的相似度是一样的。但是显然搜索的目的应该是偏向文档1的，为了解决这个问题，Lucene引入了一个和长度相关的归一化方法 <span class=\"math inline\">\\(f(\\mathbf{d}_f)\\)</span> 所以改进后的VSM如下：<span class=\"math display\">\\[{\\displaystyle sim(\\mathbf{q},\\mathbf{d}_f)={\\frac {\\mathbf {q} \\cdot \\mathbf {d}_f }{\\left\\|\\mathbf {q} \\right\\|}}}*f(\\mathbf{d}_f)\\]</span> 接下来考虑一些更加定制化的内容：</p>\n<ol style=\"list-style-type: decimal\">\n<li>我们可能会在系统中规定哪些文档是更加重要的，比如相对房地产平台销冠来说楼盘详细信息的文档就会比楼盘的小道消息重要，在查询楼盘的时候我们希望楼盘详细信息会出现在小道消息前面，我们可以通过给文档一个分数来定义文档的重要性计做<span class=\"math inline\">\\(w_{d}\\)</span></li>\n<li>同样的考虑到查询的关键字重要性定制化，我们引入查询权重向量计做<span class=\"math inline\">\\(\\mathbf{w}_{q}\\)</span></li>\n<li>Lucene是基于域的,所有的检索过程都是在域的尺度进行的，所以不同的域可以有相应的权重计做<span class=\"math inline\">\\(w_{f}\\)</span></li>\n<li>最后考虑到查询和域的匹配度，引入函数 <span class=\"math inline\">\\(f(\\mathbf{q},\\mathbf{d}_f)\\)</span> （关于查询向量<span class=\"math inline\">\\(\\mathbf{q}\\)</span>和文档<span class=\"math inline\">\\(\\mathbf{d}\\)</span> 域 <span class=\"math inline\">\\(f\\)</span> 向量的函数）</li>\n</ol>\n<p>于是我们得到计算分数公式如下： <span class=\"math display\">\\[sim(\\mathbf{q}, \\mathbf{d}) = w_d \\cdot \\sum_{f \\in d}w_f \\cdot sim(\\mathbf{q},\\mathbf{d}_f)\\]</span> <span class=\"math display\">\\[sim(\\mathbf{q},\\mathbf{d}_f) = f(\\mathbf{q},\\mathbf{d}_f) \\cdot ( \\frac{(\\mathbf{w}_{q}\\circ\\mathbf{q}) \\bullet \\mathbf{d}_f}{||(\\mathbf{w}_{q}\\circ\\mathbf{q})||} \\cdot f(\\mathbf{d}_f)) \\]</span></p>\n<p>其中： &gt; <span class=\"math inline\">\\(\\circ\\)</span> 是<a href=\"https://zh.wikipedia.org/wiki/%E7%9F%A9%E9%99%A3%E4%B9%98%E6%B3%95#.E7.B4.94.E9.87.8F.E4.B9.98.E7.A9.8D\" target=\"_blank\" rel=\"noopener\">“阿达马乘积”</a>, &gt; <span class=\"math inline\">\\(\\bullet\\)</span> 是矩阵的“点积”, &gt; <span class=\"math inline\">\\(\\mathbf{q}\\)</span>是查询<span class=\"math inline\">\\(q\\)</span>词元的tf-idf单位向量, &gt; <span class=\"math inline\">\\(\\mathbf{d}_f\\)</span>是文档 <span class=\"math inline\">\\(d\\)</span> 的域 <span class=\"math inline\">\\(f\\)</span> 以向量<span class=\"math inline\">\\(\\mathbf{q}\\)</span>为基的tf-idf值向量, &gt; <span class=\"math inline\">\\(||\\mathbf{q}||\\)</span>是向量<span class=\"math inline\">\\(\\mathbf{q}\\)</span>欧几里德范数 &gt; <span class=\"math inline\">\\(\\mathbf{w}_q\\)</span>是向量<span class=\"math inline\">\\(\\mathbf{q}\\)</span>中各个词元的权重向量</p>\n<p>具体的 <span class=\"math display\">\\[f(\\mathbf{q},\\mathbf{d}_f) = \\frac{|\\mathbf{q} \\cap \\mathbf{d}_f|}{|\\mathbf{q}|}\\]</span><span class=\"math display\">\\[tf_{t,d} = f_{t,d} ^\\frac{1}{2}\\]</span><span class=\"math display\">\\[idf_{t,d}= 1+ log(\\frac{|D|+1}{f_{t,D}+1})\\]</span><span class=\"math display\">\\[f(\\mathbf{d}_f) = t^{\\frac{1}{2}} \\cdot w_f\\]</span> 考虑到Lucene允许在同一个文档中写入多个同名的域，所以<span class=\"math display\">\\[w_f = \\prod w_{f,t}  \\]</span></p>\n<h2 id=\"优缺点\">优缺点</h2>\n<h2 id=\"elasticsearch-5-lucene-6-的-bm25-算法\">Elasticsearch 5 (Lucene 6) 的 BM25 算法</h2>\n<h2 id=\"评价指标lucece\">评价指标Lucece</h2>\n"},{"title":"Apache NiFi简介","date":"2017-03-30T15:59:05.000Z","_content":"\n <img src=\"https://nifi.apache.org/assets/images/apache-nifi-logo.svg\" width = \"80%\" height = \"80%\" alt=\"图片名称\" align=center />\n\n## 1. 背景\n\n\n[Apache NiFi](https://nifi.apache.org/index.html)是由美国过国家安全局(NSA)贡献给Apache基金会的开源项目，其设计目标是自动化系统间的数据流。2015年7月20日，Apache 基金会通过其博客宣布Apache NiFi顺利孵化完成称为Apache的顶级项目之一。NiFi初始的项目名称是Niagarafiles，当NiFi项目开源之后，一些早先在NSA（美国国家安全局）的开发者们创立了初创公司Onyara，Onyara随之继续NiFi项目的开发并提供相关的支持。[Hortonworks](https://hortonworks.com/)公司最近收购了Onyara并将其开发者整合到自己的团队中。apache nifi 也成为了Hortonworks进军物联网的利器。\n\n##2. nifi是什么\n\n简单的来说nifi的建立是为了使各个系统之间的”数据流“自动化，“数据流”这个词代表着多种含义，这里提到的数据流特指自动化和可管理的信息流。自从企业中出现多个系统之后，要面临的首要任务是解决数据生产系统与数据处理系统之间的数据处理流。自从这个问题面世以来，人们已经广泛的探讨了解决方案，其中[《Enterprise Integration Patterns》](http://www.enterpriseintegrationpatterns.com/)一书提出一个全面可行的消息消费方式。\n对于数据流来说主要面临以下几个大方面的挑战：\n\n- **系统故障（System fail）**\n    包括但不限于：网络故障，硬盘故障，软件崩溃，人为失误\n- **数据处理瓶颈**\n    有时，数据源头产生数据的速度远远超过数据处理和数据传输的速度，此时整个系统有一个很严重的瓶颈。\n- **异常数据处理**\n    您将始终收到太大，太小，太快，太慢，损坏，错误或格式错误的数据。\n- **业务快速演进**\n   快速数据处理业务的调整，新业务流程和原有业务升级改造\n- **多系统升级不同步引入的前后兼容** \n  原有系统的协议和数据格式，会伴随系统的升级有一定的调整，同时单个系统的升级会影响周边系统。数据流可以把多个大型分布式系统串边在一起，这些系统可以是松散地，甚至设计之初就没考虑未来地集成\n- **兼容性和安全性**\n 法律法规的变更，规章制度的变动，以及政策调整，业务合同的变更。系统和系统之间，系统和用户接口之间要安全，可信和权责分明。\n- **生产环境平滑升级**\n    在实验验证环境很难复制生产环境\n\n多年以来，数据流已经成为一种架构中必不可少的恶性循环之一。 现在虽然有一些积极和快速发展的运动，使得数据流更有趣，对于给定企业的成功更为重要。 这些包括像 面向服务的架构[soa](http://en.wikipedia.org/wiki/Service-oriented_architecture]，API [api][http://www.forbes.com/sites/ciocentral/2012/08/29/welcome-to-the-api-economy/) [api2](http://thenextweb.com/dd/2014/03/28/api-economy/)，物联网[iot](http://en.wikipedia.org/wiki/Internet_of_Things)以及Big Data [bigdata](http://en.wikipedia.org/wiki/Big_data)的兴起。 此外，合规性，隐私性和安全性所需的严谨程度不断增加。 即使仍然存在所有这些新概念，数据流的模式和需求仍然基本相同。 主要的区别在于复杂性的范围，适应需要的变化率，以及边缘情况在一般情况下是常见的情况。 NiFi旨在帮助解决这些现代数据流挑战。\n\n##3. nifi特点\n\n ![](https://nifi.apache.org/assets/images/flow-th.png)\n Apache NiFi--一个易于使用、功能强大而且可靠的数据处理和分发系统。它支持强大且可高度配置的基于有向图的数据路由、转换和系统中介逻辑。Apache NiFi的一些高级功能和目标包括但不限于：\n  \n* 基于web的UI\n    * 设计，控制，反馈和监控之间的无缝体验\n* 高可配置\n    * 数据丢失容错vs保证交付\n    * 低延迟vs高吞吐量\n    * 动态优先级\n    * 流可以在运行时修改\n    * 背压(Back presure)\n* 数据血统\n    * 从始至终的追踪数据流（dataflow）\n* 为扩展而设计\n    * 构建自己的处理器和跟多\n    * 支持快速开发和有效测试\n* 安全\n    * 支持SSL,SSH,HTTPS加密内容，等等……\n    * 多租户授权和内部授权/策略管理 \n\n##4. nifi的核心概念\n\nNiFi的基本设计理念与基于流程编程的主要思想密切相关[fbp](http://en.wikipedia.org/wiki/Flow-based_programming#Concepts)。 以下是一些主要的NiFi概念，以及它们如何映射到FBP：\n\n|nifi名词|FBP名词|描述|\n|-------------------|--------------------------|--------------------------------------------------------|\n|FlowFile|Information Packet|（流文件）FlowFile是系统间传输的对象，nifi会追踪每个Key/Value属性对，以及相关的内容字节流|\n|FlowFile Processor|Black Box|处理器负责执行操作，在EIP中，处理器可以实现数据路由的合并，变换，及系统间协调。处理器可以读取FlowFile的属性和流数据。处理器可以操作工作单元中多个FlowFile,也可以提交或还原提交的任务。|\n|Connection|Bounded Buffer|连接器提供处理器之间的关联，它以队列的形式存在并允许控制各处理器之间的数据流动速度，队列可以动态的设定优先级，允许设定阈值（队列数量大小或者字节大小）来实现背压。|\n|Flow Controller|Scheduler|流控制器维护处理器之间的连接关系，管理和分配所有处理器使用的线程。它用作促成处理器间流文件（FlowFiles）交换的代理|\n|Process Group|subnet|处理器组是特定的处理器和连接器的集合。它能够通过输入端口（input）接收数据，通过输出端口（）发送数据。处理器组可以通过组合各种组件方式来构造新的组件。|\n\n这种设计设计和[seda](https://nifi.apache.org/docs/nifi-docs/html/overview.html#seda)相似，它为nifi成为一个建立强大和可扩展的数据流的高效平台带来许多的好处，这些好处包括但不限于：\n\n- 可视化的创建和管理处理器之间的有向图\n- 本质上是异步的，也能够支持高吞吐量，即便在处理（processing）和流量波动情况下做到自然缓存\n- 提供高并发框架，使开发人员无需担心高并发的复杂性\n- 促进内聚和松散耦合的组件的开发，从而可在不同环境中复用和做单元测试\n- 资源受限的连接产生了重要的功能，比如非常自然和直观的背压和释压\n- 错误的处理变得和基本过程（happy path）一样自然，而不是粗粒度的捕获全部的错误\n- 数据在系统的进出的点以及流动过程能够一目了然，并且非常容易跟踪。\n\n##5. 参考\n\n1. ) [hopeatme的csdn博客](http://blog.csdn.net/hopeatme/article/details/50815448)\n2. ) [Hortonworks进军物联网，发布基于Apache NiFi项目的DataFlow产品](http://www.infoq.com/cn/news/2015/10/hortonworks-ioat-dataflow-nifi)\n3. ) [nifi doc](https://nifi.apache.org/docs.html)","source":"_posts/nifi-简介.md","raw":"---\ntitle: Apache NiFi简介\ndate: 2017-03-30 23:59:05\ntags: 笔记\ncategories: apache nifi\n---\n\n <img src=\"https://nifi.apache.org/assets/images/apache-nifi-logo.svg\" width = \"80%\" height = \"80%\" alt=\"图片名称\" align=center />\n\n## 1. 背景\n\n\n[Apache NiFi](https://nifi.apache.org/index.html)是由美国过国家安全局(NSA)贡献给Apache基金会的开源项目，其设计目标是自动化系统间的数据流。2015年7月20日，Apache 基金会通过其博客宣布Apache NiFi顺利孵化完成称为Apache的顶级项目之一。NiFi初始的项目名称是Niagarafiles，当NiFi项目开源之后，一些早先在NSA（美国国家安全局）的开发者们创立了初创公司Onyara，Onyara随之继续NiFi项目的开发并提供相关的支持。[Hortonworks](https://hortonworks.com/)公司最近收购了Onyara并将其开发者整合到自己的团队中。apache nifi 也成为了Hortonworks进军物联网的利器。\n\n##2. nifi是什么\n\n简单的来说nifi的建立是为了使各个系统之间的”数据流“自动化，“数据流”这个词代表着多种含义，这里提到的数据流特指自动化和可管理的信息流。自从企业中出现多个系统之后，要面临的首要任务是解决数据生产系统与数据处理系统之间的数据处理流。自从这个问题面世以来，人们已经广泛的探讨了解决方案，其中[《Enterprise Integration Patterns》](http://www.enterpriseintegrationpatterns.com/)一书提出一个全面可行的消息消费方式。\n对于数据流来说主要面临以下几个大方面的挑战：\n\n- **系统故障（System fail）**\n    包括但不限于：网络故障，硬盘故障，软件崩溃，人为失误\n- **数据处理瓶颈**\n    有时，数据源头产生数据的速度远远超过数据处理和数据传输的速度，此时整个系统有一个很严重的瓶颈。\n- **异常数据处理**\n    您将始终收到太大，太小，太快，太慢，损坏，错误或格式错误的数据。\n- **业务快速演进**\n   快速数据处理业务的调整，新业务流程和原有业务升级改造\n- **多系统升级不同步引入的前后兼容** \n  原有系统的协议和数据格式，会伴随系统的升级有一定的调整，同时单个系统的升级会影响周边系统。数据流可以把多个大型分布式系统串边在一起，这些系统可以是松散地，甚至设计之初就没考虑未来地集成\n- **兼容性和安全性**\n 法律法规的变更，规章制度的变动，以及政策调整，业务合同的变更。系统和系统之间，系统和用户接口之间要安全，可信和权责分明。\n- **生产环境平滑升级**\n    在实验验证环境很难复制生产环境\n\n多年以来，数据流已经成为一种架构中必不可少的恶性循环之一。 现在虽然有一些积极和快速发展的运动，使得数据流更有趣，对于给定企业的成功更为重要。 这些包括像 面向服务的架构[soa](http://en.wikipedia.org/wiki/Service-oriented_architecture]，API [api][http://www.forbes.com/sites/ciocentral/2012/08/29/welcome-to-the-api-economy/) [api2](http://thenextweb.com/dd/2014/03/28/api-economy/)，物联网[iot](http://en.wikipedia.org/wiki/Internet_of_Things)以及Big Data [bigdata](http://en.wikipedia.org/wiki/Big_data)的兴起。 此外，合规性，隐私性和安全性所需的严谨程度不断增加。 即使仍然存在所有这些新概念，数据流的模式和需求仍然基本相同。 主要的区别在于复杂性的范围，适应需要的变化率，以及边缘情况在一般情况下是常见的情况。 NiFi旨在帮助解决这些现代数据流挑战。\n\n##3. nifi特点\n\n ![](https://nifi.apache.org/assets/images/flow-th.png)\n Apache NiFi--一个易于使用、功能强大而且可靠的数据处理和分发系统。它支持强大且可高度配置的基于有向图的数据路由、转换和系统中介逻辑。Apache NiFi的一些高级功能和目标包括但不限于：\n  \n* 基于web的UI\n    * 设计，控制，反馈和监控之间的无缝体验\n* 高可配置\n    * 数据丢失容错vs保证交付\n    * 低延迟vs高吞吐量\n    * 动态优先级\n    * 流可以在运行时修改\n    * 背压(Back presure)\n* 数据血统\n    * 从始至终的追踪数据流（dataflow）\n* 为扩展而设计\n    * 构建自己的处理器和跟多\n    * 支持快速开发和有效测试\n* 安全\n    * 支持SSL,SSH,HTTPS加密内容，等等……\n    * 多租户授权和内部授权/策略管理 \n\n##4. nifi的核心概念\n\nNiFi的基本设计理念与基于流程编程的主要思想密切相关[fbp](http://en.wikipedia.org/wiki/Flow-based_programming#Concepts)。 以下是一些主要的NiFi概念，以及它们如何映射到FBP：\n\n|nifi名词|FBP名词|描述|\n|-------------------|--------------------------|--------------------------------------------------------|\n|FlowFile|Information Packet|（流文件）FlowFile是系统间传输的对象，nifi会追踪每个Key/Value属性对，以及相关的内容字节流|\n|FlowFile Processor|Black Box|处理器负责执行操作，在EIP中，处理器可以实现数据路由的合并，变换，及系统间协调。处理器可以读取FlowFile的属性和流数据。处理器可以操作工作单元中多个FlowFile,也可以提交或还原提交的任务。|\n|Connection|Bounded Buffer|连接器提供处理器之间的关联，它以队列的形式存在并允许控制各处理器之间的数据流动速度，队列可以动态的设定优先级，允许设定阈值（队列数量大小或者字节大小）来实现背压。|\n|Flow Controller|Scheduler|流控制器维护处理器之间的连接关系，管理和分配所有处理器使用的线程。它用作促成处理器间流文件（FlowFiles）交换的代理|\n|Process Group|subnet|处理器组是特定的处理器和连接器的集合。它能够通过输入端口（input）接收数据，通过输出端口（）发送数据。处理器组可以通过组合各种组件方式来构造新的组件。|\n\n这种设计设计和[seda](https://nifi.apache.org/docs/nifi-docs/html/overview.html#seda)相似，它为nifi成为一个建立强大和可扩展的数据流的高效平台带来许多的好处，这些好处包括但不限于：\n\n- 可视化的创建和管理处理器之间的有向图\n- 本质上是异步的，也能够支持高吞吐量，即便在处理（processing）和流量波动情况下做到自然缓存\n- 提供高并发框架，使开发人员无需担心高并发的复杂性\n- 促进内聚和松散耦合的组件的开发，从而可在不同环境中复用和做单元测试\n- 资源受限的连接产生了重要的功能，比如非常自然和直观的背压和释压\n- 错误的处理变得和基本过程（happy path）一样自然，而不是粗粒度的捕获全部的错误\n- 数据在系统的进出的点以及流动过程能够一目了然，并且非常容易跟踪。\n\n##5. 参考\n\n1. ) [hopeatme的csdn博客](http://blog.csdn.net/hopeatme/article/details/50815448)\n2. ) [Hortonworks进军物联网，发布基于Apache NiFi项目的DataFlow产品](http://www.infoq.com/cn/news/2015/10/hortonworks-ioat-dataflow-nifi)\n3. ) [nifi doc](https://nifi.apache.org/docs.html)","slug":"nifi-简介","published":1,"updated":"2017-09-28T10:52:58.659Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8cgqo7d00023szy5jaa4ay9","content":"<p><img src=\"https://nifi.apache.org/assets/images/apache-nifi-logo.svg\" width = \"80%\" height = \"80%\" alt=\"图片名称\" align=center /></p>\n<h2 id=\"背景\">1. 背景</h2>\n<p><a href=\"https://nifi.apache.org/index.html\" target=\"_blank\" rel=\"noopener\">Apache NiFi</a>是由美国过国家安全局(NSA)贡献给Apache基金会的开源项目，其设计目标是自动化系统间的数据流。2015年7月20日，Apache 基金会通过其博客宣布Apache NiFi顺利孵化完成称为Apache的顶级项目之一。NiFi初始的项目名称是Niagarafiles，当NiFi项目开源之后，一些早先在NSA（美国国家安全局）的开发者们创立了初创公司Onyara，Onyara随之继续NiFi项目的开发并提供相关的支持。<a href=\"https://hortonworks.com/\" target=\"_blank\" rel=\"noopener\">Hortonworks</a>公司最近收购了Onyara并将其开发者整合到自己的团队中。apache nifi 也成为了Hortonworks进军物联网的利器。</p>\n<h2 id=\"nifi是什么\">2. nifi是什么</h2>\n<p>简单的来说nifi的建立是为了使各个系统之间的”数据流“自动化，“数据流”这个词代表着多种含义，这里提到的数据流特指自动化和可管理的信息流。自从企业中出现多个系统之后，要面临的首要任务是解决数据生产系统与数据处理系统之间的数据处理流。自从这个问题面世以来，人们已经广泛的探讨了解决方案，其中<a href=\"http://www.enterpriseintegrationpatterns.com/\" target=\"_blank\" rel=\"noopener\">《Enterprise Integration Patterns》</a>一书提出一个全面可行的消息消费方式。 对于数据流来说主要面临以下几个大方面的挑战：</p>\n<ul>\n<li><strong>系统故障（System fail）</strong> 包括但不限于：网络故障，硬盘故障，软件崩溃，人为失误</li>\n<li><strong>数据处理瓶颈</strong> 有时，数据源头产生数据的速度远远超过数据处理和数据传输的速度，此时整个系统有一个很严重的瓶颈。</li>\n<li><strong>异常数据处理</strong> 您将始终收到太大，太小，太快，太慢，损坏，错误或格式错误的数据。</li>\n<li><strong>业务快速演进</strong> 快速数据处理业务的调整，新业务流程和原有业务升级改造</li>\n<li><strong>多系统升级不同步引入的前后兼容</strong> 原有系统的协议和数据格式，会伴随系统的升级有一定的调整，同时单个系统的升级会影响周边系统。数据流可以把多个大型分布式系统串边在一起，这些系统可以是松散地，甚至设计之初就没考虑未来地集成</li>\n<li><strong>兼容性和安全性</strong> 法律法规的变更，规章制度的变动，以及政策调整，业务合同的变更。系统和系统之间，系统和用户接口之间要安全，可信和权责分明。</li>\n<li><strong>生产环境平滑升级</strong> 在实验验证环境很难复制生产环境</li>\n</ul>\n<p>多年以来，数据流已经成为一种架构中必不可少的恶性循环之一。 现在虽然有一些积极和快速发展的运动，使得数据流更有趣，对于给定企业的成功更为重要。 这些包括像 面向服务的架构<a href=\"http://en.wikipedia.org/wiki/Service-oriented_architecture%5D，API%20%5Bapi%5D%5Bhttp://www.forbes.com/sites/ciocentral/2012/08/29/welcome-to-the-api-economy/\" target=\"_blank\" rel=\"noopener\">soa</a> <a href=\"http://thenextweb.com/dd/2014/03/28/api-economy/\" target=\"_blank\" rel=\"noopener\">api2</a>，物联网<a href=\"http://en.wikipedia.org/wiki/Internet_of_Things\" target=\"_blank\" rel=\"noopener\">iot</a>以及Big Data <a href=\"http://en.wikipedia.org/wiki/Big_data\" target=\"_blank\" rel=\"noopener\">bigdata</a>的兴起。 此外，合规性，隐私性和安全性所需的严谨程度不断增加。 即使仍然存在所有这些新概念，数据流的模式和需求仍然基本相同。 主要的区别在于复杂性的范围，适应需要的变化率，以及边缘情况在一般情况下是常见的情况。 NiFi旨在帮助解决这些现代数据流挑战。</p>\n<h2 id=\"nifi特点\">3. nifi特点</h2>\n<p><img src=\"https://nifi.apache.org/assets/images/flow-th.png\" /> Apache NiFi–一个易于使用、功能强大而且可靠的数据处理和分发系统。它支持强大且可高度配置的基于有向图的数据路由、转换和系统中介逻辑。Apache NiFi的一些高级功能和目标包括但不限于：</p>\n<ul>\n<li>基于web的UI\n<ul>\n<li>设计，控制，反馈和监控之间的无缝体验</li>\n</ul></li>\n<li>高可配置\n<ul>\n<li>数据丢失容错vs保证交付</li>\n<li>低延迟vs高吞吐量</li>\n<li>动态优先级</li>\n<li>流可以在运行时修改</li>\n<li>背压(Back presure)</li>\n</ul></li>\n<li>数据血统\n<ul>\n<li>从始至终的追踪数据流（dataflow）</li>\n</ul></li>\n<li>为扩展而设计\n<ul>\n<li>构建自己的处理器和跟多</li>\n<li>支持快速开发和有效测试</li>\n</ul></li>\n<li>安全\n<ul>\n<li>支持SSL,SSH,HTTPS加密内容，等等……</li>\n<li>多租户授权和内部授权/策略管理</li>\n</ul></li>\n</ul>\n<h2 id=\"nifi的核心概念\">4. nifi的核心概念</h2>\n<p>NiFi的基本设计理念与基于流程编程的主要思想密切相关<a href=\"http://en.wikipedia.org/wiki/Flow-based_programming#Concepts\" target=\"_blank\" rel=\"noopener\">fbp</a>。 以下是一些主要的NiFi概念，以及它们如何映射到FBP：</p>\n<table>\n<colgroup>\n<col width=\"19%\" />\n<col width=\"25%\" />\n<col width=\"54%\" />\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th>nifi名词</th>\n<th>FBP名词</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td>FlowFile</td>\n<td>Information Packet</td>\n<td>（流文件）FlowFile是系统间传输的对象，nifi会追踪每个Key/Value属性对，以及相关的内容字节流</td>\n</tr>\n<tr class=\"even\">\n<td>FlowFile Processor</td>\n<td>Black Box</td>\n<td>处理器负责执行操作，在EIP中，处理器可以实现数据路由的合并，变换，及系统间协调。处理器可以读取FlowFile的属性和流数据。处理器可以操作工作单元中多个FlowFile,也可以提交或还原提交的任务。</td>\n</tr>\n<tr class=\"odd\">\n<td>Connection</td>\n<td>Bounded Buffer</td>\n<td>连接器提供处理器之间的关联，它以队列的形式存在并允许控制各处理器之间的数据流动速度，队列可以动态的设定优先级，允许设定阈值（队列数量大小或者字节大小）来实现背压。</td>\n</tr>\n<tr class=\"even\">\n<td>Flow Controller</td>\n<td>Scheduler</td>\n<td>流控制器维护处理器之间的连接关系，管理和分配所有处理器使用的线程。它用作促成处理器间流文件（FlowFiles）交换的代理</td>\n</tr>\n<tr class=\"odd\">\n<td>Process Group</td>\n<td>subnet</td>\n<td>处理器组是特定的处理器和连接器的集合。它能够通过输入端口（input）接收数据，通过输出端口（）发送数据。处理器组可以通过组合各种组件方式来构造新的组件。</td>\n</tr>\n</tbody>\n</table>\n<p>这种设计设计和<a href=\"https://nifi.apache.org/docs/nifi-docs/html/overview.html#seda\" target=\"_blank\" rel=\"noopener\">seda</a>相似，它为nifi成为一个建立强大和可扩展的数据流的高效平台带来许多的好处，这些好处包括但不限于：</p>\n<ul>\n<li>可视化的创建和管理处理器之间的有向图</li>\n<li>本质上是异步的，也能够支持高吞吐量，即便在处理（processing）和流量波动情况下做到自然缓存</li>\n<li>提供高并发框架，使开发人员无需担心高并发的复杂性</li>\n<li>促进内聚和松散耦合的组件的开发，从而可在不同环境中复用和做单元测试</li>\n<li>资源受限的连接产生了重要的功能，比如非常自然和直观的背压和释压</li>\n<li>错误的处理变得和基本过程（happy path）一样自然，而不是粗粒度的捕获全部的错误</li>\n<li>数据在系统的进出的点以及流动过程能够一目了然，并且非常容易跟踪。</li>\n</ul>\n<h2 id=\"参考\">5. 参考</h2>\n<ol style=\"list-style-type: decimal\">\n<li>) <a href=\"http://blog.csdn.net/hopeatme/article/details/50815448\" target=\"_blank\" rel=\"noopener\">hopeatme的csdn博客</a></li>\n<li>) <a href=\"http://www.infoq.com/cn/news/2015/10/hortonworks-ioat-dataflow-nifi\" target=\"_blank\" rel=\"noopener\">Hortonworks进军物联网，发布基于Apache NiFi项目的DataFlow产品</a></li>\n<li>) <a href=\"https://nifi.apache.org/docs.html\" target=\"_blank\" rel=\"noopener\">nifi doc</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p><img src=\"https://nifi.apache.org/assets/images/apache-nifi-logo.svg\" width = \"80%\" height = \"80%\" alt=\"图片名称\" align=center /></p>\n<h2 id=\"背景\">1. 背景</h2>\n<p><a href=\"https://nifi.apache.org/index.html\" target=\"_blank\" rel=\"noopener\">Apache NiFi</a>是由美国过国家安全局(NSA)贡献给Apache基金会的开源项目，其设计目标是自动化系统间的数据流。2015年7月20日，Apache 基金会通过其博客宣布Apache NiFi顺利孵化完成称为Apache的顶级项目之一。NiFi初始的项目名称是Niagarafiles，当NiFi项目开源之后，一些早先在NSA（美国国家安全局）的开发者们创立了初创公司Onyara，Onyara随之继续NiFi项目的开发并提供相关的支持。<a href=\"https://hortonworks.com/\" target=\"_blank\" rel=\"noopener\">Hortonworks</a>公司最近收购了Onyara并将其开发者整合到自己的团队中。apache nifi 也成为了Hortonworks进军物联网的利器。</p>\n<h2 id=\"nifi是什么\">2. nifi是什么</h2>\n<p>简单的来说nifi的建立是为了使各个系统之间的”数据流“自动化，“数据流”这个词代表着多种含义，这里提到的数据流特指自动化和可管理的信息流。自从企业中出现多个系统之后，要面临的首要任务是解决数据生产系统与数据处理系统之间的数据处理流。自从这个问题面世以来，人们已经广泛的探讨了解决方案，其中<a href=\"http://www.enterpriseintegrationpatterns.com/\" target=\"_blank\" rel=\"noopener\">《Enterprise Integration Patterns》</a>一书提出一个全面可行的消息消费方式。 对于数据流来说主要面临以下几个大方面的挑战：</p>\n<ul>\n<li><strong>系统故障（System fail）</strong> 包括但不限于：网络故障，硬盘故障，软件崩溃，人为失误</li>\n<li><strong>数据处理瓶颈</strong> 有时，数据源头产生数据的速度远远超过数据处理和数据传输的速度，此时整个系统有一个很严重的瓶颈。</li>\n<li><strong>异常数据处理</strong> 您将始终收到太大，太小，太快，太慢，损坏，错误或格式错误的数据。</li>\n<li><strong>业务快速演进</strong> 快速数据处理业务的调整，新业务流程和原有业务升级改造</li>\n<li><strong>多系统升级不同步引入的前后兼容</strong> 原有系统的协议和数据格式，会伴随系统的升级有一定的调整，同时单个系统的升级会影响周边系统。数据流可以把多个大型分布式系统串边在一起，这些系统可以是松散地，甚至设计之初就没考虑未来地集成</li>\n<li><strong>兼容性和安全性</strong> 法律法规的变更，规章制度的变动，以及政策调整，业务合同的变更。系统和系统之间，系统和用户接口之间要安全，可信和权责分明。</li>\n<li><strong>生产环境平滑升级</strong> 在实验验证环境很难复制生产环境</li>\n</ul>\n<p>多年以来，数据流已经成为一种架构中必不可少的恶性循环之一。 现在虽然有一些积极和快速发展的运动，使得数据流更有趣，对于给定企业的成功更为重要。 这些包括像 面向服务的架构<a href=\"http://en.wikipedia.org/wiki/Service-oriented_architecture%5D，API%20%5Bapi%5D%5Bhttp://www.forbes.com/sites/ciocentral/2012/08/29/welcome-to-the-api-economy/\" target=\"_blank\" rel=\"noopener\">soa</a> <a href=\"http://thenextweb.com/dd/2014/03/28/api-economy/\" target=\"_blank\" rel=\"noopener\">api2</a>，物联网<a href=\"http://en.wikipedia.org/wiki/Internet_of_Things\" target=\"_blank\" rel=\"noopener\">iot</a>以及Big Data <a href=\"http://en.wikipedia.org/wiki/Big_data\" target=\"_blank\" rel=\"noopener\">bigdata</a>的兴起。 此外，合规性，隐私性和安全性所需的严谨程度不断增加。 即使仍然存在所有这些新概念，数据流的模式和需求仍然基本相同。 主要的区别在于复杂性的范围，适应需要的变化率，以及边缘情况在一般情况下是常见的情况。 NiFi旨在帮助解决这些现代数据流挑战。</p>\n<h2 id=\"nifi特点\">3. nifi特点</h2>\n<p><img src=\"https://nifi.apache.org/assets/images/flow-th.png\" /> Apache NiFi–一个易于使用、功能强大而且可靠的数据处理和分发系统。它支持强大且可高度配置的基于有向图的数据路由、转换和系统中介逻辑。Apache NiFi的一些高级功能和目标包括但不限于：</p>\n<ul>\n<li>基于web的UI\n<ul>\n<li>设计，控制，反馈和监控之间的无缝体验</li>\n</ul></li>\n<li>高可配置\n<ul>\n<li>数据丢失容错vs保证交付</li>\n<li>低延迟vs高吞吐量</li>\n<li>动态优先级</li>\n<li>流可以在运行时修改</li>\n<li>背压(Back presure)</li>\n</ul></li>\n<li>数据血统\n<ul>\n<li>从始至终的追踪数据流（dataflow）</li>\n</ul></li>\n<li>为扩展而设计\n<ul>\n<li>构建自己的处理器和跟多</li>\n<li>支持快速开发和有效测试</li>\n</ul></li>\n<li>安全\n<ul>\n<li>支持SSL,SSH,HTTPS加密内容，等等……</li>\n<li>多租户授权和内部授权/策略管理</li>\n</ul></li>\n</ul>\n<h2 id=\"nifi的核心概念\">4. nifi的核心概念</h2>\n<p>NiFi的基本设计理念与基于流程编程的主要思想密切相关<a href=\"http://en.wikipedia.org/wiki/Flow-based_programming#Concepts\" target=\"_blank\" rel=\"noopener\">fbp</a>。 以下是一些主要的NiFi概念，以及它们如何映射到FBP：</p>\n<table>\n<colgroup>\n<col width=\"19%\" />\n<col width=\"25%\" />\n<col width=\"54%\" />\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th>nifi名词</th>\n<th>FBP名词</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td>FlowFile</td>\n<td>Information Packet</td>\n<td>（流文件）FlowFile是系统间传输的对象，nifi会追踪每个Key/Value属性对，以及相关的内容字节流</td>\n</tr>\n<tr class=\"even\">\n<td>FlowFile Processor</td>\n<td>Black Box</td>\n<td>处理器负责执行操作，在EIP中，处理器可以实现数据路由的合并，变换，及系统间协调。处理器可以读取FlowFile的属性和流数据。处理器可以操作工作单元中多个FlowFile,也可以提交或还原提交的任务。</td>\n</tr>\n<tr class=\"odd\">\n<td>Connection</td>\n<td>Bounded Buffer</td>\n<td>连接器提供处理器之间的关联，它以队列的形式存在并允许控制各处理器之间的数据流动速度，队列可以动态的设定优先级，允许设定阈值（队列数量大小或者字节大小）来实现背压。</td>\n</tr>\n<tr class=\"even\">\n<td>Flow Controller</td>\n<td>Scheduler</td>\n<td>流控制器维护处理器之间的连接关系，管理和分配所有处理器使用的线程。它用作促成处理器间流文件（FlowFiles）交换的代理</td>\n</tr>\n<tr class=\"odd\">\n<td>Process Group</td>\n<td>subnet</td>\n<td>处理器组是特定的处理器和连接器的集合。它能够通过输入端口（input）接收数据，通过输出端口（）发送数据。处理器组可以通过组合各种组件方式来构造新的组件。</td>\n</tr>\n</tbody>\n</table>\n<p>这种设计设计和<a href=\"https://nifi.apache.org/docs/nifi-docs/html/overview.html#seda\" target=\"_blank\" rel=\"noopener\">seda</a>相似，它为nifi成为一个建立强大和可扩展的数据流的高效平台带来许多的好处，这些好处包括但不限于：</p>\n<ul>\n<li>可视化的创建和管理处理器之间的有向图</li>\n<li>本质上是异步的，也能够支持高吞吐量，即便在处理（processing）和流量波动情况下做到自然缓存</li>\n<li>提供高并发框架，使开发人员无需担心高并发的复杂性</li>\n<li>促进内聚和松散耦合的组件的开发，从而可在不同环境中复用和做单元测试</li>\n<li>资源受限的连接产生了重要的功能，比如非常自然和直观的背压和释压</li>\n<li>错误的处理变得和基本过程（happy path）一样自然，而不是粗粒度的捕获全部的错误</li>\n<li>数据在系统的进出的点以及流动过程能够一目了然，并且非常容易跟踪。</li>\n</ul>\n<h2 id=\"参考\">5. 参考</h2>\n<ol style=\"list-style-type: decimal\">\n<li>) <a href=\"http://blog.csdn.net/hopeatme/article/details/50815448\" target=\"_blank\" rel=\"noopener\">hopeatme的csdn博客</a></li>\n<li>) <a href=\"http://www.infoq.com/cn/news/2015/10/hortonworks-ioat-dataflow-nifi\" target=\"_blank\" rel=\"noopener\">Hortonworks进军物联网，发布基于Apache NiFi项目的DataFlow产品</a></li>\n<li>) <a href=\"https://nifi.apache.org/docs.html\" target=\"_blank\" rel=\"noopener\">nifi doc</a></li>\n</ol>\n"},{"title":"hexo写博客","date":"2017-05-27T09:05:47.000Z","_content":"\n##1.背景\n\n自己在不断的学习，需要一个地方来记录，写博客也是能够对已经学过的东西进行一次系统的梳理，有利于对知识的巩固。但是博客就要考虑写和放的问题，写-自然就选择用[markdown](http://wowubuntu.com/markdown/)了，主要考虑它是一个轻格式的，能够支持绝大部分的html格式，这也是现在写博客的主流。放选择了[GitHub Page](https://pages.github.com/)，主要是不用钱，还可以顺道学习一下git相关的知识。\n\n##2.hexo是什么\n\n[hexo](https://github.com/hexojs/hexo/stargazers)是基于Node.js的快速、简洁且高效的博客框架，能够快速的对markdown文件渲染为html，支持一键部署到GitHub Page，有着丰富的插件。hexo官方文档十分详实，从如何安装到文章发布，从切换主题到嵌入第三方服务，这里只做简单的摘抄，详细的过程还是需要参考[文档](https://hexo.io/zh-cn/docs/)\n\n首先，hexo的使用需要一些基本软件的支持，分别是[node](https://github.com/nodejs/node)和git。\n```shell\nbrew install nvm ##安装Node.js版本管理的工具nvm\nnvm install stable ##安装最新稳定版本的node\nbrew install git ##安装git，目前世界上最先进的分布式版本控制系统\n```\n\nhexo的安装部署很方便：\n\n```shell\nnpm install hexo-cli -g ## 1.全局安装hexo\nhexo init blog ##2.初始化博客文件夹\ncd blog ##3.切换到博客文件夹\nnpm install ##4.安装hexo的依赖包\nhexo server ##5.开启hexo本地网站服务\n```\n\n初始化的博客目录结构如下：\n\n```shell\n.\n├── _config.yml\n├── package.json\n├── scaffolds\n├── source\n|   ├── _drafts\n|   └── _posts\n└── themes\n```\n\n##3.pandoc-解决数学符号\n\n[Mathjax](https://www.mathjax.org/)可以解析网页上的数学公式，与hexo的结合也很简单，但是由hexo默认使用[marked.js](https://github.com/chjj/marked)去解析我们写的markdown，Markdwon本身的特殊符号与Latex中的符号会出现冲突（其实很多其他的markdown引擎不会存在这些问题），比如一些符号，\\_代表斜体，会被处理为\\<em\\>标签，比如x\\_i在开始被渲染的时候，处理为x\\<em\\>i\\</em\\>，这个时候mathjax就无法渲染成下标了。解决marked.js引擎带来的渲染公式问题的方法主要是以下三种：\n\n- 手动escape\n- [保护代码块](https://liam0205.me/2015/09/09/fix-conflict-between-mathjax-and-markdown/)\n- [修改Hexo渲染源码](http://blog.csdn.net/emptyset110/article/details/50123231)\n\n但是这些方法或多或少的都存在着一些问题，首先，手动escape需要对公式涉及到的每一个markdown关键词转义，例如：`\\$$f\\_i = f\\_{i + 1}\\$$`这样每一个关键词都要转义实在是太繁琐了，通用性很差,比如想迁移到其它地方，就无法识别了，因为大部分的markdown引擎是没有这个问题的。\n\n其次是保护代码块的方法，markdown中的两个\\`之间的东西不会转义例如这样`\\$f_i = f_{i + 1}\\$`，但是这样一来所有的公式的样式都是以code的形式来展现的，这个方法还有个问题，就是有时候我们的代码中会有$$的出现，这时候，仍然使用mathjax就有可能出现无法预料的结果了。\n\n最后的修改hexo的渲染源码太过于激进，而且不实用，且先不说无法保证所有字符能够正确的转义，而且有可能会丢失原来markdown的关键字语法，修改代码会带来不可预料的bug，日后的升级维护也会带来很多麻烦。\n\n说到底，数学公式的问题都是marked.js引擎导致的，那么为什么不直接换掉引擎呢，于是找到了[Pandoc](http://pandoc.org/)的这个好东西。Pandoc是由John MacFarlane开发的标记语言转换工具，可实现不同标记语言间的格式转换，堪称该领域中的“瑞士军刀”，Pandoc的语法完全没有上述问题。使用Pandoc解析器只需要2步。\n\n```shell\nbrew install pandoc ##安装pandoc软件\nnpm install hexo-renderer-pandoc ## 安装hexo的pandoc解析器\n```\n\n只需要2个命令，所有问题就都解决。有人会说pandoc太重了，是一个核弹级武器，用来解决数学符号问题引用一个这么大的软件实在是杀鸡用牛刀，但是“Life is short, you need Python”。\n\n##4.CI-自动构建\n\nhexo支持一键发布到GItHub Page和[HeroKu](https://www.heroku.com/)等平台。具体参考官方文档中的[deployment章节](https://hexo.io/docs/deployment.html)，一般博主都是先本地搭建好hexo的环境，然后编写文章，最后使用hexo deploy来发布文章。\n\n但是，这样的使用方法有时会带来一些不便。首先，如果我想在另外一台设备上面写博客，必须将整个项目拷贝过来，完成之后要保持两台设备的内容是一致的，不然就会导致部署之后有不同的地方。在这种情况下一般会将整个项目都托管到 github 上面。但是这又会导致另外一个问题，每次有改动的时候不但要部署博客，还要提交项目的代码，这又增加了操作的步骤。\n\n那么有什么办法来优雅的解决这个问题呢？毕竟我只想安安静静的写个博客啊！是时候该让[Travis CI](https://travis-ci.org/)上场了！顾名思义，Travis CI 是一个持续集成(Continuous integration，简称CI)的工具。它可以在公共的 Github 仓库上免费使用。核心思想是使用一个GitHub Page分支来管理所有博客的源代码，然后由CI编译发布到master主分支。\n\nTravis CI的持续集成非常的方便，尤其他对Github是无缝支持，只需要简单的三步：\n\n1. 开启CI\n2. 编写 .travis.yml\n3. 触发\n\n首先使用GitHub账号登入在Travis CI，并在Travis中开启GItHub Page的持续集成，如下图\n\n![](/images/2017-05-30-11-38-30.jpg)\n\n![](/images/2017-05-30-11-30-06.jpg)\n\n然后设定自动构建过程的配置文件，在本地的blog的git库的顶级目录中新加文件.travis.yml，并添加以下内容：\n```yml\nlanguage: node_js\nnode_js: stable\ncache: \n  - pandoc\n  - hexo-cli\n  - hexo-renderer-pandoc\ninstall:\n  - wget ${pandoc}\n  - sudo dpkg -i pandoc*.deb\n  - npm install -g hexo-cli\n  - npm install hexo-renderer-pandoc --save\nscript:\n  - hexo clean\n  - hexo g\nafter_script:\n  - cd ./public\n  - git init\n  - git config user.name \"peterxu\"\n  - git config user.email \"peterxugo@gmail.com\"\n  - git add .\n  - git commit -m \"Update\"\n  - git push --force --quiet \"https://${token}@${GH_REF}\" master:master\nbranches:\n  only:\n    - source_code\nenv:\n global:\n   - GH_REF: github.com/peterxugo/peterxugo.github.io.git\n```\n\n配置文件中的`${pandoc}`是pandoc的下载地址，配置在CI的变量中，后面会具体讲如何设置该变量，同样的`${token},${GH_REF}`同理。`after_script`中的`user.name`，`user.email`，需要改成你自己的git用户名和邮箱，global中的`- GH_REF: github.com/peterxugo/peterxugo.github.io.git`需要换成自己的仓库地址。\n\n重点说明一下CI中安装pandoc，Ubuntu可以直接使用`sudo apt-get install pandoc`，但是这样安装在版本是1.19.1.X(2017-05-30)，我发现这个版本的Pandoc在解析table的时候存在一些问题，不能够正确的解析出一些表格。\n\n这个问题的发现过程如下：我本地mac使用hexo预览文章能够看到表格被正常渲染，但是CI构建后一直无法正常的显示表格，检查html代码发现没有正常的渲染为table，首先想到的是hexo版本问题，通过保证本地和CI环境中的Hexo及相关的软件的版本一致，但是问题依旧没有得到解决。最后猜想到可能是Pandoc的问题，于是查看构建的过程发现本地是Pandoc是pandoc 1.19.2.1,而CI上面apt库安装的版本是1.19.1.X，更新Pandoc版本后表格问题解决。\n\n由于我们需要将构建后的代码push到master分支上面，于是我们需要给CI相关的GItHub权限。我们可以通过GItHub提供的 Personal access token方法，将Token传给CI从而使得CI能够push代码。如下图先在GItHub中新增加一个 Personal access token，**一定要记得复制生成的Token，不然就永远看不见这个Token**\n\n![](/images/2017-05-30-12-05-17.jpg)\n\n登入到CI网站，对仓库进行相关的配置，先选中需要持续集成的仓库，这里是peterxugo/peterxugo.github.io,选中setting，然后开启相应的配置，最后在环境变量中加入刚才在GItHub中生产的token，变量可以在配置文件中用{}引用，pandoc的最新版本下载地址为[Ubuntu pandoc 最新版本](https://github.com/jgm/pandoc/releases/download/1.19.2.1/pandoc-1.19.2.1-1-amd64.deb)\n\n![](/images/2017-05-30-12-16-17.jpg)\n\n![](/images/2017-05-30-12-16-55.jpg)\n\n\n![](/images/2017-05-30-12-17-43.jpg)\n\n最后，我们在本地代码中新建分支source_code，在该分支下执行提交代码\n\n```shell\ngit add . -A\ngit commit -m \"test CI\"\ngit push\n```\n\n一切配置正常的话，我们就可以看到CI中在构建博客的过程了，CI构建完成后就可以看到GitPage中的博客文章了。\n\n##5.参考\n1. [用 Travis CI 自动部署 hexo](https://segmentfault.com/a/1190000004667156)\n2. [Hexo下mathjax的转义问题](http://shomy.top/2016/10/22/hexo-markdown-mathjax/)\n3. [hexo doc](https://hexo.io/docs/)\n构建的到时候遇到的pandoc版本导致无法解析table问题","source":"_posts/hexo写博客.md","raw":"---\ntitle: hexo写博客\ntags: 笔记\ncategories: hexo\ndate: 2017-05-27 17:05:47\n---\n\n##1.背景\n\n自己在不断的学习，需要一个地方来记录，写博客也是能够对已经学过的东西进行一次系统的梳理，有利于对知识的巩固。但是博客就要考虑写和放的问题，写-自然就选择用[markdown](http://wowubuntu.com/markdown/)了，主要考虑它是一个轻格式的，能够支持绝大部分的html格式，这也是现在写博客的主流。放选择了[GitHub Page](https://pages.github.com/)，主要是不用钱，还可以顺道学习一下git相关的知识。\n\n##2.hexo是什么\n\n[hexo](https://github.com/hexojs/hexo/stargazers)是基于Node.js的快速、简洁且高效的博客框架，能够快速的对markdown文件渲染为html，支持一键部署到GitHub Page，有着丰富的插件。hexo官方文档十分详实，从如何安装到文章发布，从切换主题到嵌入第三方服务，这里只做简单的摘抄，详细的过程还是需要参考[文档](https://hexo.io/zh-cn/docs/)\n\n首先，hexo的使用需要一些基本软件的支持，分别是[node](https://github.com/nodejs/node)和git。\n```shell\nbrew install nvm ##安装Node.js版本管理的工具nvm\nnvm install stable ##安装最新稳定版本的node\nbrew install git ##安装git，目前世界上最先进的分布式版本控制系统\n```\n\nhexo的安装部署很方便：\n\n```shell\nnpm install hexo-cli -g ## 1.全局安装hexo\nhexo init blog ##2.初始化博客文件夹\ncd blog ##3.切换到博客文件夹\nnpm install ##4.安装hexo的依赖包\nhexo server ##5.开启hexo本地网站服务\n```\n\n初始化的博客目录结构如下：\n\n```shell\n.\n├── _config.yml\n├── package.json\n├── scaffolds\n├── source\n|   ├── _drafts\n|   └── _posts\n└── themes\n```\n\n##3.pandoc-解决数学符号\n\n[Mathjax](https://www.mathjax.org/)可以解析网页上的数学公式，与hexo的结合也很简单，但是由hexo默认使用[marked.js](https://github.com/chjj/marked)去解析我们写的markdown，Markdwon本身的特殊符号与Latex中的符号会出现冲突（其实很多其他的markdown引擎不会存在这些问题），比如一些符号，\\_代表斜体，会被处理为\\<em\\>标签，比如x\\_i在开始被渲染的时候，处理为x\\<em\\>i\\</em\\>，这个时候mathjax就无法渲染成下标了。解决marked.js引擎带来的渲染公式问题的方法主要是以下三种：\n\n- 手动escape\n- [保护代码块](https://liam0205.me/2015/09/09/fix-conflict-between-mathjax-and-markdown/)\n- [修改Hexo渲染源码](http://blog.csdn.net/emptyset110/article/details/50123231)\n\n但是这些方法或多或少的都存在着一些问题，首先，手动escape需要对公式涉及到的每一个markdown关键词转义，例如：`\\$$f\\_i = f\\_{i + 1}\\$$`这样每一个关键词都要转义实在是太繁琐了，通用性很差,比如想迁移到其它地方，就无法识别了，因为大部分的markdown引擎是没有这个问题的。\n\n其次是保护代码块的方法，markdown中的两个\\`之间的东西不会转义例如这样`\\$f_i = f_{i + 1}\\$`，但是这样一来所有的公式的样式都是以code的形式来展现的，这个方法还有个问题，就是有时候我们的代码中会有$$的出现，这时候，仍然使用mathjax就有可能出现无法预料的结果了。\n\n最后的修改hexo的渲染源码太过于激进，而且不实用，且先不说无法保证所有字符能够正确的转义，而且有可能会丢失原来markdown的关键字语法，修改代码会带来不可预料的bug，日后的升级维护也会带来很多麻烦。\n\n说到底，数学公式的问题都是marked.js引擎导致的，那么为什么不直接换掉引擎呢，于是找到了[Pandoc](http://pandoc.org/)的这个好东西。Pandoc是由John MacFarlane开发的标记语言转换工具，可实现不同标记语言间的格式转换，堪称该领域中的“瑞士军刀”，Pandoc的语法完全没有上述问题。使用Pandoc解析器只需要2步。\n\n```shell\nbrew install pandoc ##安装pandoc软件\nnpm install hexo-renderer-pandoc ## 安装hexo的pandoc解析器\n```\n\n只需要2个命令，所有问题就都解决。有人会说pandoc太重了，是一个核弹级武器，用来解决数学符号问题引用一个这么大的软件实在是杀鸡用牛刀，但是“Life is short, you need Python”。\n\n##4.CI-自动构建\n\nhexo支持一键发布到GItHub Page和[HeroKu](https://www.heroku.com/)等平台。具体参考官方文档中的[deployment章节](https://hexo.io/docs/deployment.html)，一般博主都是先本地搭建好hexo的环境，然后编写文章，最后使用hexo deploy来发布文章。\n\n但是，这样的使用方法有时会带来一些不便。首先，如果我想在另外一台设备上面写博客，必须将整个项目拷贝过来，完成之后要保持两台设备的内容是一致的，不然就会导致部署之后有不同的地方。在这种情况下一般会将整个项目都托管到 github 上面。但是这又会导致另外一个问题，每次有改动的时候不但要部署博客，还要提交项目的代码，这又增加了操作的步骤。\n\n那么有什么办法来优雅的解决这个问题呢？毕竟我只想安安静静的写个博客啊！是时候该让[Travis CI](https://travis-ci.org/)上场了！顾名思义，Travis CI 是一个持续集成(Continuous integration，简称CI)的工具。它可以在公共的 Github 仓库上免费使用。核心思想是使用一个GitHub Page分支来管理所有博客的源代码，然后由CI编译发布到master主分支。\n\nTravis CI的持续集成非常的方便，尤其他对Github是无缝支持，只需要简单的三步：\n\n1. 开启CI\n2. 编写 .travis.yml\n3. 触发\n\n首先使用GitHub账号登入在Travis CI，并在Travis中开启GItHub Page的持续集成，如下图\n\n![](/images/2017-05-30-11-38-30.jpg)\n\n![](/images/2017-05-30-11-30-06.jpg)\n\n然后设定自动构建过程的配置文件，在本地的blog的git库的顶级目录中新加文件.travis.yml，并添加以下内容：\n```yml\nlanguage: node_js\nnode_js: stable\ncache: \n  - pandoc\n  - hexo-cli\n  - hexo-renderer-pandoc\ninstall:\n  - wget ${pandoc}\n  - sudo dpkg -i pandoc*.deb\n  - npm install -g hexo-cli\n  - npm install hexo-renderer-pandoc --save\nscript:\n  - hexo clean\n  - hexo g\nafter_script:\n  - cd ./public\n  - git init\n  - git config user.name \"peterxu\"\n  - git config user.email \"peterxugo@gmail.com\"\n  - git add .\n  - git commit -m \"Update\"\n  - git push --force --quiet \"https://${token}@${GH_REF}\" master:master\nbranches:\n  only:\n    - source_code\nenv:\n global:\n   - GH_REF: github.com/peterxugo/peterxugo.github.io.git\n```\n\n配置文件中的`${pandoc}`是pandoc的下载地址，配置在CI的变量中，后面会具体讲如何设置该变量，同样的`${token},${GH_REF}`同理。`after_script`中的`user.name`，`user.email`，需要改成你自己的git用户名和邮箱，global中的`- GH_REF: github.com/peterxugo/peterxugo.github.io.git`需要换成自己的仓库地址。\n\n重点说明一下CI中安装pandoc，Ubuntu可以直接使用`sudo apt-get install pandoc`，但是这样安装在版本是1.19.1.X(2017-05-30)，我发现这个版本的Pandoc在解析table的时候存在一些问题，不能够正确的解析出一些表格。\n\n这个问题的发现过程如下：我本地mac使用hexo预览文章能够看到表格被正常渲染，但是CI构建后一直无法正常的显示表格，检查html代码发现没有正常的渲染为table，首先想到的是hexo版本问题，通过保证本地和CI环境中的Hexo及相关的软件的版本一致，但是问题依旧没有得到解决。最后猜想到可能是Pandoc的问题，于是查看构建的过程发现本地是Pandoc是pandoc 1.19.2.1,而CI上面apt库安装的版本是1.19.1.X，更新Pandoc版本后表格问题解决。\n\n由于我们需要将构建后的代码push到master分支上面，于是我们需要给CI相关的GItHub权限。我们可以通过GItHub提供的 Personal access token方法，将Token传给CI从而使得CI能够push代码。如下图先在GItHub中新增加一个 Personal access token，**一定要记得复制生成的Token，不然就永远看不见这个Token**\n\n![](/images/2017-05-30-12-05-17.jpg)\n\n登入到CI网站，对仓库进行相关的配置，先选中需要持续集成的仓库，这里是peterxugo/peterxugo.github.io,选中setting，然后开启相应的配置，最后在环境变量中加入刚才在GItHub中生产的token，变量可以在配置文件中用{}引用，pandoc的最新版本下载地址为[Ubuntu pandoc 最新版本](https://github.com/jgm/pandoc/releases/download/1.19.2.1/pandoc-1.19.2.1-1-amd64.deb)\n\n![](/images/2017-05-30-12-16-17.jpg)\n\n![](/images/2017-05-30-12-16-55.jpg)\n\n\n![](/images/2017-05-30-12-17-43.jpg)\n\n最后，我们在本地代码中新建分支source_code，在该分支下执行提交代码\n\n```shell\ngit add . -A\ngit commit -m \"test CI\"\ngit push\n```\n\n一切配置正常的话，我们就可以看到CI中在构建博客的过程了，CI构建完成后就可以看到GitPage中的博客文章了。\n\n##5.参考\n1. [用 Travis CI 自动部署 hexo](https://segmentfault.com/a/1190000004667156)\n2. [Hexo下mathjax的转义问题](http://shomy.top/2016/10/22/hexo-markdown-mathjax/)\n3. [hexo doc](https://hexo.io/docs/)\n构建的到时候遇到的pandoc版本导致无法解析table问题","slug":"hexo写博客","published":1,"updated":"2017-09-28T10:52:58.657Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8cgqo7i00063szycgwh3ly9","content":"<h2 id=\"背景\">1.背景</h2>\n<p>自己在不断的学习，需要一个地方来记录，写博客也是能够对已经学过的东西进行一次系统的梳理，有利于对知识的巩固。但是博客就要考虑写和放的问题，写-自然就选择用<a href=\"http://wowubuntu.com/markdown/\" target=\"_blank\" rel=\"noopener\">markdown</a>了，主要考虑它是一个轻格式的，能够支持绝大部分的html格式，这也是现在写博客的主流。放选择了<a href=\"https://pages.github.com/\" target=\"_blank\" rel=\"noopener\">GitHub Page</a>，主要是不用钱，还可以顺道学习一下git相关的知识。</p>\n<h2 id=\"hexo是什么\">2.hexo是什么</h2>\n<p><a href=\"https://github.com/hexojs/hexo/stargazers\" target=\"_blank\" rel=\"noopener\">hexo</a>是基于Node.js的快速、简洁且高效的博客框架，能够快速的对markdown文件渲染为html，支持一键部署到GitHub Page，有着丰富的插件。hexo官方文档十分详实，从如何安装到文章发布，从切换主题到嵌入第三方服务，这里只做简单的摘抄，详细的过程还是需要参考<a href=\"https://hexo.io/zh-cn/docs/\" target=\"_blank\" rel=\"noopener\">文档</a></p>\n<p>首先，hexo的使用需要一些基本软件的支持，分别是<a href=\"https://github.com/nodejs/node\" target=\"_blank\" rel=\"noopener\">node</a>和git。 <figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brew install nvm ##安装Node.js版本管理的工具nvm</span><br><span class=\"line\">nvm install stable ##安装最新稳定版本的node</span><br><span class=\"line\">brew install git ##安装git，目前世界上最先进的分布式版本控制系统</span><br></pre></td></tr></table></figure></p>\n<p>hexo的安装部署很方便：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-cli -g ## 1.全局安装hexo</span><br><span class=\"line\">hexo init blog ##2.初始化博客文件夹</span><br><span class=\"line\">cd blog ##3.切换到博客文件夹</span><br><span class=\"line\">npm install ##4.安装hexo的依赖包</span><br><span class=\"line\">hexo server ##5.开启hexo本地网站服务</span><br></pre></td></tr></table></figure>\n<p>初始化的博客目录结构如下：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.</span><br><span class=\"line\">├── _config.yml</span><br><span class=\"line\">├── package.json</span><br><span class=\"line\">├── scaffolds</span><br><span class=\"line\">├── source</span><br><span class=\"line\">|   ├── _drafts</span><br><span class=\"line\">|   └── _posts</span><br><span class=\"line\">└── themes</span><br></pre></td></tr></table></figure>\n<h2 id=\"pandoc-解决数学符号\">3.pandoc-解决数学符号</h2>\n<p><a href=\"https://www.mathjax.org/\" target=\"_blank\" rel=\"noopener\">Mathjax</a>可以解析网页上的数学公式，与hexo的结合也很简单，但是由hexo默认使用<a href=\"https://github.com/chjj/marked\" target=\"_blank\" rel=\"noopener\">marked.js</a>去解析我们写的markdown，Markdwon本身的特殊符号与Latex中的符号会出现冲突（其实很多其他的markdown引擎不会存在这些问题），比如一些符号，_代表斜体，会被处理为&lt;em&gt;标签，比如x_i在开始被渲染的时候，处理为x&lt;em&gt;i&lt;/em&gt;，这个时候mathjax就无法渲染成下标了。解决marked.js引擎带来的渲染公式问题的方法主要是以下三种：</p>\n<ul>\n<li>手动escape</li>\n<li><a href=\"https://liam0205.me/2015/09/09/fix-conflict-between-mathjax-and-markdown/\" target=\"_blank\" rel=\"noopener\">保护代码块</a></li>\n<li><a href=\"http://blog.csdn.net/emptyset110/article/details/50123231\" target=\"_blank\" rel=\"noopener\">修改Hexo渲染源码</a></li>\n</ul>\n<p>但是这些方法或多或少的都存在着一些问题，首先，手动escape需要对公式涉及到的每一个markdown关键词转义，例如：<code>\\$$f\\_i = f\\_{i + 1}\\$$</code>这样每一个关键词都要转义实在是太繁琐了，通用性很差,比如想迁移到其它地方，就无法识别了，因为大部分的markdown引擎是没有这个问题的。</p>\n<p>其次是保护代码块的方法，markdown中的两个`之间的东西不会转义例如这样<code>\\$f_i = f_{i + 1}\\$</code>，但是这样一来所有的公式的样式都是以code的形式来展现的，这个方法还有个问题，就是有时候我们的代码中会有$$的出现，这时候，仍然使用mathjax就有可能出现无法预料的结果了。</p>\n<p>最后的修改hexo的渲染源码太过于激进，而且不实用，且先不说无法保证所有字符能够正确的转义，而且有可能会丢失原来markdown的关键字语法，修改代码会带来不可预料的bug，日后的升级维护也会带来很多麻烦。</p>\n<p>说到底，数学公式的问题都是marked.js引擎导致的，那么为什么不直接换掉引擎呢，于是找到了<a href=\"http://pandoc.org/\" target=\"_blank\" rel=\"noopener\">Pandoc</a>的这个好东西。Pandoc是由John MacFarlane开发的标记语言转换工具，可实现不同标记语言间的格式转换，堪称该领域中的“瑞士军刀”，Pandoc的语法完全没有上述问题。使用Pandoc解析器只需要2步。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brew install pandoc ##安装pandoc软件</span><br><span class=\"line\">npm install hexo-renderer-pandoc ## 安装hexo的pandoc解析器</span><br></pre></td></tr></table></figure>\n<p>只需要2个命令，所有问题就都解决。有人会说pandoc太重了，是一个核弹级武器，用来解决数学符号问题引用一个这么大的软件实在是杀鸡用牛刀，但是“Life is short, you need Python”。</p>\n<h2 id=\"ci-自动构建\">4.CI-自动构建</h2>\n<p>hexo支持一键发布到GItHub Page和<a href=\"https://www.heroku.com/\" target=\"_blank\" rel=\"noopener\">HeroKu</a>等平台。具体参考官方文档中的<a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">deployment章节</a>，一般博主都是先本地搭建好hexo的环境，然后编写文章，最后使用hexo deploy来发布文章。</p>\n<p>但是，这样的使用方法有时会带来一些不便。首先，如果我想在另外一台设备上面写博客，必须将整个项目拷贝过来，完成之后要保持两台设备的内容是一致的，不然就会导致部署之后有不同的地方。在这种情况下一般会将整个项目都托管到 github 上面。但是这又会导致另外一个问题，每次有改动的时候不但要部署博客，还要提交项目的代码，这又增加了操作的步骤。</p>\n<p>那么有什么办法来优雅的解决这个问题呢？毕竟我只想安安静静的写个博客啊！是时候该让<a href=\"https://travis-ci.org/\" target=\"_blank\" rel=\"noopener\">Travis CI</a>上场了！顾名思义，Travis CI 是一个持续集成(Continuous integration，简称CI)的工具。它可以在公共的 Github 仓库上免费使用。核心思想是使用一个GitHub Page分支来管理所有博客的源代码，然后由CI编译发布到master主分支。</p>\n<p>Travis CI的持续集成非常的方便，尤其他对Github是无缝支持，只需要简单的三步：</p>\n<ol style=\"list-style-type: decimal\">\n<li>开启CI</li>\n<li>编写 .travis.yml</li>\n<li>触发</li>\n</ol>\n<p>首先使用GitHub账号登入在Travis CI，并在Travis中开启GItHub Page的持续集成，如下图</p>\n<div class=\"figure\">\n<img src=\"/images/2017-05-30-11-38-30.jpg\" />\n\n</div>\n<div class=\"figure\">\n<img src=\"/images/2017-05-30-11-30-06.jpg\" />\n\n</div>\n<p>然后设定自动构建过程的配置文件，在本地的blog的git库的顶级目录中新加文件.travis.yml，并添加以下内容： <figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">language:</span> <span class=\"string\">node_js</span></span><br><span class=\"line\"><span class=\"attr\">node_js:</span> <span class=\"string\">stable</span></span><br><span class=\"line\"><span class=\"attr\">cache:</span> </span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">pandoc</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">hexo-cli</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">hexo-renderer-pandoc</span></span><br><span class=\"line\"><span class=\"attr\">install:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">wget</span> <span class=\"string\">$&#123;pandoc&#125;</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">sudo</span> <span class=\"string\">dpkg</span> <span class=\"string\">-i</span> <span class=\"string\">pandoc*.deb</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">npm</span> <span class=\"string\">install</span> <span class=\"string\">-g</span> <span class=\"string\">hexo-cli</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">npm</span> <span class=\"string\">install</span> <span class=\"string\">hexo-renderer-pandoc</span> <span class=\"string\">--save</span></span><br><span class=\"line\"><span class=\"attr\">script:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">hexo</span> <span class=\"string\">clean</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">hexo</span> <span class=\"string\">g</span></span><br><span class=\"line\"><span class=\"attr\">after_script:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">cd</span> <span class=\"string\">./public</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">git</span> <span class=\"string\">init</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">git</span> <span class=\"string\">config</span> <span class=\"string\">user.name</span> <span class=\"string\">\"peterxu\"</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">git</span> <span class=\"string\">config</span> <span class=\"string\">user.email</span> <span class=\"string\">\"peterxugo@gmail.com\"</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">git</span> <span class=\"string\">add</span> <span class=\"string\">.</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">git</span> <span class=\"string\">commit</span> <span class=\"string\">-m</span> <span class=\"string\">\"Update\"</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">git</span> <span class=\"string\">push</span> <span class=\"string\">--force</span> <span class=\"string\">--quiet</span> <span class=\"string\">\"https://$&#123;token&#125;@$&#123;GH_REF&#125;\"</span> <span class=\"string\">master:master</span></span><br><span class=\"line\"><span class=\"attr\">branches:</span></span><br><span class=\"line\">  <span class=\"attr\">only:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"string\">source_code</span></span><br><span class=\"line\"><span class=\"attr\">env:</span></span><br><span class=\"line\"> <span class=\"attr\">global:</span></span><br><span class=\"line\">   <span class=\"bullet\">-</span> <span class=\"attr\">GH_REF:</span> <span class=\"string\">github.com/peterxugo/peterxugo.github.io.git</span></span><br></pre></td></tr></table></figure></p>\n<p>配置文件中的<code>${pandoc}</code>是pandoc的下载地址，配置在CI的变量中，后面会具体讲如何设置该变量，同样的<code>${token},${GH_REF}</code>同理。<code>after_script</code>中的<code>user.name</code>，<code>user.email</code>，需要改成你自己的git用户名和邮箱，global中的<code>- GH_REF: github.com/peterxugo/peterxugo.github.io.git</code>需要换成自己的仓库地址。</p>\n<p>重点说明一下CI中安装pandoc，Ubuntu可以直接使用<code>sudo apt-get install pandoc</code>，但是这样安装在版本是1.19.1.X(2017-05-30)，我发现这个版本的Pandoc在解析table的时候存在一些问题，不能够正确的解析出一些表格。</p>\n<p>这个问题的发现过程如下：我本地mac使用hexo预览文章能够看到表格被正常渲染，但是CI构建后一直无法正常的显示表格，检查html代码发现没有正常的渲染为table，首先想到的是hexo版本问题，通过保证本地和CI环境中的Hexo及相关的软件的版本一致，但是问题依旧没有得到解决。最后猜想到可能是Pandoc的问题，于是查看构建的过程发现本地是Pandoc是pandoc 1.19.2.1,而CI上面apt库安装的版本是1.19.1.X，更新Pandoc版本后表格问题解决。</p>\n<p>由于我们需要将构建后的代码push到master分支上面，于是我们需要给CI相关的GItHub权限。我们可以通过GItHub提供的 Personal access token方法，将Token传给CI从而使得CI能够push代码。如下图先在GItHub中新增加一个 Personal access token，<strong>一定要记得复制生成的Token，不然就永远看不见这个Token</strong></p>\n<div class=\"figure\">\n<img src=\"/images/2017-05-30-12-05-17.jpg\" />\n\n</div>\n<p>登入到CI网站，对仓库进行相关的配置，先选中需要持续集成的仓库，这里是peterxugo/peterxugo.github.io,选中setting，然后开启相应的配置，最后在环境变量中加入刚才在GItHub中生产的token，变量可以在配置文件中用{}引用，pandoc的最新版本下载地址为<a href=\"https://github.com/jgm/pandoc/releases/download/1.19.2.1/pandoc-1.19.2.1-1-amd64.deb\" target=\"_blank\" rel=\"noopener\">Ubuntu pandoc 最新版本</a></p>\n<div class=\"figure\">\n<img src=\"/images/2017-05-30-12-16-17.jpg\" />\n\n</div>\n<div class=\"figure\">\n<img src=\"/images/2017-05-30-12-16-55.jpg\" />\n\n</div>\n<div class=\"figure\">\n<img src=\"/images/2017-05-30-12-17-43.jpg\" />\n\n</div>\n<p>最后，我们在本地代码中新建分支source_code，在该分支下执行提交代码</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git add . -A</span><br><span class=\"line\">git commit -m \"test CI\"</span><br><span class=\"line\">git push</span><br></pre></td></tr></table></figure>\n<p>一切配置正常的话，我们就可以看到CI中在构建博客的过程了，CI构建完成后就可以看到GitPage中的博客文章了。</p>\n<h2 id=\"参考\">5.参考</h2>\n<ol style=\"list-style-type: decimal\">\n<li><a href=\"https://segmentfault.com/a/1190000004667156\" target=\"_blank\" rel=\"noopener\">用 Travis CI 自动部署 hexo</a></li>\n<li><a href=\"http://shomy.top/2016/10/22/hexo-markdown-mathjax/\" target=\"_blank\" rel=\"noopener\">Hexo下mathjax的转义问题</a></li>\n<li><a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">hexo doc</a> 构建的到时候遇到的pandoc版本导致无法解析table问题</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"背景\">1.背景</h2>\n<p>自己在不断的学习，需要一个地方来记录，写博客也是能够对已经学过的东西进行一次系统的梳理，有利于对知识的巩固。但是博客就要考虑写和放的问题，写-自然就选择用<a href=\"http://wowubuntu.com/markdown/\" target=\"_blank\" rel=\"noopener\">markdown</a>了，主要考虑它是一个轻格式的，能够支持绝大部分的html格式，这也是现在写博客的主流。放选择了<a href=\"https://pages.github.com/\" target=\"_blank\" rel=\"noopener\">GitHub Page</a>，主要是不用钱，还可以顺道学习一下git相关的知识。</p>\n<h2 id=\"hexo是什么\">2.hexo是什么</h2>\n<p><a href=\"https://github.com/hexojs/hexo/stargazers\" target=\"_blank\" rel=\"noopener\">hexo</a>是基于Node.js的快速、简洁且高效的博客框架，能够快速的对markdown文件渲染为html，支持一键部署到GitHub Page，有着丰富的插件。hexo官方文档十分详实，从如何安装到文章发布，从切换主题到嵌入第三方服务，这里只做简单的摘抄，详细的过程还是需要参考<a href=\"https://hexo.io/zh-cn/docs/\" target=\"_blank\" rel=\"noopener\">文档</a></p>\n<p>首先，hexo的使用需要一些基本软件的支持，分别是<a href=\"https://github.com/nodejs/node\" target=\"_blank\" rel=\"noopener\">node</a>和git。 <figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brew install nvm ##安装Node.js版本管理的工具nvm</span><br><span class=\"line\">nvm install stable ##安装最新稳定版本的node</span><br><span class=\"line\">brew install git ##安装git，目前世界上最先进的分布式版本控制系统</span><br></pre></td></tr></table></figure></p>\n<p>hexo的安装部署很方便：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-cli -g ## 1.全局安装hexo</span><br><span class=\"line\">hexo init blog ##2.初始化博客文件夹</span><br><span class=\"line\">cd blog ##3.切换到博客文件夹</span><br><span class=\"line\">npm install ##4.安装hexo的依赖包</span><br><span class=\"line\">hexo server ##5.开启hexo本地网站服务</span><br></pre></td></tr></table></figure>\n<p>初始化的博客目录结构如下：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">.</span><br><span class=\"line\">├── _config.yml</span><br><span class=\"line\">├── package.json</span><br><span class=\"line\">├── scaffolds</span><br><span class=\"line\">├── source</span><br><span class=\"line\">|   ├── _drafts</span><br><span class=\"line\">|   └── _posts</span><br><span class=\"line\">└── themes</span><br></pre></td></tr></table></figure>\n<h2 id=\"pandoc-解决数学符号\">3.pandoc-解决数学符号</h2>\n<p><a href=\"https://www.mathjax.org/\" target=\"_blank\" rel=\"noopener\">Mathjax</a>可以解析网页上的数学公式，与hexo的结合也很简单，但是由hexo默认使用<a href=\"https://github.com/chjj/marked\" target=\"_blank\" rel=\"noopener\">marked.js</a>去解析我们写的markdown，Markdwon本身的特殊符号与Latex中的符号会出现冲突（其实很多其他的markdown引擎不会存在这些问题），比如一些符号，_代表斜体，会被处理为&lt;em&gt;标签，比如x_i在开始被渲染的时候，处理为x&lt;em&gt;i&lt;/em&gt;，这个时候mathjax就无法渲染成下标了。解决marked.js引擎带来的渲染公式问题的方法主要是以下三种：</p>\n<ul>\n<li>手动escape</li>\n<li><a href=\"https://liam0205.me/2015/09/09/fix-conflict-between-mathjax-and-markdown/\" target=\"_blank\" rel=\"noopener\">保护代码块</a></li>\n<li><a href=\"http://blog.csdn.net/emptyset110/article/details/50123231\" target=\"_blank\" rel=\"noopener\">修改Hexo渲染源码</a></li>\n</ul>\n<p>但是这些方法或多或少的都存在着一些问题，首先，手动escape需要对公式涉及到的每一个markdown关键词转义，例如：<code>\\$$f\\_i = f\\_{i + 1}\\$$</code>这样每一个关键词都要转义实在是太繁琐了，通用性很差,比如想迁移到其它地方，就无法识别了，因为大部分的markdown引擎是没有这个问题的。</p>\n<p>其次是保护代码块的方法，markdown中的两个`之间的东西不会转义例如这样<code>\\$f_i = f_{i + 1}\\$</code>，但是这样一来所有的公式的样式都是以code的形式来展现的，这个方法还有个问题，就是有时候我们的代码中会有$$的出现，这时候，仍然使用mathjax就有可能出现无法预料的结果了。</p>\n<p>最后的修改hexo的渲染源码太过于激进，而且不实用，且先不说无法保证所有字符能够正确的转义，而且有可能会丢失原来markdown的关键字语法，修改代码会带来不可预料的bug，日后的升级维护也会带来很多麻烦。</p>\n<p>说到底，数学公式的问题都是marked.js引擎导致的，那么为什么不直接换掉引擎呢，于是找到了<a href=\"http://pandoc.org/\" target=\"_blank\" rel=\"noopener\">Pandoc</a>的这个好东西。Pandoc是由John MacFarlane开发的标记语言转换工具，可实现不同标记语言间的格式转换，堪称该领域中的“瑞士军刀”，Pandoc的语法完全没有上述问题。使用Pandoc解析器只需要2步。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brew install pandoc ##安装pandoc软件</span><br><span class=\"line\">npm install hexo-renderer-pandoc ## 安装hexo的pandoc解析器</span><br></pre></td></tr></table></figure>\n<p>只需要2个命令，所有问题就都解决。有人会说pandoc太重了，是一个核弹级武器，用来解决数学符号问题引用一个这么大的软件实在是杀鸡用牛刀，但是“Life is short, you need Python”。</p>\n<h2 id=\"ci-自动构建\">4.CI-自动构建</h2>\n<p>hexo支持一键发布到GItHub Page和<a href=\"https://www.heroku.com/\" target=\"_blank\" rel=\"noopener\">HeroKu</a>等平台。具体参考官方文档中的<a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">deployment章节</a>，一般博主都是先本地搭建好hexo的环境，然后编写文章，最后使用hexo deploy来发布文章。</p>\n<p>但是，这样的使用方法有时会带来一些不便。首先，如果我想在另外一台设备上面写博客，必须将整个项目拷贝过来，完成之后要保持两台设备的内容是一致的，不然就会导致部署之后有不同的地方。在这种情况下一般会将整个项目都托管到 github 上面。但是这又会导致另外一个问题，每次有改动的时候不但要部署博客，还要提交项目的代码，这又增加了操作的步骤。</p>\n<p>那么有什么办法来优雅的解决这个问题呢？毕竟我只想安安静静的写个博客啊！是时候该让<a href=\"https://travis-ci.org/\" target=\"_blank\" rel=\"noopener\">Travis CI</a>上场了！顾名思义，Travis CI 是一个持续集成(Continuous integration，简称CI)的工具。它可以在公共的 Github 仓库上免费使用。核心思想是使用一个GitHub Page分支来管理所有博客的源代码，然后由CI编译发布到master主分支。</p>\n<p>Travis CI的持续集成非常的方便，尤其他对Github是无缝支持，只需要简单的三步：</p>\n<ol style=\"list-style-type: decimal\">\n<li>开启CI</li>\n<li>编写 .travis.yml</li>\n<li>触发</li>\n</ol>\n<p>首先使用GitHub账号登入在Travis CI，并在Travis中开启GItHub Page的持续集成，如下图</p>\n<div class=\"figure\">\n<img src=\"/images/2017-05-30-11-38-30.jpg\" />\n\n</div>\n<div class=\"figure\">\n<img src=\"/images/2017-05-30-11-30-06.jpg\" />\n\n</div>\n<p>然后设定自动构建过程的配置文件，在本地的blog的git库的顶级目录中新加文件.travis.yml，并添加以下内容： <figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">language:</span> <span class=\"string\">node_js</span></span><br><span class=\"line\"><span class=\"attr\">node_js:</span> <span class=\"string\">stable</span></span><br><span class=\"line\"><span class=\"attr\">cache:</span> </span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">pandoc</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">hexo-cli</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">hexo-renderer-pandoc</span></span><br><span class=\"line\"><span class=\"attr\">install:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">wget</span> <span class=\"string\">$&#123;pandoc&#125;</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">sudo</span> <span class=\"string\">dpkg</span> <span class=\"string\">-i</span> <span class=\"string\">pandoc*.deb</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">npm</span> <span class=\"string\">install</span> <span class=\"string\">-g</span> <span class=\"string\">hexo-cli</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">npm</span> <span class=\"string\">install</span> <span class=\"string\">hexo-renderer-pandoc</span> <span class=\"string\">--save</span></span><br><span class=\"line\"><span class=\"attr\">script:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">hexo</span> <span class=\"string\">clean</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">hexo</span> <span class=\"string\">g</span></span><br><span class=\"line\"><span class=\"attr\">after_script:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">cd</span> <span class=\"string\">./public</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">git</span> <span class=\"string\">init</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">git</span> <span class=\"string\">config</span> <span class=\"string\">user.name</span> <span class=\"string\">\"peterxu\"</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">git</span> <span class=\"string\">config</span> <span class=\"string\">user.email</span> <span class=\"string\">\"peterxugo@gmail.com\"</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">git</span> <span class=\"string\">add</span> <span class=\"string\">.</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">git</span> <span class=\"string\">commit</span> <span class=\"string\">-m</span> <span class=\"string\">\"Update\"</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"string\">git</span> <span class=\"string\">push</span> <span class=\"string\">--force</span> <span class=\"string\">--quiet</span> <span class=\"string\">\"https://$&#123;token&#125;@$&#123;GH_REF&#125;\"</span> <span class=\"string\">master:master</span></span><br><span class=\"line\"><span class=\"attr\">branches:</span></span><br><span class=\"line\">  <span class=\"attr\">only:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"string\">source_code</span></span><br><span class=\"line\"><span class=\"attr\">env:</span></span><br><span class=\"line\"> <span class=\"attr\">global:</span></span><br><span class=\"line\">   <span class=\"bullet\">-</span> <span class=\"attr\">GH_REF:</span> <span class=\"string\">github.com/peterxugo/peterxugo.github.io.git</span></span><br></pre></td></tr></table></figure></p>\n<p>配置文件中的<code>${pandoc}</code>是pandoc的下载地址，配置在CI的变量中，后面会具体讲如何设置该变量，同样的<code>${token},${GH_REF}</code>同理。<code>after_script</code>中的<code>user.name</code>，<code>user.email</code>，需要改成你自己的git用户名和邮箱，global中的<code>- GH_REF: github.com/peterxugo/peterxugo.github.io.git</code>需要换成自己的仓库地址。</p>\n<p>重点说明一下CI中安装pandoc，Ubuntu可以直接使用<code>sudo apt-get install pandoc</code>，但是这样安装在版本是1.19.1.X(2017-05-30)，我发现这个版本的Pandoc在解析table的时候存在一些问题，不能够正确的解析出一些表格。</p>\n<p>这个问题的发现过程如下：我本地mac使用hexo预览文章能够看到表格被正常渲染，但是CI构建后一直无法正常的显示表格，检查html代码发现没有正常的渲染为table，首先想到的是hexo版本问题，通过保证本地和CI环境中的Hexo及相关的软件的版本一致，但是问题依旧没有得到解决。最后猜想到可能是Pandoc的问题，于是查看构建的过程发现本地是Pandoc是pandoc 1.19.2.1,而CI上面apt库安装的版本是1.19.1.X，更新Pandoc版本后表格问题解决。</p>\n<p>由于我们需要将构建后的代码push到master分支上面，于是我们需要给CI相关的GItHub权限。我们可以通过GItHub提供的 Personal access token方法，将Token传给CI从而使得CI能够push代码。如下图先在GItHub中新增加一个 Personal access token，<strong>一定要记得复制生成的Token，不然就永远看不见这个Token</strong></p>\n<div class=\"figure\">\n<img src=\"/images/2017-05-30-12-05-17.jpg\" />\n\n</div>\n<p>登入到CI网站，对仓库进行相关的配置，先选中需要持续集成的仓库，这里是peterxugo/peterxugo.github.io,选中setting，然后开启相应的配置，最后在环境变量中加入刚才在GItHub中生产的token，变量可以在配置文件中用{}引用，pandoc的最新版本下载地址为<a href=\"https://github.com/jgm/pandoc/releases/download/1.19.2.1/pandoc-1.19.2.1-1-amd64.deb\" target=\"_blank\" rel=\"noopener\">Ubuntu pandoc 最新版本</a></p>\n<div class=\"figure\">\n<img src=\"/images/2017-05-30-12-16-17.jpg\" />\n\n</div>\n<div class=\"figure\">\n<img src=\"/images/2017-05-30-12-16-55.jpg\" />\n\n</div>\n<div class=\"figure\">\n<img src=\"/images/2017-05-30-12-17-43.jpg\" />\n\n</div>\n<p>最后，我们在本地代码中新建分支source_code，在该分支下执行提交代码</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git add . -A</span><br><span class=\"line\">git commit -m \"test CI\"</span><br><span class=\"line\">git push</span><br></pre></td></tr></table></figure>\n<p>一切配置正常的话，我们就可以看到CI中在构建博客的过程了，CI构建完成后就可以看到GitPage中的博客文章了。</p>\n<h2 id=\"参考\">5.参考</h2>\n<ol style=\"list-style-type: decimal\">\n<li><a href=\"https://segmentfault.com/a/1190000004667156\" target=\"_blank\" rel=\"noopener\">用 Travis CI 自动部署 hexo</a></li>\n<li><a href=\"http://shomy.top/2016/10/22/hexo-markdown-mathjax/\" target=\"_blank\" rel=\"noopener\">Hexo下mathjax的转义问题</a></li>\n<li><a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">hexo doc</a> 构建的到时候遇到的pandoc版本导致无法解析table问题</li>\n</ol>\n"},{"title":"nifi架构","date":"2017-06-06T15:42:29.000Z","_content":"\n\nnifi是运行在jvm上的一个软件,NIFI的主要组成部分如下：\n\n![](https://nifi.apache.org/docs/nifi-docs/html/images/zero-master-node.png)\n\n- **Web Server（网络服务）**\n\n    Web Server的主要作用是提供网页服务和rest api\n\n- **Flow Controller（流控制器）**\n\n    Flow Controller是NIIF操作的大脑。它为处理器（processor）提供线程执行任务，同时管理处理器的执行调度\n    \n- **Extensions（Preocessor处理器）**\n\n    NIFI中拥有众多的类型处理器，主要分为以下几类：\n    - Data Transformation（数据转换）\n    - Routing and Mediation（路由和调解）\n    - Database Access（数据库访问）\n    - Attribute Extraction（属性提取）\n    - System Interaction（系统交互）\n    - Data Ingestion（数据撷取）\n    - Data Egress / Sending Data（数据出口／数据发送）\n    - Splitting and Aggregation（拆分和聚合）\n    - HTTP\n    - Amazon Web Services（亚马逊网络服务）\n\n- **FlowFile Repository（流文件仓库）**\n\n    FlowFlie仓库是NIFI 保持追踪流中flowfile的相关信息的地方，仓库的实现是可插拔的，默认的方法是位于一个指定的磁盘分区持久写式日志。 Write-Ahead Log方法\n\n- **Content Repository（内容仓库）**\n\n    内容仓库是存储FlowFile的实际内容的地方。仓库的实现是可插拔的。默认的方法是相当简单的机制-直接在文件系统中存储数据块。可以指定多个系统存储地址从而获得不同的物理分区优化单个文件卷的IO性能问题\n \n- **Provenance Repository（源谱仓库）**\n\n    Provenance Repository是所有源谱事件数据的存储位置。该库的构建是可插拔使用，默认的实现是使用一个或多个物理磁盘卷。在每个位置的事件数据进行索引和搜索。\n\n\nNiFi同时也是支持集群的，如下\n\n![](https://nifi.apache.org/docs/nifi-docs/html/images/zero-master-cluster.png)\n\nNiFi 从1.0.0版本发布以来便已实现Zero-Master Clustering（不知道怎么翻译），每一个节点对不同对数据执行相同的操作。apache zookeeper选取一个节点作为协调器（Coordinator），zookeeper自动处理故障切换。所有集群的节点发送心跳和状态信息到集群的协调器，协调器负责连接和断开节点。此外，每一个集群一个都有zookeeper选举的主节点。操作人员可以从任何一个节点的用户界面（UI）的NiFi集群互动，所做的任何更改将被复制到集群中的所有节点，允许多个入口点。","source":"_posts/nifi架构.md","raw":"---\ntitle: nifi架构\ndate: 2017-06-06 23:42:29\ntags: 笔记\ncategories: apache nifi\n---\n\n\nnifi是运行在jvm上的一个软件,NIFI的主要组成部分如下：\n\n![](https://nifi.apache.org/docs/nifi-docs/html/images/zero-master-node.png)\n\n- **Web Server（网络服务）**\n\n    Web Server的主要作用是提供网页服务和rest api\n\n- **Flow Controller（流控制器）**\n\n    Flow Controller是NIIF操作的大脑。它为处理器（processor）提供线程执行任务，同时管理处理器的执行调度\n    \n- **Extensions（Preocessor处理器）**\n\n    NIFI中拥有众多的类型处理器，主要分为以下几类：\n    - Data Transformation（数据转换）\n    - Routing and Mediation（路由和调解）\n    - Database Access（数据库访问）\n    - Attribute Extraction（属性提取）\n    - System Interaction（系统交互）\n    - Data Ingestion（数据撷取）\n    - Data Egress / Sending Data（数据出口／数据发送）\n    - Splitting and Aggregation（拆分和聚合）\n    - HTTP\n    - Amazon Web Services（亚马逊网络服务）\n\n- **FlowFile Repository（流文件仓库）**\n\n    FlowFlie仓库是NIFI 保持追踪流中flowfile的相关信息的地方，仓库的实现是可插拔的，默认的方法是位于一个指定的磁盘分区持久写式日志。 Write-Ahead Log方法\n\n- **Content Repository（内容仓库）**\n\n    内容仓库是存储FlowFile的实际内容的地方。仓库的实现是可插拔的。默认的方法是相当简单的机制-直接在文件系统中存储数据块。可以指定多个系统存储地址从而获得不同的物理分区优化单个文件卷的IO性能问题\n \n- **Provenance Repository（源谱仓库）**\n\n    Provenance Repository是所有源谱事件数据的存储位置。该库的构建是可插拔使用，默认的实现是使用一个或多个物理磁盘卷。在每个位置的事件数据进行索引和搜索。\n\n\nNiFi同时也是支持集群的，如下\n\n![](https://nifi.apache.org/docs/nifi-docs/html/images/zero-master-cluster.png)\n\nNiFi 从1.0.0版本发布以来便已实现Zero-Master Clustering（不知道怎么翻译），每一个节点对不同对数据执行相同的操作。apache zookeeper选取一个节点作为协调器（Coordinator），zookeeper自动处理故障切换。所有集群的节点发送心跳和状态信息到集群的协调器，协调器负责连接和断开节点。此外，每一个集群一个都有zookeeper选举的主节点。操作人员可以从任何一个节点的用户界面（UI）的NiFi集群互动，所做的任何更改将被复制到集群中的所有节点，允许多个入口点。","slug":"nifi架构","published":1,"updated":"2017-09-28T10:52:58.657Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8cgqo7j00083szy6suegqo8","content":"<p>nifi是运行在jvm上的一个软件,NIFI的主要组成部分如下：</p>\n<div class=\"figure\">\n<img src=\"https://nifi.apache.org/docs/nifi-docs/html/images/zero-master-node.png\" />\n\n</div>\n<ul>\n<li><p><strong>Web Server（网络服务）</strong></p>\n<p>Web Server的主要作用是提供网页服务和rest api</p></li>\n<li><p><strong>Flow Controller（流控制器）</strong></p>\n<p>Flow Controller是NIIF操作的大脑。它为处理器（processor）提供线程执行任务，同时管理处理器的执行调度</p></li>\n<li><p><strong>Extensions（Preocessor处理器）</strong></p>\nNIFI中拥有众多的类型处理器，主要分为以下几类：\n<ul>\n<li>Data Transformation（数据转换）</li>\n<li>Routing and Mediation（路由和调解）</li>\n<li>Database Access（数据库访问）</li>\n<li>Attribute Extraction（属性提取）</li>\n<li>System Interaction（系统交互）</li>\n<li>Data Ingestion（数据撷取）</li>\n<li>Data Egress / Sending Data（数据出口／数据发送）</li>\n<li>Splitting and Aggregation（拆分和聚合）</li>\n<li>HTTP</li>\n<li>Amazon Web Services（亚马逊网络服务）</li>\n</ul></li>\n<li><p><strong>FlowFile Repository（流文件仓库）</strong></p>\n<p>FlowFlie仓库是NIFI 保持追踪流中flowfile的相关信息的地方，仓库的实现是可插拔的，默认的方法是位于一个指定的磁盘分区持久写式日志。 Write-Ahead Log方法</p></li>\n<li><p><strong>Content Repository（内容仓库）</strong></p>\n<p>内容仓库是存储FlowFile的实际内容的地方。仓库的实现是可插拔的。默认的方法是相当简单的机制-直接在文件系统中存储数据块。可以指定多个系统存储地址从而获得不同的物理分区优化单个文件卷的IO性能问题</p></li>\n<li><p><strong>Provenance Repository（源谱仓库）</strong></p>\n<p>Provenance Repository是所有源谱事件数据的存储位置。该库的构建是可插拔使用，默认的实现是使用一个或多个物理磁盘卷。在每个位置的事件数据进行索引和搜索。</p></li>\n</ul>\n<p>NiFi同时也是支持集群的，如下</p>\n<div class=\"figure\">\n<img src=\"https://nifi.apache.org/docs/nifi-docs/html/images/zero-master-cluster.png\" />\n\n</div>\n<p>NiFi 从1.0.0版本发布以来便已实现Zero-Master Clustering（不知道怎么翻译），每一个节点对不同对数据执行相同的操作。apache zookeeper选取一个节点作为协调器（Coordinator），zookeeper自动处理故障切换。所有集群的节点发送心跳和状态信息到集群的协调器，协调器负责连接和断开节点。此外，每一个集群一个都有zookeeper选举的主节点。操作人员可以从任何一个节点的用户界面（UI）的NiFi集群互动，所做的任何更改将被复制到集群中的所有节点，允许多个入口点。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>nifi是运行在jvm上的一个软件,NIFI的主要组成部分如下：</p>\n<div class=\"figure\">\n<img src=\"https://nifi.apache.org/docs/nifi-docs/html/images/zero-master-node.png\" />\n\n</div>\n<ul>\n<li><p><strong>Web Server（网络服务）</strong></p>\n<p>Web Server的主要作用是提供网页服务和rest api</p></li>\n<li><p><strong>Flow Controller（流控制器）</strong></p>\n<p>Flow Controller是NIIF操作的大脑。它为处理器（processor）提供线程执行任务，同时管理处理器的执行调度</p></li>\n<li><p><strong>Extensions（Preocessor处理器）</strong></p>\nNIFI中拥有众多的类型处理器，主要分为以下几类：\n<ul>\n<li>Data Transformation（数据转换）</li>\n<li>Routing and Mediation（路由和调解）</li>\n<li>Database Access（数据库访问）</li>\n<li>Attribute Extraction（属性提取）</li>\n<li>System Interaction（系统交互）</li>\n<li>Data Ingestion（数据撷取）</li>\n<li>Data Egress / Sending Data（数据出口／数据发送）</li>\n<li>Splitting and Aggregation（拆分和聚合）</li>\n<li>HTTP</li>\n<li>Amazon Web Services（亚马逊网络服务）</li>\n</ul></li>\n<li><p><strong>FlowFile Repository（流文件仓库）</strong></p>\n<p>FlowFlie仓库是NIFI 保持追踪流中flowfile的相关信息的地方，仓库的实现是可插拔的，默认的方法是位于一个指定的磁盘分区持久写式日志。 Write-Ahead Log方法</p></li>\n<li><p><strong>Content Repository（内容仓库）</strong></p>\n<p>内容仓库是存储FlowFile的实际内容的地方。仓库的实现是可插拔的。默认的方法是相当简单的机制-直接在文件系统中存储数据块。可以指定多个系统存储地址从而获得不同的物理分区优化单个文件卷的IO性能问题</p></li>\n<li><p><strong>Provenance Repository（源谱仓库）</strong></p>\n<p>Provenance Repository是所有源谱事件数据的存储位置。该库的构建是可插拔使用，默认的实现是使用一个或多个物理磁盘卷。在每个位置的事件数据进行索引和搜索。</p></li>\n</ul>\n<p>NiFi同时也是支持集群的，如下</p>\n<div class=\"figure\">\n<img src=\"https://nifi.apache.org/docs/nifi-docs/html/images/zero-master-cluster.png\" />\n\n</div>\n<p>NiFi 从1.0.0版本发布以来便已实现Zero-Master Clustering（不知道怎么翻译），每一个节点对不同对数据执行相同的操作。apache zookeeper选取一个节点作为协调器（Coordinator），zookeeper自动处理故障切换。所有集群的节点发送心跳和状态信息到集群的协调器，协调器负责连接和断开节点。此外，每一个集群一个都有zookeeper选举的主节点。操作人员可以从任何一个节点的用户界面（UI）的NiFi集群互动，所做的任何更改将被复制到集群中的所有节点，允许多个入口点。</p>\n"},{"layout":"draft","title":"采用hue使用oozie调度sqoop问题","date":"2018-01-27T06:16:38.000Z","_content":"\n##环境\n\n软件|版本|备注\n---|---|---|\nHDP|2.6.3|2rm+3nm(=48g,24c)+1client|\nHue|4.1.0|client节点|\ncentos|7.0||\n\n其他：\n\n1. slave2+master1在一个母机\n2. slave1,slave3,master2在一个母机\n3. 母机之间是万兆网卡\n\n\n##部署过程\n\n1. 运维帮忙安装必要的依赖包(curl,jdk8+,ntp,openssl 1.01,python 2.7.x ,rpm,scp,tar,unzip,wget,yum)\n2. 通过ambari先部署的hdp基础的hadoop环境，然后部署的oozie，保证配置，软件环境等一致。\n\n\n##调试过程\n在Hue的editor下使用sqoop执行 \n\n```bash\nimport   --connect jdbc:mysql://xx:3306/xx --username xx --password xx --table weight --hive-table tmp.test --hive-import  --hive-overwrite -m 1\n```\n\n\n###问题1：只安装了jre没有安装jdk\n主要报错内容 \n\n```bash \n13/04/19 10:35:24 ERROR tool.ImportTool: Encountered IOException running import job: java.io.IOException: Could not start Java compiler.\n```\n\n解决思路\n\n1. 首先安装java-1.7.0-openjdk-devel `yum install -y java-1.7.0-openjdk-devel`\n2. 整个平台的jdk路径由ambari-server分发,配置ambari.properties中java.home=/usr/lib/jvm/java\n3. 重启整个平台，ambari分发配置\n\n\n\n###问题2：hiveconf class not find\n\n主要报错内容\n\n```bash\n    Could not load org.apache.hadoop.hive.conf.HiveConf. Make sure HIVE_CONF_DIR is set correctly.\n     \n    Encountered IOException running import job: java.io.IOException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.conf.HiveConf\n    \n```\n\n解决思路\n\n1. oozie在安装的时候回自动在hdfs中上传对应的jar包，更加action的类型取classpath，sqoop该action没有将hive的jar包含进来\n2. 可以通过设置oozie.action.sharelib.for.{action}参数来指定某个action的全局classpath，所以设置oozie.action.sharelib.for.sqoop=sqoop,hive\n3. 重启oozie服务\n\n\n###问题3：system kill 没有hive-site.xml\n主要报错内容:\n\n```bash\nMain class [org.apache.oozie.action.hadoop.SqoopMain], exit code [1]\n```\n只有这么一句话没有其他任何对应的提示，通过google发现很多报错都是这个信息，但是对应不同的具体错误\n\n解决方案\n\n1. 尝试直接用oozie调度hive，可以成功的写入hive\n2. 发现每次oozie调度sqoop的时候都能够写入hdfs，说明最后一步写入hive出错\n3. 结合网上的资料发现需要制定hive-site.xml,tez-site.xml\n4. 考虑到都是新人就直接全局把hive-site.xml,tez-site.xml放到sqoop这个sharelib中，并update\n5. 重启oozie服务\n\n###问题4：hue默认不开启rerun参数\n\n主要报错内容\n\n```bash\nMain class [org.apache.oozie.action.hadoop.SqoopMain], exit code [1]\n```\n和上面的完全一致，但是偶尔成功，通过观察发现sqoop这个job如果是在slave2节点上启动的时候都成功，但是如果是其他节点启动sqoop的container就会失败，于是认为是节点之间的环境不一致，但是ambari统一部署的不会存在环境问题，怀疑是网络不稳定，同时多次试验发现slave2也会出现失败，其他节点也会有极小的概率成功\n\n解决过程：\n\n1. oozie的报错真的很不友好，基本上靠猜。\n2. 想到会不会是hue和hdp水土不服，毕竟之前有hive的教训，hdp中要加入hive.server2.parallel.ops.in.session=true，否则hue中无法正常使用hive。\n3. 尝试使用ambari的workflow view来编写调度，一样的命令发现可以执行，发现2者的workflow不完全一直，action的版本上面有一些差异\n4. 对应在hue中修改一致workflow，但是发现还是不行，继续查找到job.properties中的重要信息oozie.wf.rerun.failnodes=true\n5. 参考[oozie官网](https://oozie.apache.org/docs/3.1.3-incubating/DG_WorkflowReRun.html)说明也是很少\n6. hue中workflow加上该参数，发现可以执行\n7. 考虑到sqoop前期用的很多，hue中的sqoop editor没有可以设置参数的地方，于是全局设置oozie.wf.rerun.failnodes=true\n8. 重启服务，一切正常\n\n##后话\n部署软件调试是一个细心的活，尤其是对于这种报错信息极少的，需要靠经验来猜，而自己经验有不足。","source":"_posts/oozie调度sqoop问题.md","raw":"---\nlayout: draft\ntitle: 采用hue使用oozie调度sqoop问题\ndate: 2018-01-27 14:16:38\ntags:\n---\n\n##环境\n\n软件|版本|备注\n---|---|---|\nHDP|2.6.3|2rm+3nm(=48g,24c)+1client|\nHue|4.1.0|client节点|\ncentos|7.0||\n\n其他：\n\n1. slave2+master1在一个母机\n2. slave1,slave3,master2在一个母机\n3. 母机之间是万兆网卡\n\n\n##部署过程\n\n1. 运维帮忙安装必要的依赖包(curl,jdk8+,ntp,openssl 1.01,python 2.7.x ,rpm,scp,tar,unzip,wget,yum)\n2. 通过ambari先部署的hdp基础的hadoop环境，然后部署的oozie，保证配置，软件环境等一致。\n\n\n##调试过程\n在Hue的editor下使用sqoop执行 \n\n```bash\nimport   --connect jdbc:mysql://xx:3306/xx --username xx --password xx --table weight --hive-table tmp.test --hive-import  --hive-overwrite -m 1\n```\n\n\n###问题1：只安装了jre没有安装jdk\n主要报错内容 \n\n```bash \n13/04/19 10:35:24 ERROR tool.ImportTool: Encountered IOException running import job: java.io.IOException: Could not start Java compiler.\n```\n\n解决思路\n\n1. 首先安装java-1.7.0-openjdk-devel `yum install -y java-1.7.0-openjdk-devel`\n2. 整个平台的jdk路径由ambari-server分发,配置ambari.properties中java.home=/usr/lib/jvm/java\n3. 重启整个平台，ambari分发配置\n\n\n\n###问题2：hiveconf class not find\n\n主要报错内容\n\n```bash\n    Could not load org.apache.hadoop.hive.conf.HiveConf. Make sure HIVE_CONF_DIR is set correctly.\n     \n    Encountered IOException running import job: java.io.IOException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.conf.HiveConf\n    \n```\n\n解决思路\n\n1. oozie在安装的时候回自动在hdfs中上传对应的jar包，更加action的类型取classpath，sqoop该action没有将hive的jar包含进来\n2. 可以通过设置oozie.action.sharelib.for.{action}参数来指定某个action的全局classpath，所以设置oozie.action.sharelib.for.sqoop=sqoop,hive\n3. 重启oozie服务\n\n\n###问题3：system kill 没有hive-site.xml\n主要报错内容:\n\n```bash\nMain class [org.apache.oozie.action.hadoop.SqoopMain], exit code [1]\n```\n只有这么一句话没有其他任何对应的提示，通过google发现很多报错都是这个信息，但是对应不同的具体错误\n\n解决方案\n\n1. 尝试直接用oozie调度hive，可以成功的写入hive\n2. 发现每次oozie调度sqoop的时候都能够写入hdfs，说明最后一步写入hive出错\n3. 结合网上的资料发现需要制定hive-site.xml,tez-site.xml\n4. 考虑到都是新人就直接全局把hive-site.xml,tez-site.xml放到sqoop这个sharelib中，并update\n5. 重启oozie服务\n\n###问题4：hue默认不开启rerun参数\n\n主要报错内容\n\n```bash\nMain class [org.apache.oozie.action.hadoop.SqoopMain], exit code [1]\n```\n和上面的完全一致，但是偶尔成功，通过观察发现sqoop这个job如果是在slave2节点上启动的时候都成功，但是如果是其他节点启动sqoop的container就会失败，于是认为是节点之间的环境不一致，但是ambari统一部署的不会存在环境问题，怀疑是网络不稳定，同时多次试验发现slave2也会出现失败，其他节点也会有极小的概率成功\n\n解决过程：\n\n1. oozie的报错真的很不友好，基本上靠猜。\n2. 想到会不会是hue和hdp水土不服，毕竟之前有hive的教训，hdp中要加入hive.server2.parallel.ops.in.session=true，否则hue中无法正常使用hive。\n3. 尝试使用ambari的workflow view来编写调度，一样的命令发现可以执行，发现2者的workflow不完全一直，action的版本上面有一些差异\n4. 对应在hue中修改一致workflow，但是发现还是不行，继续查找到job.properties中的重要信息oozie.wf.rerun.failnodes=true\n5. 参考[oozie官网](https://oozie.apache.org/docs/3.1.3-incubating/DG_WorkflowReRun.html)说明也是很少\n6. hue中workflow加上该参数，发现可以执行\n7. 考虑到sqoop前期用的很多，hue中的sqoop editor没有可以设置参数的地方，于是全局设置oozie.wf.rerun.failnodes=true\n8. 重启服务，一切正常\n\n##后话\n部署软件调试是一个细心的活，尤其是对于这种报错信息极少的，需要靠经验来猜，而自己经验有不足。","slug":"oozie调度sqoop问题","published":1,"updated":"2018-02-02T13:46:39.540Z","comments":1,"photos":[],"link":"","_id":"ck8cgqo7k00093szy69a1chwq","content":"<h2 id=\"环境\">环境</h2>\n<table>\n<thead>\n<tr class=\"header\">\n<th>软件</th>\n<th>版本</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td>HDP</td>\n<td>2.6.3</td>\n<td>2rm+3nm(=48g,24c)+1client</td>\n</tr>\n<tr class=\"even\">\n<td>Hue</td>\n<td>4.1.0</td>\n<td>client节点</td>\n</tr>\n<tr class=\"odd\">\n<td>centos</td>\n<td>7.0</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p>其他：</p>\n<ol style=\"list-style-type: decimal\">\n<li>slave2+master1在一个母机</li>\n<li>slave1,slave3,master2在一个母机</li>\n<li>母机之间是万兆网卡</li>\n</ol>\n<h2 id=\"部署过程\">部署过程</h2>\n<ol style=\"list-style-type: decimal\">\n<li>运维帮忙安装必要的依赖包(curl,jdk8+,ntp,openssl 1.01,python 2.7.x ,rpm,scp,tar,unzip,wget,yum)</li>\n<li>通过ambari先部署的hdp基础的hadoop环境，然后部署的oozie，保证配置，软件环境等一致。</li>\n</ol>\n<h2 id=\"调试过程\">调试过程</h2>\n<p>在Hue的editor下使用sqoop执行</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import   --connect jdbc:mysql://xx:3306/xx --username xx --password xx --table weight --hive-table tmp.test --hive-import  --hive-overwrite -m 1</span><br></pre></td></tr></table></figure>\n<h3 id=\"问题1只安装了jre没有安装jdk\">问题1：只安装了jre没有安装jdk</h3>\n<p>主要报错内容</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">13/04/19 10:35:24 ERROR tool.ImportTool: Encountered IOException running import job: java.io.IOException: Could not start Java compiler.</span><br></pre></td></tr></table></figure>\n<p>解决思路</p>\n<ol style=\"list-style-type: decimal\">\n<li>首先安装java-1.7.0-openjdk-devel <code>yum install -y java-1.7.0-openjdk-devel</code></li>\n<li>整个平台的jdk路径由ambari-server分发,配置ambari.properties中java.home=/usr/lib/jvm/java</li>\n<li>重启整个平台，ambari分发配置</li>\n</ol>\n<h3 id=\"问题2hiveconf-class-not-find\">问题2：hiveconf class not find</h3>\n<p>主要报错内容</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Could not load org.apache.hadoop.hive.conf.HiveConf. Make sure HIVE_CONF_DIR is <span class=\"built_in\">set</span> correctly.</span><br><span class=\"line\"> </span><br><span class=\"line\">Encountered IOException running import job: java.io.IOException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.conf.HiveConf</span><br></pre></td></tr></table></figure>\n<p>解决思路</p>\n<ol style=\"list-style-type: decimal\">\n<li>oozie在安装的时候回自动在hdfs中上传对应的jar包，更加action的类型取classpath，sqoop该action没有将hive的jar包含进来</li>\n<li>可以通过设置oozie.action.sharelib.for.{action}参数来指定某个action的全局classpath，所以设置oozie.action.sharelib.for.sqoop=sqoop,hive</li>\n<li>重启oozie服务</li>\n</ol>\n<h3 id=\"问题3system-kill-没有hive-site.xml\">问题3：system kill 没有hive-site.xml</h3>\n<p>主要报错内容:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Main class [org.apache.oozie.action.hadoop.SqoopMain], <span class=\"built_in\">exit</span> code [1]</span><br></pre></td></tr></table></figure>\n<p>只有这么一句话没有其他任何对应的提示，通过google发现很多报错都是这个信息，但是对应不同的具体错误</p>\n<p>解决方案</p>\n<ol style=\"list-style-type: decimal\">\n<li>尝试直接用oozie调度hive，可以成功的写入hive</li>\n<li>发现每次oozie调度sqoop的时候都能够写入hdfs，说明最后一步写入hive出错</li>\n<li>结合网上的资料发现需要制定hive-site.xml,tez-site.xml</li>\n<li>考虑到都是新人就直接全局把hive-site.xml,tez-site.xml放到sqoop这个sharelib中，并update</li>\n<li>重启oozie服务</li>\n</ol>\n<h3 id=\"问题4hue默认不开启rerun参数\">问题4：hue默认不开启rerun参数</h3>\n<p>主要报错内容</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Main class [org.apache.oozie.action.hadoop.SqoopMain], <span class=\"built_in\">exit</span> code [1]</span><br></pre></td></tr></table></figure>\n<p>和上面的完全一致，但是偶尔成功，通过观察发现sqoop这个job如果是在slave2节点上启动的时候都成功，但是如果是其他节点启动sqoop的container就会失败，于是认为是节点之间的环境不一致，但是ambari统一部署的不会存在环境问题，怀疑是网络不稳定，同时多次试验发现slave2也会出现失败，其他节点也会有极小的概率成功</p>\n<p>解决过程：</p>\n<ol style=\"list-style-type: decimal\">\n<li>oozie的报错真的很不友好，基本上靠猜。</li>\n<li>想到会不会是hue和hdp水土不服，毕竟之前有hive的教训，hdp中要加入hive.server2.parallel.ops.in.session=true，否则hue中无法正常使用hive。</li>\n<li>尝试使用ambari的workflow view来编写调度，一样的命令发现可以执行，发现2者的workflow不完全一直，action的版本上面有一些差异</li>\n<li>对应在hue中修改一致workflow，但是发现还是不行，继续查找到job.properties中的重要信息oozie.wf.rerun.failnodes=true</li>\n<li>参考<a href=\"https://oozie.apache.org/docs/3.1.3-incubating/DG_WorkflowReRun.html\" target=\"_blank\" rel=\"noopener\">oozie官网</a>说明也是很少</li>\n<li>hue中workflow加上该参数，发现可以执行</li>\n<li>考虑到sqoop前期用的很多，hue中的sqoop editor没有可以设置参数的地方，于是全局设置oozie.wf.rerun.failnodes=true</li>\n<li>重启服务，一切正常</li>\n</ol>\n<h2 id=\"后话\">后话</h2>\n<p>部署软件调试是一个细心的活，尤其是对于这种报错信息极少的，需要靠经验来猜，而自己经验有不足。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"环境\">环境</h2>\n<table>\n<thead>\n<tr class=\"header\">\n<th>软件</th>\n<th>版本</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td>HDP</td>\n<td>2.6.3</td>\n<td>2rm+3nm(=48g,24c)+1client</td>\n</tr>\n<tr class=\"even\">\n<td>Hue</td>\n<td>4.1.0</td>\n<td>client节点</td>\n</tr>\n<tr class=\"odd\">\n<td>centos</td>\n<td>7.0</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p>其他：</p>\n<ol style=\"list-style-type: decimal\">\n<li>slave2+master1在一个母机</li>\n<li>slave1,slave3,master2在一个母机</li>\n<li>母机之间是万兆网卡</li>\n</ol>\n<h2 id=\"部署过程\">部署过程</h2>\n<ol style=\"list-style-type: decimal\">\n<li>运维帮忙安装必要的依赖包(curl,jdk8+,ntp,openssl 1.01,python 2.7.x ,rpm,scp,tar,unzip,wget,yum)</li>\n<li>通过ambari先部署的hdp基础的hadoop环境，然后部署的oozie，保证配置，软件环境等一致。</li>\n</ol>\n<h2 id=\"调试过程\">调试过程</h2>\n<p>在Hue的editor下使用sqoop执行</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import   --connect jdbc:mysql://xx:3306/xx --username xx --password xx --table weight --hive-table tmp.test --hive-import  --hive-overwrite -m 1</span><br></pre></td></tr></table></figure>\n<h3 id=\"问题1只安装了jre没有安装jdk\">问题1：只安装了jre没有安装jdk</h3>\n<p>主要报错内容</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">13/04/19 10:35:24 ERROR tool.ImportTool: Encountered IOException running import job: java.io.IOException: Could not start Java compiler.</span><br></pre></td></tr></table></figure>\n<p>解决思路</p>\n<ol style=\"list-style-type: decimal\">\n<li>首先安装java-1.7.0-openjdk-devel <code>yum install -y java-1.7.0-openjdk-devel</code></li>\n<li>整个平台的jdk路径由ambari-server分发,配置ambari.properties中java.home=/usr/lib/jvm/java</li>\n<li>重启整个平台，ambari分发配置</li>\n</ol>\n<h3 id=\"问题2hiveconf-class-not-find\">问题2：hiveconf class not find</h3>\n<p>主要报错内容</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Could not load org.apache.hadoop.hive.conf.HiveConf. Make sure HIVE_CONF_DIR is <span class=\"built_in\">set</span> correctly.</span><br><span class=\"line\"> </span><br><span class=\"line\">Encountered IOException running import job: java.io.IOException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.conf.HiveConf</span><br></pre></td></tr></table></figure>\n<p>解决思路</p>\n<ol style=\"list-style-type: decimal\">\n<li>oozie在安装的时候回自动在hdfs中上传对应的jar包，更加action的类型取classpath，sqoop该action没有将hive的jar包含进来</li>\n<li>可以通过设置oozie.action.sharelib.for.{action}参数来指定某个action的全局classpath，所以设置oozie.action.sharelib.for.sqoop=sqoop,hive</li>\n<li>重启oozie服务</li>\n</ol>\n<h3 id=\"问题3system-kill-没有hive-site.xml\">问题3：system kill 没有hive-site.xml</h3>\n<p>主要报错内容:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Main class [org.apache.oozie.action.hadoop.SqoopMain], <span class=\"built_in\">exit</span> code [1]</span><br></pre></td></tr></table></figure>\n<p>只有这么一句话没有其他任何对应的提示，通过google发现很多报错都是这个信息，但是对应不同的具体错误</p>\n<p>解决方案</p>\n<ol style=\"list-style-type: decimal\">\n<li>尝试直接用oozie调度hive，可以成功的写入hive</li>\n<li>发现每次oozie调度sqoop的时候都能够写入hdfs，说明最后一步写入hive出错</li>\n<li>结合网上的资料发现需要制定hive-site.xml,tez-site.xml</li>\n<li>考虑到都是新人就直接全局把hive-site.xml,tez-site.xml放到sqoop这个sharelib中，并update</li>\n<li>重启oozie服务</li>\n</ol>\n<h3 id=\"问题4hue默认不开启rerun参数\">问题4：hue默认不开启rerun参数</h3>\n<p>主要报错内容</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Main class [org.apache.oozie.action.hadoop.SqoopMain], <span class=\"built_in\">exit</span> code [1]</span><br></pre></td></tr></table></figure>\n<p>和上面的完全一致，但是偶尔成功，通过观察发现sqoop这个job如果是在slave2节点上启动的时候都成功，但是如果是其他节点启动sqoop的container就会失败，于是认为是节点之间的环境不一致，但是ambari统一部署的不会存在环境问题，怀疑是网络不稳定，同时多次试验发现slave2也会出现失败，其他节点也会有极小的概率成功</p>\n<p>解决过程：</p>\n<ol style=\"list-style-type: decimal\">\n<li>oozie的报错真的很不友好，基本上靠猜。</li>\n<li>想到会不会是hue和hdp水土不服，毕竟之前有hive的教训，hdp中要加入hive.server2.parallel.ops.in.session=true，否则hue中无法正常使用hive。</li>\n<li>尝试使用ambari的workflow view来编写调度，一样的命令发现可以执行，发现2者的workflow不完全一直，action的版本上面有一些差异</li>\n<li>对应在hue中修改一致workflow，但是发现还是不行，继续查找到job.properties中的重要信息oozie.wf.rerun.failnodes=true</li>\n<li>参考<a href=\"https://oozie.apache.org/docs/3.1.3-incubating/DG_WorkflowReRun.html\" target=\"_blank\" rel=\"noopener\">oozie官网</a>说明也是很少</li>\n<li>hue中workflow加上该参数，发现可以执行</li>\n<li>考虑到sqoop前期用的很多，hue中的sqoop editor没有可以设置参数的地方，于是全局设置oozie.wf.rerun.failnodes=true</li>\n<li>重启服务，一切正常</li>\n</ol>\n<h2 id=\"后话\">后话</h2>\n<p>部署软件调试是一个细心的活，尤其是对于这种报错信息极少的，需要靠经验来猜，而自己经验有不足。</p>\n"},{"layout":"graft","title":"pilosa-data-mode","date":"2019-02-02T03:35:02.000Z","_content":"\n## 数据模型\n### 概观\n\nPilosa数据模型核心就是布尔矩阵，矩阵中的每个单元是一个位（计算机存储最小单位），每一个bit代表着行和列之间存在关系（通常是是或者否）\n\n任何的实体都可以成为行和列，行和列也可以是同样的实体比如[bigraph](https://en.wikipedia.org/wiki/Bigraph)。Pilosa可以将任意键/值对（称为属性）与行和列相关联，但查询和存储在围绕矩阵核心进行优化。\n\nPilosa lays out data first in rows, so queries which get all the set bits in one or many rows, or compute a combining operation—such as Intersect or Union—on multiple rows, are the fastest. Pilosa categorizes rows into different *fields* and quickly retrieves the top rows in a field sorted by the number of columns set in each row.\n\nPlease note that Pilosa is most performant when row and column IDs are sequential starting from 0. You can deviate from this to some degree, but setting a bit with column ID 2<sup>63</sup> on a single-node cluster, for example, will not work well due to memory limitations.\n\n![basic data model diagram](/img/docs/data-model.png)\n*Basic data model diagram*\n\n\n\n\n### Index\n\nThe purpose of the Index is to represent a data namespace. You cannot perform cross-index queries.\n\n### Column\n\nColumn ids are sequential, increasing integers and they are common to all Fields within an Index. A single column often corresponds to a record in a relational table, although other configurations are possible, and sometimes preferable.\n\n### Row\n\nRow ids are sequential, increasing integers namespaced to each Field within an Index.\n\n### Field\n\nFields are used to segment rows within an index, for example to define different functional groups. A Pilosa field might correspond to a single field in a relational table, where each row in a standard Pilosa field represents a single possible value of the relational field. Similarly, an integer field could represent all possible integer values of a relational field.\n\n#### Relational Analogy\n\nThe Pilosa index is a flexible structure; it can represent any sort of high-cardinality binary matrix. We have explored a number of modeling patterns in Pilosa use cases; one accessible example is a direct analogy to the relational model, summarized here.\n\nEntities:\n\n Relational  | Pilosa\n-------------|----------------------------------------------\n Database    | N/A *(internal: Holder)*\n Table       | Index\n Row         | Column\n Column      | Field\n Value       | Row\n Value (int) | Field.Value (see [BSI](#bsi-range-encoding))\n\nSimple queries:\n\n Relational                                    | Pilosa\n-----------------------------------------------|------------------------------------\n `select ID from People where Name = 'Bob'`    | `Row(Name=\"Bob\")`\n `select ID from People where Age > 30`        | `Row(Age > 30)`\n `select ID from People where Member = true`   | `Row(Member=0)`\n\nNote that `Row(Member=0)` selects all entities with a bit set in row 0 of the Member field. We could just as well use row 1 to store this, in which case we would use `Row(Member=1)`, which looks a bit more intuitive. In the relational model, joins are often necessary. Because Pilosa supports extremely high cardinality in both rows and columns, many types of joins are accomplished with basic Pilosa queries across multiple fields. For example, this SQL join:\n\n```sql\nselect AVG(p.Age) from People p\ninner join PersonCar pc on pc.PersonID=p.ID\ninner join Cars c on pc.CarID=c.ID\nwhere c.Make = 'Ford'\n```\n\ncan be accomplished with a Pilosa query like this (note that [Sum](../query-language/#sum) returns a json object containing both the sum and count, from which the average is easily computed):\n\n```pql\nSum(Row(Car-Make=\"Ford\"), field=Age)\n```\n\nThis is one major component of Pilosa's ability to combine relationships from multiple data stores.\n\n#### Ranked\n\nRanked Fields maintain a sorted cache of column counts by Row ID (yielding the top rows by columns with a bit set in each). This cache facilitates the TopN query. The cache size defaults to 50,000 and can be set at Field creation.\n\n![ranked field diagram](/img/docs/field-ranked.png)\n*Ranked field diagram*\n\n#### LRU\n\nThe LRU cache maintains the most recently accessed Rows.\n\n![lru field diagram](/img/docs/field-lru.png)\n*LRU field diagram*\n\n### Time Quantum\n\nSetting a time quantum on a field creates extra views which allow ranged Row queries down to the time interval specified. For example, if the time quantum is set to `YMD`, ranged Row queries down to the granularity of a day are supported.\n\n### Attribute\n\nAttributes are arbitrary key/value pairs that can be associated with either rows or columns. This metadata is stored in a separate BoltDB data structure.\n\nColumn-level attributes are common across an index. That is, each column attribute applies to all bits in the corresponding column, across all fields in an index. Row attributes apply to all bits in the corresponding row.\n\n### Shard\n\nIndexes are segmented into groups of columns called shards (previously known as slices). Each shard contains a fixed number of columns, which is the ShardWidth. ShardWidth is a constant that can only be modified at compile time, and before ingesting data. The default value is 2<sup>20</sup>.\n\nQuery operations run in parallel, and they are evenly distributed across a cluster via a consistent hash algorithm.\n\n### Field Type\n\nUpon creation, fields are configured to be of a certain type. Pilosa supports the following field types: `set`, `int`, `bool`, `time`, and `mutex`.\n\n#### Set\n\nSet is the default field type in Pilosa. Set fields represent a standard, binary matrix of rows and columns where each row key represents a possible field value. The following example creates a `set` field called \"info\" with a ranked cache containing up to 100,000 records.\n\n``` request\ncurl localhost:10101/index/repository/field/info \\\n     -X POST \\\n     -d '{\"options\": {\"type\": \"set\", \"cacheType\": \"ranked\", \"cacheSize\":100000}}'\n```\n``` response\n{\"success\":true}\n```\n\n#### Int\nFields of type `int` are used to store integer values. Integer fields share the same columns as the other fields in the index, but values for the field must be integers that fall between the `min` and `max` values specified when creating the field. The following example creates an `int` field called \"quantity\" capable of storing values from -1000 to 2000:\n\n``` request\ncurl localhost:10101/index/repository/field/quantity \\\n     -X POST \\\n     -d '{\"options\": {\"type\": \"int\", \"min\": -1000, \"max\":2000}}'\n```\n``` response\n{\"success\":true}\n```\n\n##### BSI Range-Encoding\n\nBit-Sliced Indexing (BSI) is the storage method Pilosa uses to represent multi-bit integers in a bitmap index. Integers are stored as n-bit, range-encoded bit-sliced indexes of base-2, along with an additional row indicating \"not null\". This means that a 16-bit integer will require 17 rows: one for each 0-bit of the 16 bit-slice components (the 1-bit does not need to be stored because with range-encoding the highest bit position is always 1) and one for the non-null row. Pilosa can evaluate `Row`, `Min`, `Max`, and `Sum` queries on these BSI integers. The result of a `Sum` query includes a count, which can be used to compute an average with no other overhead.\n\nInternally Pilosa stores each BSI `field` as a `view`. The rows of the `view` contain the base-2 representations of the integer values. Pilosa manages the base-2 offset and translation that efficiently packs the integer value within the minimum set of rows.\n\nFor example, the following `Set()` queries executed against BSI fields will result in the data described in the diagram below:\n\n```\nSet(1, A=1)\nSet(2, A=2)\nSet(3, A=3)\nSet(4, A=7)\nSet(2, B=1)\nSet(3, B=6)\n```\n\n![BSI field diagram](/img/docs/field-bsi.png)\n*BSI field diagram*\n\nCheck out this [blog post](/blog/range-encoded-bitmaps/) for some more details about BSI in Pilosa.\n\n#### Time\n\nTime fields are similar to `set` fields, but in addition to row and column information, they also store a per-bit time value down to a defined granularity. The following example creates a `time` field called \"event\" which stores timestamp information down to a day granularity.\n\n``` request\ncurl localhost:10101/index/repository/field/event \\\n     -X POST \\\n     -d '{\"options\": {\"type\": \"time\", \"timeQuantum\": \"YMD\"}}'\n```\n``` response\n{\"success\":true}\n```\n\nWith `time` fields, data views are generated for each of the defined time segments. For example, for a field with a time quantum of `YMD`, the following `Set()` queries will result in the data described in the diagram below:\n\n```\nSet(3, A=8, 2017-05-18T00:00)\nSet(3, A=8, 2017-05-19T00:00)\n```\n\n![time quantum field diagram](/img/docs/field-time-quantum.png)\n*Time quantum fueld diagram*\n\n#### Mutex\n\nMutex fields are similar to `set` fields, with the distinction of requiring the row value for each column to be mutually exclusive. In other words, each column can only have a single value for the field. If the field value for a column is updated on a `mutex` field, then the previous field value for that column will be cleared. This field type is like a field in an RDBMS table where every record contains a single value for a particular field.\n\n#### Boolean\n\nA boolean field is similar to a `mutex` field tracking only two values: `true` and `false`. Boolean fields do not maintain a sorted cache, nor do they support key values.\n","source":"_posts/pilosa-data-mode.md","raw":"---\nlayout: graft\ntitle: pilosa-data-mode\ndate: 2019-02-02 11:35:02\ntags: pilosa \n---\n\n## 数据模型\n### 概观\n\nPilosa数据模型核心就是布尔矩阵，矩阵中的每个单元是一个位（计算机存储最小单位），每一个bit代表着行和列之间存在关系（通常是是或者否）\n\n任何的实体都可以成为行和列，行和列也可以是同样的实体比如[bigraph](https://en.wikipedia.org/wiki/Bigraph)。Pilosa可以将任意键/值对（称为属性）与行和列相关联，但查询和存储在围绕矩阵核心进行优化。\n\nPilosa lays out data first in rows, so queries which get all the set bits in one or many rows, or compute a combining operation—such as Intersect or Union—on multiple rows, are the fastest. Pilosa categorizes rows into different *fields* and quickly retrieves the top rows in a field sorted by the number of columns set in each row.\n\nPlease note that Pilosa is most performant when row and column IDs are sequential starting from 0. You can deviate from this to some degree, but setting a bit with column ID 2<sup>63</sup> on a single-node cluster, for example, will not work well due to memory limitations.\n\n![basic data model diagram](/img/docs/data-model.png)\n*Basic data model diagram*\n\n\n\n\n### Index\n\nThe purpose of the Index is to represent a data namespace. You cannot perform cross-index queries.\n\n### Column\n\nColumn ids are sequential, increasing integers and they are common to all Fields within an Index. A single column often corresponds to a record in a relational table, although other configurations are possible, and sometimes preferable.\n\n### Row\n\nRow ids are sequential, increasing integers namespaced to each Field within an Index.\n\n### Field\n\nFields are used to segment rows within an index, for example to define different functional groups. A Pilosa field might correspond to a single field in a relational table, where each row in a standard Pilosa field represents a single possible value of the relational field. Similarly, an integer field could represent all possible integer values of a relational field.\n\n#### Relational Analogy\n\nThe Pilosa index is a flexible structure; it can represent any sort of high-cardinality binary matrix. We have explored a number of modeling patterns in Pilosa use cases; one accessible example is a direct analogy to the relational model, summarized here.\n\nEntities:\n\n Relational  | Pilosa\n-------------|----------------------------------------------\n Database    | N/A *(internal: Holder)*\n Table       | Index\n Row         | Column\n Column      | Field\n Value       | Row\n Value (int) | Field.Value (see [BSI](#bsi-range-encoding))\n\nSimple queries:\n\n Relational                                    | Pilosa\n-----------------------------------------------|------------------------------------\n `select ID from People where Name = 'Bob'`    | `Row(Name=\"Bob\")`\n `select ID from People where Age > 30`        | `Row(Age > 30)`\n `select ID from People where Member = true`   | `Row(Member=0)`\n\nNote that `Row(Member=0)` selects all entities with a bit set in row 0 of the Member field. We could just as well use row 1 to store this, in which case we would use `Row(Member=1)`, which looks a bit more intuitive. In the relational model, joins are often necessary. Because Pilosa supports extremely high cardinality in both rows and columns, many types of joins are accomplished with basic Pilosa queries across multiple fields. For example, this SQL join:\n\n```sql\nselect AVG(p.Age) from People p\ninner join PersonCar pc on pc.PersonID=p.ID\ninner join Cars c on pc.CarID=c.ID\nwhere c.Make = 'Ford'\n```\n\ncan be accomplished with a Pilosa query like this (note that [Sum](../query-language/#sum) returns a json object containing both the sum and count, from which the average is easily computed):\n\n```pql\nSum(Row(Car-Make=\"Ford\"), field=Age)\n```\n\nThis is one major component of Pilosa's ability to combine relationships from multiple data stores.\n\n#### Ranked\n\nRanked Fields maintain a sorted cache of column counts by Row ID (yielding the top rows by columns with a bit set in each). This cache facilitates the TopN query. The cache size defaults to 50,000 and can be set at Field creation.\n\n![ranked field diagram](/img/docs/field-ranked.png)\n*Ranked field diagram*\n\n#### LRU\n\nThe LRU cache maintains the most recently accessed Rows.\n\n![lru field diagram](/img/docs/field-lru.png)\n*LRU field diagram*\n\n### Time Quantum\n\nSetting a time quantum on a field creates extra views which allow ranged Row queries down to the time interval specified. For example, if the time quantum is set to `YMD`, ranged Row queries down to the granularity of a day are supported.\n\n### Attribute\n\nAttributes are arbitrary key/value pairs that can be associated with either rows or columns. This metadata is stored in a separate BoltDB data structure.\n\nColumn-level attributes are common across an index. That is, each column attribute applies to all bits in the corresponding column, across all fields in an index. Row attributes apply to all bits in the corresponding row.\n\n### Shard\n\nIndexes are segmented into groups of columns called shards (previously known as slices). Each shard contains a fixed number of columns, which is the ShardWidth. ShardWidth is a constant that can only be modified at compile time, and before ingesting data. The default value is 2<sup>20</sup>.\n\nQuery operations run in parallel, and they are evenly distributed across a cluster via a consistent hash algorithm.\n\n### Field Type\n\nUpon creation, fields are configured to be of a certain type. Pilosa supports the following field types: `set`, `int`, `bool`, `time`, and `mutex`.\n\n#### Set\n\nSet is the default field type in Pilosa. Set fields represent a standard, binary matrix of rows and columns where each row key represents a possible field value. The following example creates a `set` field called \"info\" with a ranked cache containing up to 100,000 records.\n\n``` request\ncurl localhost:10101/index/repository/field/info \\\n     -X POST \\\n     -d '{\"options\": {\"type\": \"set\", \"cacheType\": \"ranked\", \"cacheSize\":100000}}'\n```\n``` response\n{\"success\":true}\n```\n\n#### Int\nFields of type `int` are used to store integer values. Integer fields share the same columns as the other fields in the index, but values for the field must be integers that fall between the `min` and `max` values specified when creating the field. The following example creates an `int` field called \"quantity\" capable of storing values from -1000 to 2000:\n\n``` request\ncurl localhost:10101/index/repository/field/quantity \\\n     -X POST \\\n     -d '{\"options\": {\"type\": \"int\", \"min\": -1000, \"max\":2000}}'\n```\n``` response\n{\"success\":true}\n```\n\n##### BSI Range-Encoding\n\nBit-Sliced Indexing (BSI) is the storage method Pilosa uses to represent multi-bit integers in a bitmap index. Integers are stored as n-bit, range-encoded bit-sliced indexes of base-2, along with an additional row indicating \"not null\". This means that a 16-bit integer will require 17 rows: one for each 0-bit of the 16 bit-slice components (the 1-bit does not need to be stored because with range-encoding the highest bit position is always 1) and one for the non-null row. Pilosa can evaluate `Row`, `Min`, `Max`, and `Sum` queries on these BSI integers. The result of a `Sum` query includes a count, which can be used to compute an average with no other overhead.\n\nInternally Pilosa stores each BSI `field` as a `view`. The rows of the `view` contain the base-2 representations of the integer values. Pilosa manages the base-2 offset and translation that efficiently packs the integer value within the minimum set of rows.\n\nFor example, the following `Set()` queries executed against BSI fields will result in the data described in the diagram below:\n\n```\nSet(1, A=1)\nSet(2, A=2)\nSet(3, A=3)\nSet(4, A=7)\nSet(2, B=1)\nSet(3, B=6)\n```\n\n![BSI field diagram](/img/docs/field-bsi.png)\n*BSI field diagram*\n\nCheck out this [blog post](/blog/range-encoded-bitmaps/) for some more details about BSI in Pilosa.\n\n#### Time\n\nTime fields are similar to `set` fields, but in addition to row and column information, they also store a per-bit time value down to a defined granularity. The following example creates a `time` field called \"event\" which stores timestamp information down to a day granularity.\n\n``` request\ncurl localhost:10101/index/repository/field/event \\\n     -X POST \\\n     -d '{\"options\": {\"type\": \"time\", \"timeQuantum\": \"YMD\"}}'\n```\n``` response\n{\"success\":true}\n```\n\nWith `time` fields, data views are generated for each of the defined time segments. For example, for a field with a time quantum of `YMD`, the following `Set()` queries will result in the data described in the diagram below:\n\n```\nSet(3, A=8, 2017-05-18T00:00)\nSet(3, A=8, 2017-05-19T00:00)\n```\n\n![time quantum field diagram](/img/docs/field-time-quantum.png)\n*Time quantum fueld diagram*\n\n#### Mutex\n\nMutex fields are similar to `set` fields, with the distinction of requiring the row value for each column to be mutually exclusive. In other words, each column can only have a single value for the field. If the field value for a column is updated on a `mutex` field, then the previous field value for that column will be cleared. This field type is like a field in an RDBMS table where every record contains a single value for a particular field.\n\n#### Boolean\n\nA boolean field is similar to a `mutex` field tracking only two values: `true` and `false`. Boolean fields do not maintain a sorted cache, nor do they support key values.\n","slug":"pilosa-data-mode","published":1,"updated":"2019-02-02T04:28:44.706Z","comments":1,"photos":[],"link":"","_id":"ck8cgqo7m000d3szygne08whg","content":"<h2 id=\"数据模型\">数据模型</h2>\n<h3 id=\"概观\">概观</h3>\n<p>Pilosa数据模型核心就是布尔矩阵，矩阵中的每个单元是一个位（计算机存储最小单位），每一个bit代表着行和列之间存在关系（通常是是或者否）</p>\n<p>任何的实体都可以成为行和列，行和列也可以是同样的实体比如<a href=\"https://en.wikipedia.org/wiki/Bigraph\" target=\"_blank\" rel=\"noopener\">bigraph</a>。Pilosa可以将任意键/值对（称为属性）与行和列相关联，但查询和存储在围绕矩阵核心进行优化。</p>\n<p>Pilosa lays out data first in rows, so queries which get all the set bits in one or many rows, or compute a combining operation—such as Intersect or Union—on multiple rows, are the fastest. Pilosa categorizes rows into different <em>fields</em> and quickly retrieves the top rows in a field sorted by the number of columns set in each row.</p>\n<p>Please note that Pilosa is most performant when row and column IDs are sequential starting from 0. You can deviate from this to some degree, but setting a bit with column ID 2<sup>63</sup> on a single-node cluster, for example, will not work well due to memory limitations.</p>\n<p><img src=\"/img/docs/data-model.png\" alt=\"basic data model diagram\" /> <em>Basic data model diagram</em></p>\n<h3 id=\"index\">Index</h3>\n<p>The purpose of the Index is to represent a data namespace. You cannot perform cross-index queries.</p>\n<h3 id=\"column\">Column</h3>\n<p>Column ids are sequential, increasing integers and they are common to all Fields within an Index. A single column often corresponds to a record in a relational table, although other configurations are possible, and sometimes preferable.</p>\n<h3 id=\"row\">Row</h3>\n<p>Row ids are sequential, increasing integers namespaced to each Field within an Index.</p>\n<h3 id=\"field\">Field</h3>\n<p>Fields are used to segment rows within an index, for example to define different functional groups. A Pilosa field might correspond to a single field in a relational table, where each row in a standard Pilosa field represents a single possible value of the relational field. Similarly, an integer field could represent all possible integer values of a relational field.</p>\n<h4 id=\"relational-analogy\">Relational Analogy</h4>\n<p>The Pilosa index is a flexible structure; it can represent any sort of high-cardinality binary matrix. We have explored a number of modeling patterns in Pilosa use cases; one accessible example is a direct analogy to the relational model, summarized here.</p>\n<p>Entities:</p>\n<table>\n<thead>\n<tr class=\"header\">\n<th>Relational</th>\n<th>Pilosa</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td>Database</td>\n<td>N/A <em>(internal: Holder)</em></td>\n</tr>\n<tr class=\"even\">\n<td>Table</td>\n<td>Index</td>\n</tr>\n<tr class=\"odd\">\n<td>Row</td>\n<td>Column</td>\n</tr>\n<tr class=\"even\">\n<td>Column</td>\n<td>Field</td>\n</tr>\n<tr class=\"odd\">\n<td>Value</td>\n<td>Row</td>\n</tr>\n<tr class=\"even\">\n<td>Value (int)</td>\n<td>Field.Value (see <a href=\"#bsi-range-encoding\">BSI</a>)</td>\n</tr>\n</tbody>\n</table>\n<p>Simple queries:</p>\n<table>\n<thead>\n<tr class=\"header\">\n<th>Relational</th>\n<th>Pilosa</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td><code>select ID from People where Name = 'Bob'</code></td>\n<td><code>Row(Name=&quot;Bob&quot;)</code></td>\n</tr>\n<tr class=\"even\">\n<td><code>select ID from People where Age &gt; 30</code></td>\n<td><code>Row(Age &gt; 30)</code></td>\n</tr>\n<tr class=\"odd\">\n<td><code>select ID from People where Member = true</code></td>\n<td><code>Row(Member=0)</code></td>\n</tr>\n</tbody>\n</table>\n<p>Note that <code>Row(Member=0)</code> selects all entities with a bit set in row 0 of the Member field. We could just as well use row 1 to store this, in which case we would use <code>Row(Member=1)</code>, which looks a bit more intuitive. In the relational model, joins are often necessary. Because Pilosa supports extremely high cardinality in both rows and columns, many types of joins are accomplished with basic Pilosa queries across multiple fields. For example, this SQL join:</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"keyword\">AVG</span>(p.Age) <span class=\"keyword\">from</span> People p</span><br><span class=\"line\"><span class=\"keyword\">inner</span> <span class=\"keyword\">join</span> PersonCar pc <span class=\"keyword\">on</span> pc.PersonID=p.ID</span><br><span class=\"line\"><span class=\"keyword\">inner</span> <span class=\"keyword\">join</span> Cars c <span class=\"keyword\">on</span> pc.CarID=c.ID</span><br><span class=\"line\"><span class=\"keyword\">where</span> c.Make = <span class=\"string\">'Ford'</span></span><br></pre></td></tr></table></figure>\n<p>can be accomplished with a Pilosa query like this (note that <a href=\"../query-language/#sum\">Sum</a> returns a json object containing both the sum and count, from which the average is easily computed):</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Sum(Row(Car-Make&#x3D;&quot;Ford&quot;), field&#x3D;Age)</span><br></pre></td></tr></table></figure>\n<p>This is one major component of Pilosa’s ability to combine relationships from multiple data stores.</p>\n<h4 id=\"ranked\">Ranked</h4>\n<p>Ranked Fields maintain a sorted cache of column counts by Row ID (yielding the top rows by columns with a bit set in each). This cache facilitates the TopN query. The cache size defaults to 50,000 and can be set at Field creation.</p>\n<p><img src=\"/img/docs/field-ranked.png\" alt=\"ranked field diagram\" /> <em>Ranked field diagram</em></p>\n<h4 id=\"lru\">LRU</h4>\n<p>The LRU cache maintains the most recently accessed Rows.</p>\n<p><img src=\"/img/docs/field-lru.png\" alt=\"lru field diagram\" /> <em>LRU field diagram</em></p>\n<h3 id=\"time-quantum\">Time Quantum</h3>\n<p>Setting a time quantum on a field creates extra views which allow ranged Row queries down to the time interval specified. For example, if the time quantum is set to <code>YMD</code>, ranged Row queries down to the granularity of a day are supported.</p>\n<h3 id=\"attribute\">Attribute</h3>\n<p>Attributes are arbitrary key/value pairs that can be associated with either rows or columns. This metadata is stored in a separate BoltDB data structure.</p>\n<p>Column-level attributes are common across an index. That is, each column attribute applies to all bits in the corresponding column, across all fields in an index. Row attributes apply to all bits in the corresponding row.</p>\n<h3 id=\"shard\">Shard</h3>\n<p>Indexes are segmented into groups of columns called shards (previously known as slices). Each shard contains a fixed number of columns, which is the ShardWidth. ShardWidth is a constant that can only be modified at compile time, and before ingesting data. The default value is 2<sup>20</sup>.</p>\n<p>Query operations run in parallel, and they are evenly distributed across a cluster via a consistent hash algorithm.</p>\n<h3 id=\"field-type\">Field Type</h3>\n<p>Upon creation, fields are configured to be of a certain type. Pilosa supports the following field types: <code>set</code>, <code>int</code>, <code>bool</code>, <code>time</code>, and <code>mutex</code>.</p>\n<h4 id=\"set\">Set</h4>\n<p>Set is the default field type in Pilosa. Set fields represent a standard, binary matrix of rows and columns where each row key represents a possible field value. The following example creates a <code>set</code> field called “info” with a ranked cache containing up to 100,000 records.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl localhost:10101&#x2F;index&#x2F;repository&#x2F;field&#x2F;info \\</span><br><span class=\"line\">     -X POST \\</span><br><span class=\"line\">     -d &#39;&#123;&quot;options&quot;: &#123;&quot;type&quot;: &quot;set&quot;, &quot;cacheType&quot;: &quot;ranked&quot;, &quot;cacheSize&quot;:100000&#125;&#125;&#39;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&quot;success&quot;:true&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"int\">Int</h4>\n<p>Fields of type <code>int</code> are used to store integer values. Integer fields share the same columns as the other fields in the index, but values for the field must be integers that fall between the <code>min</code> and <code>max</code> values specified when creating the field. The following example creates an <code>int</code> field called “quantity” capable of storing values from -1000 to 2000:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl localhost:10101&#x2F;index&#x2F;repository&#x2F;field&#x2F;quantity \\</span><br><span class=\"line\">     -X POST \\</span><br><span class=\"line\">     -d &#39;&#123;&quot;options&quot;: &#123;&quot;type&quot;: &quot;int&quot;, &quot;min&quot;: -1000, &quot;max&quot;:2000&#125;&#125;&#39;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&quot;success&quot;:true&#125;</span><br></pre></td></tr></table></figure>\n<h5 id=\"bsi-range-encoding\">BSI Range-Encoding</h5>\n<p>Bit-Sliced Indexing (BSI) is the storage method Pilosa uses to represent multi-bit integers in a bitmap index. Integers are stored as n-bit, range-encoded bit-sliced indexes of base-2, along with an additional row indicating “not null”. This means that a 16-bit integer will require 17 rows: one for each 0-bit of the 16 bit-slice components (the 1-bit does not need to be stored because with range-encoding the highest bit position is always 1) and one for the non-null row. Pilosa can evaluate <code>Row</code>, <code>Min</code>, <code>Max</code>, and <code>Sum</code> queries on these BSI integers. The result of a <code>Sum</code> query includes a count, which can be used to compute an average with no other overhead.</p>\n<p>Internally Pilosa stores each BSI <code>field</code> as a <code>view</code>. The rows of the <code>view</code> contain the base-2 representations of the integer values. Pilosa manages the base-2 offset and translation that efficiently packs the integer value within the minimum set of rows.</p>\n<p>For example, the following <code>Set()</code> queries executed against BSI fields will result in the data described in the diagram below:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Set(1, A&#x3D;1)</span><br><span class=\"line\">Set(2, A&#x3D;2)</span><br><span class=\"line\">Set(3, A&#x3D;3)</span><br><span class=\"line\">Set(4, A&#x3D;7)</span><br><span class=\"line\">Set(2, B&#x3D;1)</span><br><span class=\"line\">Set(3, B&#x3D;6)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/img/docs/field-bsi.png\" alt=\"BSI field diagram\" /> <em>BSI field diagram</em></p>\n<p>Check out this <a href=\"/blog/range-encoded-bitmaps/\">blog post</a> for some more details about BSI in Pilosa.</p>\n<h4 id=\"time\">Time</h4>\n<p>Time fields are similar to <code>set</code> fields, but in addition to row and column information, they also store a per-bit time value down to a defined granularity. The following example creates a <code>time</code> field called “event” which stores timestamp information down to a day granularity.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl localhost:10101&#x2F;index&#x2F;repository&#x2F;field&#x2F;event \\</span><br><span class=\"line\">     -X POST \\</span><br><span class=\"line\">     -d &#39;&#123;&quot;options&quot;: &#123;&quot;type&quot;: &quot;time&quot;, &quot;timeQuantum&quot;: &quot;YMD&quot;&#125;&#125;&#39;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&quot;success&quot;:true&#125;</span><br></pre></td></tr></table></figure>\n<p>With <code>time</code> fields, data views are generated for each of the defined time segments. For example, for a field with a time quantum of <code>YMD</code>, the following <code>Set()</code> queries will result in the data described in the diagram below:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Set(3, A&#x3D;8, 2017-05-18T00:00)</span><br><span class=\"line\">Set(3, A&#x3D;8, 2017-05-19T00:00)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/img/docs/field-time-quantum.png\" alt=\"time quantum field diagram\" /> <em>Time quantum fueld diagram</em></p>\n<h4 id=\"mutex\">Mutex</h4>\n<p>Mutex fields are similar to <code>set</code> fields, with the distinction of requiring the row value for each column to be mutually exclusive. In other words, each column can only have a single value for the field. If the field value for a column is updated on a <code>mutex</code> field, then the previous field value for that column will be cleared. This field type is like a field in an RDBMS table where every record contains a single value for a particular field.</p>\n<h4 id=\"boolean\">Boolean</h4>\n<p>A boolean field is similar to a <code>mutex</code> field tracking only two values: <code>true</code> and <code>false</code>. Boolean fields do not maintain a sorted cache, nor do they support key values.</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"数据模型\">数据模型</h2>\n<h3 id=\"概观\">概观</h3>\n<p>Pilosa数据模型核心就是布尔矩阵，矩阵中的每个单元是一个位（计算机存储最小单位），每一个bit代表着行和列之间存在关系（通常是是或者否）</p>\n<p>任何的实体都可以成为行和列，行和列也可以是同样的实体比如<a href=\"https://en.wikipedia.org/wiki/Bigraph\" target=\"_blank\" rel=\"noopener\">bigraph</a>。Pilosa可以将任意键/值对（称为属性）与行和列相关联，但查询和存储在围绕矩阵核心进行优化。</p>\n<p>Pilosa lays out data first in rows, so queries which get all the set bits in one or many rows, or compute a combining operation—such as Intersect or Union—on multiple rows, are the fastest. Pilosa categorizes rows into different <em>fields</em> and quickly retrieves the top rows in a field sorted by the number of columns set in each row.</p>\n<p>Please note that Pilosa is most performant when row and column IDs are sequential starting from 0. You can deviate from this to some degree, but setting a bit with column ID 2<sup>63</sup> on a single-node cluster, for example, will not work well due to memory limitations.</p>\n<p><img src=\"/img/docs/data-model.png\" alt=\"basic data model diagram\" /> <em>Basic data model diagram</em></p>\n<h3 id=\"index\">Index</h3>\n<p>The purpose of the Index is to represent a data namespace. You cannot perform cross-index queries.</p>\n<h3 id=\"column\">Column</h3>\n<p>Column ids are sequential, increasing integers and they are common to all Fields within an Index. A single column often corresponds to a record in a relational table, although other configurations are possible, and sometimes preferable.</p>\n<h3 id=\"row\">Row</h3>\n<p>Row ids are sequential, increasing integers namespaced to each Field within an Index.</p>\n<h3 id=\"field\">Field</h3>\n<p>Fields are used to segment rows within an index, for example to define different functional groups. A Pilosa field might correspond to a single field in a relational table, where each row in a standard Pilosa field represents a single possible value of the relational field. Similarly, an integer field could represent all possible integer values of a relational field.</p>\n<h4 id=\"relational-analogy\">Relational Analogy</h4>\n<p>The Pilosa index is a flexible structure; it can represent any sort of high-cardinality binary matrix. We have explored a number of modeling patterns in Pilosa use cases; one accessible example is a direct analogy to the relational model, summarized here.</p>\n<p>Entities:</p>\n<table>\n<thead>\n<tr class=\"header\">\n<th>Relational</th>\n<th>Pilosa</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td>Database</td>\n<td>N/A <em>(internal: Holder)</em></td>\n</tr>\n<tr class=\"even\">\n<td>Table</td>\n<td>Index</td>\n</tr>\n<tr class=\"odd\">\n<td>Row</td>\n<td>Column</td>\n</tr>\n<tr class=\"even\">\n<td>Column</td>\n<td>Field</td>\n</tr>\n<tr class=\"odd\">\n<td>Value</td>\n<td>Row</td>\n</tr>\n<tr class=\"even\">\n<td>Value (int)</td>\n<td>Field.Value (see <a href=\"#bsi-range-encoding\">BSI</a>)</td>\n</tr>\n</tbody>\n</table>\n<p>Simple queries:</p>\n<table>\n<thead>\n<tr class=\"header\">\n<th>Relational</th>\n<th>Pilosa</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td><code>select ID from People where Name = 'Bob'</code></td>\n<td><code>Row(Name=&quot;Bob&quot;)</code></td>\n</tr>\n<tr class=\"even\">\n<td><code>select ID from People where Age &gt; 30</code></td>\n<td><code>Row(Age &gt; 30)</code></td>\n</tr>\n<tr class=\"odd\">\n<td><code>select ID from People where Member = true</code></td>\n<td><code>Row(Member=0)</code></td>\n</tr>\n</tbody>\n</table>\n<p>Note that <code>Row(Member=0)</code> selects all entities with a bit set in row 0 of the Member field. We could just as well use row 1 to store this, in which case we would use <code>Row(Member=1)</code>, which looks a bit more intuitive. In the relational model, joins are often necessary. Because Pilosa supports extremely high cardinality in both rows and columns, many types of joins are accomplished with basic Pilosa queries across multiple fields. For example, this SQL join:</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"keyword\">AVG</span>(p.Age) <span class=\"keyword\">from</span> People p</span><br><span class=\"line\"><span class=\"keyword\">inner</span> <span class=\"keyword\">join</span> PersonCar pc <span class=\"keyword\">on</span> pc.PersonID=p.ID</span><br><span class=\"line\"><span class=\"keyword\">inner</span> <span class=\"keyword\">join</span> Cars c <span class=\"keyword\">on</span> pc.CarID=c.ID</span><br><span class=\"line\"><span class=\"keyword\">where</span> c.Make = <span class=\"string\">'Ford'</span></span><br></pre></td></tr></table></figure>\n<p>can be accomplished with a Pilosa query like this (note that <a href=\"../query-language/#sum\">Sum</a> returns a json object containing both the sum and count, from which the average is easily computed):</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Sum(Row(Car-Make&#x3D;&quot;Ford&quot;), field&#x3D;Age)</span><br></pre></td></tr></table></figure>\n<p>This is one major component of Pilosa’s ability to combine relationships from multiple data stores.</p>\n<h4 id=\"ranked\">Ranked</h4>\n<p>Ranked Fields maintain a sorted cache of column counts by Row ID (yielding the top rows by columns with a bit set in each). This cache facilitates the TopN query. The cache size defaults to 50,000 and can be set at Field creation.</p>\n<p><img src=\"/img/docs/field-ranked.png\" alt=\"ranked field diagram\" /> <em>Ranked field diagram</em></p>\n<h4 id=\"lru\">LRU</h4>\n<p>The LRU cache maintains the most recently accessed Rows.</p>\n<p><img src=\"/img/docs/field-lru.png\" alt=\"lru field diagram\" /> <em>LRU field diagram</em></p>\n<h3 id=\"time-quantum\">Time Quantum</h3>\n<p>Setting a time quantum on a field creates extra views which allow ranged Row queries down to the time interval specified. For example, if the time quantum is set to <code>YMD</code>, ranged Row queries down to the granularity of a day are supported.</p>\n<h3 id=\"attribute\">Attribute</h3>\n<p>Attributes are arbitrary key/value pairs that can be associated with either rows or columns. This metadata is stored in a separate BoltDB data structure.</p>\n<p>Column-level attributes are common across an index. That is, each column attribute applies to all bits in the corresponding column, across all fields in an index. Row attributes apply to all bits in the corresponding row.</p>\n<h3 id=\"shard\">Shard</h3>\n<p>Indexes are segmented into groups of columns called shards (previously known as slices). Each shard contains a fixed number of columns, which is the ShardWidth. ShardWidth is a constant that can only be modified at compile time, and before ingesting data. The default value is 2<sup>20</sup>.</p>\n<p>Query operations run in parallel, and they are evenly distributed across a cluster via a consistent hash algorithm.</p>\n<h3 id=\"field-type\">Field Type</h3>\n<p>Upon creation, fields are configured to be of a certain type. Pilosa supports the following field types: <code>set</code>, <code>int</code>, <code>bool</code>, <code>time</code>, and <code>mutex</code>.</p>\n<h4 id=\"set\">Set</h4>\n<p>Set is the default field type in Pilosa. Set fields represent a standard, binary matrix of rows and columns where each row key represents a possible field value. The following example creates a <code>set</code> field called “info” with a ranked cache containing up to 100,000 records.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl localhost:10101&#x2F;index&#x2F;repository&#x2F;field&#x2F;info \\</span><br><span class=\"line\">     -X POST \\</span><br><span class=\"line\">     -d &#39;&#123;&quot;options&quot;: &#123;&quot;type&quot;: &quot;set&quot;, &quot;cacheType&quot;: &quot;ranked&quot;, &quot;cacheSize&quot;:100000&#125;&#125;&#39;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&quot;success&quot;:true&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"int\">Int</h4>\n<p>Fields of type <code>int</code> are used to store integer values. Integer fields share the same columns as the other fields in the index, but values for the field must be integers that fall between the <code>min</code> and <code>max</code> values specified when creating the field. The following example creates an <code>int</code> field called “quantity” capable of storing values from -1000 to 2000:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl localhost:10101&#x2F;index&#x2F;repository&#x2F;field&#x2F;quantity \\</span><br><span class=\"line\">     -X POST \\</span><br><span class=\"line\">     -d &#39;&#123;&quot;options&quot;: &#123;&quot;type&quot;: &quot;int&quot;, &quot;min&quot;: -1000, &quot;max&quot;:2000&#125;&#125;&#39;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&quot;success&quot;:true&#125;</span><br></pre></td></tr></table></figure>\n<h5 id=\"bsi-range-encoding\">BSI Range-Encoding</h5>\n<p>Bit-Sliced Indexing (BSI) is the storage method Pilosa uses to represent multi-bit integers in a bitmap index. Integers are stored as n-bit, range-encoded bit-sliced indexes of base-2, along with an additional row indicating “not null”. This means that a 16-bit integer will require 17 rows: one for each 0-bit of the 16 bit-slice components (the 1-bit does not need to be stored because with range-encoding the highest bit position is always 1) and one for the non-null row. Pilosa can evaluate <code>Row</code>, <code>Min</code>, <code>Max</code>, and <code>Sum</code> queries on these BSI integers. The result of a <code>Sum</code> query includes a count, which can be used to compute an average with no other overhead.</p>\n<p>Internally Pilosa stores each BSI <code>field</code> as a <code>view</code>. The rows of the <code>view</code> contain the base-2 representations of the integer values. Pilosa manages the base-2 offset and translation that efficiently packs the integer value within the minimum set of rows.</p>\n<p>For example, the following <code>Set()</code> queries executed against BSI fields will result in the data described in the diagram below:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Set(1, A&#x3D;1)</span><br><span class=\"line\">Set(2, A&#x3D;2)</span><br><span class=\"line\">Set(3, A&#x3D;3)</span><br><span class=\"line\">Set(4, A&#x3D;7)</span><br><span class=\"line\">Set(2, B&#x3D;1)</span><br><span class=\"line\">Set(3, B&#x3D;6)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/img/docs/field-bsi.png\" alt=\"BSI field diagram\" /> <em>BSI field diagram</em></p>\n<p>Check out this <a href=\"/blog/range-encoded-bitmaps/\">blog post</a> for some more details about BSI in Pilosa.</p>\n<h4 id=\"time\">Time</h4>\n<p>Time fields are similar to <code>set</code> fields, but in addition to row and column information, they also store a per-bit time value down to a defined granularity. The following example creates a <code>time</code> field called “event” which stores timestamp information down to a day granularity.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl localhost:10101&#x2F;index&#x2F;repository&#x2F;field&#x2F;event \\</span><br><span class=\"line\">     -X POST \\</span><br><span class=\"line\">     -d &#39;&#123;&quot;options&quot;: &#123;&quot;type&quot;: &quot;time&quot;, &quot;timeQuantum&quot;: &quot;YMD&quot;&#125;&#125;&#39;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&quot;success&quot;:true&#125;</span><br></pre></td></tr></table></figure>\n<p>With <code>time</code> fields, data views are generated for each of the defined time segments. For example, for a field with a time quantum of <code>YMD</code>, the following <code>Set()</code> queries will result in the data described in the diagram below:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Set(3, A&#x3D;8, 2017-05-18T00:00)</span><br><span class=\"line\">Set(3, A&#x3D;8, 2017-05-19T00:00)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/img/docs/field-time-quantum.png\" alt=\"time quantum field diagram\" /> <em>Time quantum fueld diagram</em></p>\n<h4 id=\"mutex\">Mutex</h4>\n<p>Mutex fields are similar to <code>set</code> fields, with the distinction of requiring the row value for each column to be mutually exclusive. In other words, each column can only have a single value for the field. If the field value for a column is updated on a <code>mutex</code> field, then the previous field value for that column will be cleared. This field type is like a field in an RDBMS table where every record contains a single value for a particular field.</p>\n<h4 id=\"boolean\">Boolean</h4>\n<p>A boolean field is similar to a <code>mutex</code> field tracking only two values: <code>true</code> and <code>false</code>. Boolean fields do not maintain a sorted cache, nor do they support key values.</p>\n"},{"title":"各种基础分布","date":"2017-09-06T08:05:54.000Z","_content":"\n\n![](/images/各种分布.png)\n\n\n------------\n####连续\n<ul>\n<li><a href=\"/wiki/%CE%92%E5%88%86%E5%B8%83\" title=\"Β分布\">Β</a></li>\n<li><a href=\"/wiki/%E6%9F%AF%E8%A5%BF%E5%88%86%E5%B8%83\" title=\"柯西分布\">柯西</a></li>\n<li><a href=\"/wiki/%E5%8D%A1%E6%96%B9%E5%88%86%E4%BD%88\" title=\"卡方分布\">χ²</a></li>\n<li><a href=\"/wiki/%E6%8C%87%E6%95%B0%E5%88%86%E5%B8%83\" title=\"指数分布\">指数</a></li>\n<li><a href=\"/wiki/F-%E5%88%86%E5%B8%83\" title=\"F-分布\"><i>F</i></a></li>\n<li><a href=\"/wiki/%E4%BC%BD%E7%8E%9B%E5%88%86%E5%B8%83\" title=\"伽玛分布\">Γ</a></li>\n<li><a href=\"/wiki/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%88%86%E5%B8%83\" title=\"拉普拉斯分布\">拉普拉斯</a></li>\n<li><a href=\"/wiki/%E5%AF%B9%E6%95%B0%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83\" title=\"对数正态分布\">对数正态</a></li>\n<li><a class=\"mw-selflink selflink\">正态</a></li>\n<li><a href=\"/wiki/%E5%B8%95%E7%B4%AF%E6%89%98%E5%88%86%E5%B8%83\" title=\"帕累托分布\">帕累托</a></li>\n<li><a href=\"/wiki/%E5%AD%A6%E7%94%9Ft-%E5%88%86%E5%B8%83\" title=\"学生t-分布\">学生<i>t</i></a></li>\n<li><a href=\"/wiki/%E9%80%A3%E7%BA%8C%E5%9E%8B%E5%9D%87%E5%8B%BB%E5%88%86%E5%B8%83\" title=\"连续型均匀分布\">均匀</a></li>\n<li><a href=\"/wiki/%E9%9F%A6%E4%BC%AF%E5%88%86%E5%B8%83\" title=\"韦伯分布\">韦伯</a></li>\n</ul>\n\n--------------\n####离散\n<ul>\n<li><a href=\"/wiki/%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83\" title=\"伯努利分布\">伯努利</a></li>\n<li><a href=\"/wiki/%E4%BA%8C%E9%A0%85%E5%88%86%E4%BD%88\" title=\"二项分布\">二项</a></li>\n<li><a href=\"/wiki/%E9%9B%A2%E6%95%A3%E5%9E%8B%E5%9D%87%E5%8B%BB%E5%88%86%E4%BD%88\" title=\"离散型均匀分布\">离散均匀</a></li>\n<li><a href=\"/wiki/%E5%B9%BE%E4%BD%95%E5%88%86%E4%BD%88\" title=\"几何分布\">几何</a></li>\n<li><a href=\"/wiki/%E8%B6%85%E5%87%A0%E4%BD%95%E5%88%86%E5%B8%83\" title=\"超几何分布\">超几何</a></li>\n<li><a href=\"/wiki/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83\" title=\"负二项分布\">负二项</a></li>\n<li><a href=\"/wiki/%E6%B3%8A%E6%9D%BE%E5%88%86%E4%BD%88\" title=\"泊松分布\">泊松</a></li>\n</ul>\n\n\n","source":"_posts/各种分布.md","raw":"---\ntitle: 各种基础分布\ndate: 2017-09-06 16:05:54\ntags:\n---\n\n\n![](/images/各种分布.png)\n\n\n------------\n####连续\n<ul>\n<li><a href=\"/wiki/%CE%92%E5%88%86%E5%B8%83\" title=\"Β分布\">Β</a></li>\n<li><a href=\"/wiki/%E6%9F%AF%E8%A5%BF%E5%88%86%E5%B8%83\" title=\"柯西分布\">柯西</a></li>\n<li><a href=\"/wiki/%E5%8D%A1%E6%96%B9%E5%88%86%E4%BD%88\" title=\"卡方分布\">χ²</a></li>\n<li><a href=\"/wiki/%E6%8C%87%E6%95%B0%E5%88%86%E5%B8%83\" title=\"指数分布\">指数</a></li>\n<li><a href=\"/wiki/F-%E5%88%86%E5%B8%83\" title=\"F-分布\"><i>F</i></a></li>\n<li><a href=\"/wiki/%E4%BC%BD%E7%8E%9B%E5%88%86%E5%B8%83\" title=\"伽玛分布\">Γ</a></li>\n<li><a href=\"/wiki/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%88%86%E5%B8%83\" title=\"拉普拉斯分布\">拉普拉斯</a></li>\n<li><a href=\"/wiki/%E5%AF%B9%E6%95%B0%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83\" title=\"对数正态分布\">对数正态</a></li>\n<li><a class=\"mw-selflink selflink\">正态</a></li>\n<li><a href=\"/wiki/%E5%B8%95%E7%B4%AF%E6%89%98%E5%88%86%E5%B8%83\" title=\"帕累托分布\">帕累托</a></li>\n<li><a href=\"/wiki/%E5%AD%A6%E7%94%9Ft-%E5%88%86%E5%B8%83\" title=\"学生t-分布\">学生<i>t</i></a></li>\n<li><a href=\"/wiki/%E9%80%A3%E7%BA%8C%E5%9E%8B%E5%9D%87%E5%8B%BB%E5%88%86%E5%B8%83\" title=\"连续型均匀分布\">均匀</a></li>\n<li><a href=\"/wiki/%E9%9F%A6%E4%BC%AF%E5%88%86%E5%B8%83\" title=\"韦伯分布\">韦伯</a></li>\n</ul>\n\n--------------\n####离散\n<ul>\n<li><a href=\"/wiki/%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83\" title=\"伯努利分布\">伯努利</a></li>\n<li><a href=\"/wiki/%E4%BA%8C%E9%A0%85%E5%88%86%E4%BD%88\" title=\"二项分布\">二项</a></li>\n<li><a href=\"/wiki/%E9%9B%A2%E6%95%A3%E5%9E%8B%E5%9D%87%E5%8B%BB%E5%88%86%E4%BD%88\" title=\"离散型均匀分布\">离散均匀</a></li>\n<li><a href=\"/wiki/%E5%B9%BE%E4%BD%95%E5%88%86%E4%BD%88\" title=\"几何分布\">几何</a></li>\n<li><a href=\"/wiki/%E8%B6%85%E5%87%A0%E4%BD%95%E5%88%86%E5%B8%83\" title=\"超几何分布\">超几何</a></li>\n<li><a href=\"/wiki/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83\" title=\"负二项分布\">负二项</a></li>\n<li><a href=\"/wiki/%E6%B3%8A%E6%9D%BE%E5%88%86%E4%BD%88\" title=\"泊松分布\">泊松</a></li>\n</ul>\n\n\n","slug":"各种分布","published":1,"updated":"2017-09-29T10:21:59.648Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8cgqo7n000e3szy69gla5av","content":"<div class=\"figure\">\n<img src=\"/images/各种分布.png\" />\n\n</div>\n<hr />\n<h4 id=\"连续\">连续</h4>\n<ul>\n<li>\n<a href=\"/wiki/%CE%92%E5%88%86%E5%B8%83\" title=\"Β分布\">Β</a>\n</li>\n<li>\n<a href=\"/wiki/%E6%9F%AF%E8%A5%BF%E5%88%86%E5%B8%83\" title=\"柯西分布\">柯西</a>\n</li>\n<li>\n<a href=\"/wiki/%E5%8D%A1%E6%96%B9%E5%88%86%E4%BD%88\" title=\"卡方分布\">χ²</a>\n</li>\n<li>\n<a href=\"/wiki/%E6%8C%87%E6%95%B0%E5%88%86%E5%B8%83\" title=\"指数分布\">指数</a>\n</li>\n<li>\n<a href=\"/wiki/F-%E5%88%86%E5%B8%83\" title=\"F-分布\"><i>F</i></a>\n</li>\n<li>\n<a href=\"/wiki/%E4%BC%BD%E7%8E%9B%E5%88%86%E5%B8%83\" title=\"伽玛分布\">Γ</a>\n</li>\n<li>\n<a href=\"/wiki/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%88%86%E5%B8%83\" title=\"拉普拉斯分布\">拉普拉斯</a>\n</li>\n<li>\n<a href=\"/wiki/%E5%AF%B9%E6%95%B0%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83\" title=\"对数正态分布\">对数正态</a>\n</li>\n<li>\n<a class=\"mw-selflink selflink\">正态</a>\n</li>\n<li>\n<a href=\"/wiki/%E5%B8%95%E7%B4%AF%E6%89%98%E5%88%86%E5%B8%83\" title=\"帕累托分布\">帕累托</a>\n</li>\n<li>\n<a href=\"/wiki/%E5%AD%A6%E7%94%9Ft-%E5%88%86%E5%B8%83\" title=\"学生t-分布\">学生<i>t</i></a>\n</li>\n<li>\n<a href=\"/wiki/%E9%80%A3%E7%BA%8C%E5%9E%8B%E5%9D%87%E5%8B%BB%E5%88%86%E5%B8%83\" title=\"连续型均匀分布\">均匀</a>\n</li>\n<li>\n<a href=\"/wiki/%E9%9F%A6%E4%BC%AF%E5%88%86%E5%B8%83\" title=\"韦伯分布\">韦伯</a>\n</li>\n</ul>\n<hr />\n<h4 id=\"离散\">离散</h4>\n<ul>\n<li>\n<a href=\"/wiki/%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83\" title=\"伯努利分布\">伯努利</a>\n</li>\n<li>\n<a href=\"/wiki/%E4%BA%8C%E9%A0%85%E5%88%86%E4%BD%88\" title=\"二项分布\">二项</a>\n</li>\n<li>\n<a href=\"/wiki/%E9%9B%A2%E6%95%A3%E5%9E%8B%E5%9D%87%E5%8B%BB%E5%88%86%E4%BD%88\" title=\"离散型均匀分布\">离散均匀</a>\n</li>\n<li>\n<a href=\"/wiki/%E5%B9%BE%E4%BD%95%E5%88%86%E4%BD%88\" title=\"几何分布\">几何</a>\n</li>\n<li>\n<a href=\"/wiki/%E8%B6%85%E5%87%A0%E4%BD%95%E5%88%86%E5%B8%83\" title=\"超几何分布\">超几何</a>\n</li>\n<li>\n<a href=\"/wiki/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83\" title=\"负二项分布\">负二项</a>\n</li>\n<li>\n<a href=\"/wiki/%E6%B3%8A%E6%9D%BE%E5%88%86%E4%BD%88\" title=\"泊松分布\">泊松</a>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<div class=\"figure\">\n<img src=\"/images/各种分布.png\" />\n\n</div>\n<hr />\n<h4 id=\"连续\">连续</h4>\n<ul>\n<li>\n<a href=\"/wiki/%CE%92%E5%88%86%E5%B8%83\" title=\"Β分布\">Β</a>\n</li>\n<li>\n<a href=\"/wiki/%E6%9F%AF%E8%A5%BF%E5%88%86%E5%B8%83\" title=\"柯西分布\">柯西</a>\n</li>\n<li>\n<a href=\"/wiki/%E5%8D%A1%E6%96%B9%E5%88%86%E4%BD%88\" title=\"卡方分布\">χ²</a>\n</li>\n<li>\n<a href=\"/wiki/%E6%8C%87%E6%95%B0%E5%88%86%E5%B8%83\" title=\"指数分布\">指数</a>\n</li>\n<li>\n<a href=\"/wiki/F-%E5%88%86%E5%B8%83\" title=\"F-分布\"><i>F</i></a>\n</li>\n<li>\n<a href=\"/wiki/%E4%BC%BD%E7%8E%9B%E5%88%86%E5%B8%83\" title=\"伽玛分布\">Γ</a>\n</li>\n<li>\n<a href=\"/wiki/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%88%86%E5%B8%83\" title=\"拉普拉斯分布\">拉普拉斯</a>\n</li>\n<li>\n<a href=\"/wiki/%E5%AF%B9%E6%95%B0%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83\" title=\"对数正态分布\">对数正态</a>\n</li>\n<li>\n<a class=\"mw-selflink selflink\">正态</a>\n</li>\n<li>\n<a href=\"/wiki/%E5%B8%95%E7%B4%AF%E6%89%98%E5%88%86%E5%B8%83\" title=\"帕累托分布\">帕累托</a>\n</li>\n<li>\n<a href=\"/wiki/%E5%AD%A6%E7%94%9Ft-%E5%88%86%E5%B8%83\" title=\"学生t-分布\">学生<i>t</i></a>\n</li>\n<li>\n<a href=\"/wiki/%E9%80%A3%E7%BA%8C%E5%9E%8B%E5%9D%87%E5%8B%BB%E5%88%86%E5%B8%83\" title=\"连续型均匀分布\">均匀</a>\n</li>\n<li>\n<a href=\"/wiki/%E9%9F%A6%E4%BC%AF%E5%88%86%E5%B8%83\" title=\"韦伯分布\">韦伯</a>\n</li>\n</ul>\n<hr />\n<h4 id=\"离散\">离散</h4>\n<ul>\n<li>\n<a href=\"/wiki/%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83\" title=\"伯努利分布\">伯努利</a>\n</li>\n<li>\n<a href=\"/wiki/%E4%BA%8C%E9%A0%85%E5%88%86%E4%BD%88\" title=\"二项分布\">二项</a>\n</li>\n<li>\n<a href=\"/wiki/%E9%9B%A2%E6%95%A3%E5%9E%8B%E5%9D%87%E5%8B%BB%E5%88%86%E4%BD%88\" title=\"离散型均匀分布\">离散均匀</a>\n</li>\n<li>\n<a href=\"/wiki/%E5%B9%BE%E4%BD%95%E5%88%86%E4%BD%88\" title=\"几何分布\">几何</a>\n</li>\n<li>\n<a href=\"/wiki/%E8%B6%85%E5%87%A0%E4%BD%95%E5%88%86%E5%B8%83\" title=\"超几何分布\">超几何</a>\n</li>\n<li>\n<a href=\"/wiki/%E8%B4%9F%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83\" title=\"负二项分布\">负二项</a>\n</li>\n<li>\n<a href=\"/wiki/%E6%B3%8A%E6%9D%BE%E5%88%86%E4%BD%88\" title=\"泊松分布\">泊松</a>\n</li>\n</ul>\n"},{"title":"推荐系统2","date":"2020-03-28T15:43:00.000Z","_content":"\n\n###基于相似的算法\n\n 基于相似的推荐算法代表着推荐系统中最成功的一种，他们已经被广泛研究并在电子商务中的建立了各种应用[117,118]。这类算法可以进一步分为基于用户（user-base）和基于项目(item-base)相似度的方法。基于用户相似性的方法的基本假设是，在过去的评价一致的人在未来的评价中往往会再次一致。因此，对于目标用户，根据与目标用户相似的用户（“品味对象”）的评价来估计对象的潜在评价（参见图5作为示意图）。与用户相似度不同，基于项目相似度的算法向用户推荐与用户之前收集的对象相似的对象。请注意，有时来自不相似用户（兴趣不同）[119]或负面评价[120,121]的意见在确定推荐系统过程中可能发挥重要（甚至是积极的）作用，特别是当数据集非常稀疏时，因此关联性的信息比相似性信息更加重要[122]。有关更多信息，请参阅最近的回顾文章[123,124]，[125]是一个很好的综述，其中包含许多相似性指数。\n \n ![](/images/fig5.png)\n \n\n####算法\n \n 这里我们简要的介绍常规的基于相似度的算法即常说的基于记忆的协同过滤技术。 “协同过滤”一词由第一个商业推荐系统的创作者Tapestry [126]引入，他源于这样一个事实：它需要多个代理人协作共享他们的数据以获得更好的推荐。 在以下部分中，我们描述了基本算法以及计算相似度的主要方法，这是推荐过程的关键组成部分。 \n\n#####用户相似度\n \n 该算法的目的是通过收集其他用户尤其是那些和目标用户具有相同评价的用户的评价来自动预测目标用户的偏好。设$r_{u\\alpha}$表示用户$u$对商品$\\alpha$的评价，$\\Gamma_u$表示用户$u$已经评价过的商品的集合。用户评价的平均值计算方式为$\\bar {r_u} = \\frac {1} {|\\Gamma_u|} \\sum_{a \\in \\Gamma_u} r_{u\\alpha}$。根据标准的协同过滤算法，预测的用户$u$对商品$\\alpha$的评价是$$\\bar {r}_{u\\alpha}=\\bar {r}_u+K\\sum_{v \\in \\hat{U}_u} S_{uv}(r_{v\\alpha} - \\bar r_v ) \\quad \\quad \\quad  (25) $$其中$\\hat{U}_u$代表与目标用户$u$高度相似的用户集合，$S_{uv}$代表用户$u$和用户$v$之间的相似度,$K = \\frac {1} {\\sum_v|S_{uv}|}$是一个标准化的因子。如果没有显性的评价，只知道用户收集的对象（商品）的集合（隐性评价），我们的目标则是去预测用户未来最有可能会收集的对象，根据[119]，公式25应该被替换为$$P_{u\\alpha} = \\sum_{v \\in \\hat{U}_u} S_{uv} \\alpha_{v\\alpha} \\quad \\quad \\quad  (26)$$其中$P_{u\\alpha}$是对用户$u$推荐商品$\\alpha$的分数，$\\alpha_{v\\alpha} $ 是“用户-商品”二部图的邻接矩阵的元素（如果用户$u$收集过对象$\\alpha$ 则 $\\alpha_{v\\alpha} =1$ 否则 $\\alpha_{v\\alpha} =0$）\n \n 公式25和26已经明确说明了该算法只考虑那些和目标用户$u$相似的用户，通常有2种方法来获取$\\hat U_u$ ：（i）相似系数阈值[127]通过选择相似度$s_{uv}$大于阈值的用户$v$，（ii）最大数量邻居方法[128]通过选择$k$个与用户$u$最相似的用户（$k$在这里是算法 的一个参数）。限制在只计算那些最相似的用户不仅有利于计算也能够获得更好的结果。\n \n\n\n####商品相似\n\n在该算法中，商品之间的相似度$S_{\\alpha \\beta}$被引进代替用户之间的相似度$S_{uv}$，最简单的办法就是通过加权平均来估计那些未知的评价[130]$$\\widetilde{r}_{\\alpha \\beta} = \\frac {\\sum_{\\beta \\in \\Gamma_u} S_{\\alpha \\beta} r_{u \\beta}} {\\sum_{\\beta \\in \\Gamma_u} |S_{\\alpha \\beta}|} \\quad \\quad \\quad  (27)$$其中$\\Gamma_u$表示用户$u$评级过的对象集合，和上面的用户相似度一样，在计算$\\widetilde{r}_{\\alpha \\beta} $的时候将对象限制为那些和对象$\\alpha$最相似的的。相对于基于用户间的用户相似度方法，该算法的的好处是对象之间的相似度趋向于稳定的，允许离线计算其值和邻居 its values and neighborhoods（换言之，可以在用户请求推荐之前计算--这样可以缩短获取推荐的时间）。混合基于对象的和基于用户或基于用户属性的协同推荐算法在[131,132]中被提出来，他们的结果表明，该方法不但能够提高预测的精准性，而且对于那些稀疏的数据鲁棒性更好。\n\n####Slope One predictor\n\n该算法是形式为 $f(x) = x + b$ 的算法，其中$b$是常量$x$是代表打分的变量,他是最简单的基于打分的基于商品的协同过滤算法。它减掉两个商品的平均评分，以衡量一个商品在平均值上比另外一个商品喜好程度多多少。这个差别被用来预测用户对一个商品的评分当他对另外一个商品的评分已知的时候。举例来说，用户$i$ 对商品$ \\alpha \\beta$ 打分分别是1和2，用户 $j$ 给商品 $\\alpha$ 打了2分,Slope one 就会预测用户 $j$ 对商品 $\\beta$ 的打分为 $2+(1.5-1) =2.5 $(参考图6具体的说明)\n\n![](/images/fig6.png)\n\nSlope one 算法同时考虑了对相同商品评分的其他用户和被同一用户评分的其他商品的信息，尤其在预测的过程中只考虑和目标用户有共同商品评分的用户和目标用户已经评分过的商品。用 $S(\\alpha ,\\beta)$ 表示同时评价商品 $\\alpha $ 和 $\\beta$ 的用户集合，商品 $\\beta$ 相对于商品 $\\alpha$ 的平均偏差被定义为$$dev_{\\beta \\alpha} = \\frac{\\sum_{i \\in S(\\alpha ,\\beta)} r_{i \\beta} -r_{i \\alpha} }{|S(\\alpha ,\\beta)|} \\quad \\quad \\quad  (28)$$给定一个已知的评分$r_{u\\alpha}$，slope one 预测用户 $u$ 对商品 $\\beta$ 的评分为 $r_{u \\alpha}+dev_{\\beta \\alpha}$，改变公式28中的 $\\alpha$ ，我们会得到不同的预测结果，所以一个更加合理的全面的预测方法是对他们做平均。$$\\bar r_{u\\alpha} = \\frac{1}{|R(u,\\alpha)|} \\sum_{\\alpha \\in R(u,\\alpha)} (r_{u \\alpha} +  dev_{\\alpha \\beta} ) \\quad \\quad \\quad  (29)$$，其中 $R(u,\\alpha)$ 是用户 $u$  评价的商品集合，需要注意的是无论多少用户共同参与对商品 $\\alpha \\beta$ 打分,算法对不同的商品 $\\alpha$ 的权重是相同的。考虑到实际上 $dev_{\\alpha \\beta}$ 依赖于 $|S(\\alpha ,\\beta)|$(重合的越多，信任度越高)，我们可以得到一个加权的 slope one算法 $$ \\bar r_{u\\alpha}^w = \\frac{ \\sum_{\\alpha} |S(\\alpha ,\\beta)|(r_{u \\alpha} +  dev_{\\alpha \\beta} ) }{\\sum_\\alpha S(\\alpha ,\\beta)}\n\\quad \\quad \\quad  (30)$$ 基本Slope One算法的另一个改进是将所有商品集合划分为用户喜欢和不喜欢的（一个来识别喜欢和不喜欢的项目直接标准是检查他们的评分是高于还是低于给定用户的平均评分）。从这些喜欢的和不喜欢的集合导出2个单独的预测然后结合在一起来预测。用 $S^{+1}(\\alpha , \\beta) ,S^{-1}(\\alpha , \\beta)$ 分布代表用喜欢和不喜欢的集合，喜欢和不喜欢的偏差定义为 $$ dev_{\\beta \\alpha}^{+1} = \\frac{1}{|S^{+1}(\\alpha ,\\beta)|}{\\sum_{i \\in S(\\alpha ,\\beta)} (r_{i \\beta} -r_{i \\alpha} )}   \\quad \\quad   dev_{\\beta \\alpha}^{-1} = \\frac{1}{|S^{-1}(\\alpha ,\\beta)|}{\\sum_{i \\in S(\\alpha ,\\beta)} (r_{i \\beta} -r_{i \\alpha} )}  \\quad  (31)$$ 基于商品$\\alpha$的打分对商品$\\beta$的打分预测是 $dev_{\\beta \\alpha}^{+1}$ 或者 $dev_{\\beta \\alpha}^{-1}$ 这取决于目标用户 $j$ 喜欢或者不喜欢商品$\\alpha$，于是定义 Bi-Polar Slope One为 $$ p_{j\\beta}^{bi} = \\frac {\\sum_{\\alpha} |S^{+1}(\\beta ,\\alpha)|(r_{j\\alpha}+dev^{+1}_{\\\\beta \\alpha})+\\sum_{\\alpha} |S^{-1}(\\beta ,\\alpha)|(r_{j\\alpha}+dev^{-1}_{\\\\beta \\alpha})}   {\\sum_{\\alpha} |S^{+1}(\\beta ,\\alpha)|+\\sum_{\\alpha} |S^{-1}(\\beta ,\\alpha)|} \\quad \\quad \\quad (32)$$ ，其中权重部分和带权重的Slope One相似。\n\n实践表明，slope one算法能够比线性回归（即通过$f(x) = ax+b$的估计）得到更好的结果，这个简单的方法也减少了存储成本和降低推荐系统的延迟性。Slope One已被用作积木来改进其他算法[134-136]。 例如，它可以与基于用户的协同过滤组合，以通过 slope one 方案填充用户商品矩阵的空白评分来解决数据稀疏问题，从而提高预测精度[134]。\n\n\n###如何定义相似\n\n基于相似度算法的关键问题是如何定义用户或对象之间的相似性。 当显式评级可用时，通常使用诸如Pearson之类的相关指标来定义相似度（如果两个用户倾向于对他们评估的对象给出类似的评级，则认为两个用户相似）。 当没有可用的评估信息时，可以从输入数据的结构属性推断出相似性（当他们喜欢/购买了许多共同的对象时，两个用户被认为是相似的）。 此外，可以利用诸如用户属性，标签和对象的内容元信息之类的外部信息来更好地估计相似性。\n\n####基于打分的相似\n\n在许多在线电子商务服务中，用户可以通过打分对消费对象进行评价。 例如，在雅虎音乐中，用户用一到五颗星给每首歌曲投票，1星-“再也不播放” ，2星-“可以”，3星-“喜欢”，4星-“爱它”和5星-“非常爱”。 通过显性的评分信息，我们可以通过余弦指数[15,137]来测量两个用户之间或两个对象之间的相似度，余弦指数定义如下：$$ S_{xy}^{cos} = \\frac{r_x \\bullet r_y}{| r_x || r_Y|} \\quad \\quad \\quad (33)$$计算用户之间的相似性时，$r_x，r_y$是N维商品空间中的评估向量，而当计算商品之间的相似性，$r_x，r_y$ 是M维度用户空间中的向量。 请注意，在计算基于评分的相似度时，有必要消除用户和/或商品的评级倾向，否则相似性结果没意义。 实际上，根据最近报道的智能方法，在一些评分系统中，通过适当使用评分趋势，预测未知评分的时候可以比基于相似度的简单方法准确性高得多[116]。\n\n评分相关性也可以通过person系数来计算。通过公式$$ s_{uv}^{PC}  = \\frac {\\sum_{\\alpha \\in O_{uv}} (r_{u\\alpha} - \\bar r_u)(r_{v\\alpha} - \\bar r_v)} {  \\sqrt{\\sum_{\\alpha \\in O_{uv}} (r_{u\\alpha} - \\bar r_u)^2}   \\sqrt{\\sum_{\\alpha \\in O_{uv}} (r_{v\\alpha} - \\bar r_v)^2}   } \\quad \\quad \\quad(34)$$来量化用户 $u$ 和 $v$ 之间的相似性，其中 $O_{uv} = \\Gamma_u \\cap \\Gamma_v$ 表示被用户$u,v$同时评分的商品集合。由Shardanand和Maes提出的约束Pearson系数[127]用“中心”(central)评分（例如，从1到5的评分，可以将中心评分设置为3）来代替公式34中的用户平均值。 这个想法是考虑到积极（高于中心评分）和负面评分（低于中心评分）之间的差异。 加权Pearson系数是基于捕获可以放在相似度值上的置信度的想法（当两个用户只评分了几个共同的商品时，它们的潜在的高相似性不应该 和具有许多共同商品评分的一对用户可信度一样）。 [138]提出将皮尔逊系数加权为$$S_{uv}^{WPC} = \\begin{cases} S_{uv}^{PC}\\frac{O_{uv}}{H} &  for \\space |O_{uv}| \\leq H \\\\\\\\ S_{uv}^{PC} & otherwise\\end{cases} \\quad \\quad \\quad(35)$$其中H是阈值，通过实验确定，超过该阈值的相关性可信。\n\n类似的，商品之间的person相似性溃疡定义为 $$ s_{\\alpha \\beta}^{PC}  = \\frac {\\sum_{u \\in U_{\\alpha \\beta}} (r_{u\\alpha} - \\bar r_{\\alpha})(r_{u\\beta} - \\bar r_{\\beta})} {  \\sqrt{\\sum_{\\alpha \\in O_{uv}} (r_{u\\alpha} - \\bar r_{\\alpha})^2}   \\sqrt{\\sum_{\\alpha \\in O_{uv}} (r_{u\\beta} - \\bar r_{\\beta})^2}   } \\quad \\quad \\quad(36)$$ 其中 $U_{\\alpha \\beta}$是同时给商品 $\\alpha ,\\beta$ 评分的用户集合， $\\bar r_{\\beta}$是商品 $\\beta$ 评分的平均值。试验证明Pearson系数比向量的余弦指数效果更好。当只有二元评分（喜欢和不喜欢，购买了和米有购买，点击或者没有点击）的时候，余弦和pearson系数依旧可以量化二元向量的相似性。 例如，亚马逊的专利算法[117]通过计算代表用户购买情况的二元向量的余弦相似性来做基于商品的协同过滤。\n\n\n####结构相似性，主要是基于复杂网络的一些技术\n\n如上所述，可以使用诸如标签和内容信息之类的外部属性来定义相似度。然而，所需的数据通常很难收集。另一个简单而有效量化相似性的方法是结构相似性[139]，它是完全基于数据的网络结构。最近的研究表明，相对于Pearson相关系数相似性方法，基于结构的相似性可以产生更好的推荐结果，特别是当输入数据非常稀疏时[122]。\n\n为了计算用户或者商品之间的结构相似度，我们通常将包含系统完整信息的用户商品二分网络投入到用户-用户或商品-商品网络中（有关相似性方面的更多信息，请参见[103]）。在最简单的情况下，如果两个用户至少投票一个相同商品，那么两个用户被认为是相似的（类似地，如果两个商品被至少一个用户共同投票，则被认为是相似的）。更精细的相似性度量可以粗略地分类为依赖于路径的路径，本地与全局，无参数与参数相关，等等。我们将回顾其中的一些。\n\n（i）节点依赖相似性。最简单的加权相似性指数是相同的邻居（CN），其中两个节点的相似性由公共邻居的数量直接给出（考虑同时购买$\\alpha \\beta$两个商品的用户数量和/或用户u和v都购买的商品数量）。通过考虑两个目标节点的度，得出了CN的六个变体：Salton指数[140]，Jaccard指数[141]，Sørensen指数[142]，Hub推荐指数（HPI）[143]，Hub Depressed Index（HDI）和Leicht-Holme-Newman指数（LHN16）[144]。可以进一步考虑各个共同邻居的度来奖励具有较高权重的较少连接的邻居，如在Adamic-Adar指数（AA）[145]和资源分配指数（RA）[102]。注意，由于AA使用对数加权，因此对于高度共同邻居惩罚小于RA的。最后，优先连接 (PA)指数建立在网络科学中的经典优先连接规则的基础上[146]。该指标已被用于量化各种基于网络动态的链路的功能意义，如渗透[147]，同步[148]和运输[149]（This index has been used to quantify the functional significance of links subject to various network- based dynamics, such as percolation [147], synchronization [148] and transportation [149]. ）。请注意，当计算用户和商品相似度，这些相似度也可以用于公共邻居是对象和用户的二分网络。这些相似性指数的数学定义的总结如表4所示。\n\n![](/images/table4.png)\n\n（ii）基于边的相似性。 这里的基本假设是，如果两个节点通过许多边连接，则它们是相似的。 由于相邻矩阵$A_n$的n次方的元素等于各对节点之间不同路径的数量，所以路径相关相似性度量通常可以以紧凑形式写成，例如$$ S_{xy}^{LP} = (A^2)_{xy}+ \\epsilon(A^3)_{xy} \\quad \\quad \\quad(37)$$对于局部路径指数[150]，其中只有长度为2和3的路径和 $\\epsilon$ 是阻尼参数。 （请注意，在一个二分网络中，同类型节点之间只能有一个偶数长度的路径。）通过包括所有长度的路径，我们获得经典的Katz相似度[151]，其被定义为$$ S_{xy}^{Katz} = \\beta A_{xy}+\\beta^2(A^2)_{xy}+ \\beta^3(A^3)_{xy} + \\cdots \\quad \\quad \\quad(38)$$ $\\beta $ 其中是阻尼系数控制路径的权重，这个公式可以改写为 $S^{Katz} = (I - \\beta A)^{-1} -I $ 。Leicht-Holme-Newman指数（LHN2）[144]是Katz指数的变体，其中 $（A^l)_{xy}$ 被  $（A^l)_{xy} / E[(A^l_{xy}]$代替，其中$E[X]$是X的期望。\n\n（iii）基于随机游走的相似性。 该类方法是基于网络上的随机游走。\n\n***平均到达时间***：节点x和y之间的平均通勤时间被定义为随机步行者从节点x开始到达节点y加上从y到x所需的平均步数。 可以通过网络的拉普拉斯矩阵 $L^+$ 的伪逆来获得，如[152,153] $$n(x,y) = ((L^+)_{xx} +(L^+)_{yy} - 2(L^+)_{xy})E $$ 其中E是网络中的边数量。 假设当两个节点的平均通勤时间很小时两个节点相似，节点x和y之间的相似性可以被定义为它们的平均通勤时间的倒数 $$ S_{xy}^{ACT}=\\frac{1}{((L^+)_{xx} +(L^+)_{yy} - 2(L^+)_{xy})} $$ 其中常量 $E$ 被移除\n\n***基于 $L^+$ 的余弦***：该指标是基于內积的一个度量方式。 在欧几里德空间中$v_x = \\Lambda^{\\frac{1}{2}}U^T e_x $ ，U是由其特征值x的递减顺序排列的$L^+$的特征向量组成的正交矩阵，$\\Lambda= diag(x)$，$e_x$是列基向量 $（(e_x)_y = xy)$ 和T是矩阵转置，拉普拉斯矩阵的伪逆的元素由节点的向量內积构成，$（L^+)_{xy} = v_x^T v_y$。因此余弦相似度定义为[153]\n$$S^{cos+}_{xy} = \\frac{v^t_xv_y}{|v_x|v_y|} = \\frac{(L^+)_{xy}}{(L^+)_{xx}(L^+)_{yy}}$$\n\n***带重启的随机游走***\n $$q_x  =cP^Tq_x +(1-c)e_x $$ 其中P是 如果x和y连接而 $P_{xy} = 1 / k_x $ 的转置矩阵，否则为$P_{xy} = 0$。 解决方案这个方程是\n\n***SimRank***\n\n***局部随机游走***","source":"_posts/推荐系统2.md","raw":"---\ntitle: 推荐系统2\ndate: 2020-03-28 23:43:00\ntags:\n---\n\n\n###基于相似的算法\n\n 基于相似的推荐算法代表着推荐系统中最成功的一种，他们已经被广泛研究并在电子商务中的建立了各种应用[117,118]。这类算法可以进一步分为基于用户（user-base）和基于项目(item-base)相似度的方法。基于用户相似性的方法的基本假设是，在过去的评价一致的人在未来的评价中往往会再次一致。因此，对于目标用户，根据与目标用户相似的用户（“品味对象”）的评价来估计对象的潜在评价（参见图5作为示意图）。与用户相似度不同，基于项目相似度的算法向用户推荐与用户之前收集的对象相似的对象。请注意，有时来自不相似用户（兴趣不同）[119]或负面评价[120,121]的意见在确定推荐系统过程中可能发挥重要（甚至是积极的）作用，特别是当数据集非常稀疏时，因此关联性的信息比相似性信息更加重要[122]。有关更多信息，请参阅最近的回顾文章[123,124]，[125]是一个很好的综述，其中包含许多相似性指数。\n \n ![](/images/fig5.png)\n \n\n####算法\n \n 这里我们简要的介绍常规的基于相似度的算法即常说的基于记忆的协同过滤技术。 “协同过滤”一词由第一个商业推荐系统的创作者Tapestry [126]引入，他源于这样一个事实：它需要多个代理人协作共享他们的数据以获得更好的推荐。 在以下部分中，我们描述了基本算法以及计算相似度的主要方法，这是推荐过程的关键组成部分。 \n\n#####用户相似度\n \n 该算法的目的是通过收集其他用户尤其是那些和目标用户具有相同评价的用户的评价来自动预测目标用户的偏好。设$r_{u\\alpha}$表示用户$u$对商品$\\alpha$的评价，$\\Gamma_u$表示用户$u$已经评价过的商品的集合。用户评价的平均值计算方式为$\\bar {r_u} = \\frac {1} {|\\Gamma_u|} \\sum_{a \\in \\Gamma_u} r_{u\\alpha}$。根据标准的协同过滤算法，预测的用户$u$对商品$\\alpha$的评价是$$\\bar {r}_{u\\alpha}=\\bar {r}_u+K\\sum_{v \\in \\hat{U}_u} S_{uv}(r_{v\\alpha} - \\bar r_v ) \\quad \\quad \\quad  (25) $$其中$\\hat{U}_u$代表与目标用户$u$高度相似的用户集合，$S_{uv}$代表用户$u$和用户$v$之间的相似度,$K = \\frac {1} {\\sum_v|S_{uv}|}$是一个标准化的因子。如果没有显性的评价，只知道用户收集的对象（商品）的集合（隐性评价），我们的目标则是去预测用户未来最有可能会收集的对象，根据[119]，公式25应该被替换为$$P_{u\\alpha} = \\sum_{v \\in \\hat{U}_u} S_{uv} \\alpha_{v\\alpha} \\quad \\quad \\quad  (26)$$其中$P_{u\\alpha}$是对用户$u$推荐商品$\\alpha$的分数，$\\alpha_{v\\alpha} $ 是“用户-商品”二部图的邻接矩阵的元素（如果用户$u$收集过对象$\\alpha$ 则 $\\alpha_{v\\alpha} =1$ 否则 $\\alpha_{v\\alpha} =0$）\n \n 公式25和26已经明确说明了该算法只考虑那些和目标用户$u$相似的用户，通常有2种方法来获取$\\hat U_u$ ：（i）相似系数阈值[127]通过选择相似度$s_{uv}$大于阈值的用户$v$，（ii）最大数量邻居方法[128]通过选择$k$个与用户$u$最相似的用户（$k$在这里是算法 的一个参数）。限制在只计算那些最相似的用户不仅有利于计算也能够获得更好的结果。\n \n\n\n####商品相似\n\n在该算法中，商品之间的相似度$S_{\\alpha \\beta}$被引进代替用户之间的相似度$S_{uv}$，最简单的办法就是通过加权平均来估计那些未知的评价[130]$$\\widetilde{r}_{\\alpha \\beta} = \\frac {\\sum_{\\beta \\in \\Gamma_u} S_{\\alpha \\beta} r_{u \\beta}} {\\sum_{\\beta \\in \\Gamma_u} |S_{\\alpha \\beta}|} \\quad \\quad \\quad  (27)$$其中$\\Gamma_u$表示用户$u$评级过的对象集合，和上面的用户相似度一样，在计算$\\widetilde{r}_{\\alpha \\beta} $的时候将对象限制为那些和对象$\\alpha$最相似的的。相对于基于用户间的用户相似度方法，该算法的的好处是对象之间的相似度趋向于稳定的，允许离线计算其值和邻居 its values and neighborhoods（换言之，可以在用户请求推荐之前计算--这样可以缩短获取推荐的时间）。混合基于对象的和基于用户或基于用户属性的协同推荐算法在[131,132]中被提出来，他们的结果表明，该方法不但能够提高预测的精准性，而且对于那些稀疏的数据鲁棒性更好。\n\n####Slope One predictor\n\n该算法是形式为 $f(x) = x + b$ 的算法，其中$b$是常量$x$是代表打分的变量,他是最简单的基于打分的基于商品的协同过滤算法。它减掉两个商品的平均评分，以衡量一个商品在平均值上比另外一个商品喜好程度多多少。这个差别被用来预测用户对一个商品的评分当他对另外一个商品的评分已知的时候。举例来说，用户$i$ 对商品$ \\alpha \\beta$ 打分分别是1和2，用户 $j$ 给商品 $\\alpha$ 打了2分,Slope one 就会预测用户 $j$ 对商品 $\\beta$ 的打分为 $2+(1.5-1) =2.5 $(参考图6具体的说明)\n\n![](/images/fig6.png)\n\nSlope one 算法同时考虑了对相同商品评分的其他用户和被同一用户评分的其他商品的信息，尤其在预测的过程中只考虑和目标用户有共同商品评分的用户和目标用户已经评分过的商品。用 $S(\\alpha ,\\beta)$ 表示同时评价商品 $\\alpha $ 和 $\\beta$ 的用户集合，商品 $\\beta$ 相对于商品 $\\alpha$ 的平均偏差被定义为$$dev_{\\beta \\alpha} = \\frac{\\sum_{i \\in S(\\alpha ,\\beta)} r_{i \\beta} -r_{i \\alpha} }{|S(\\alpha ,\\beta)|} \\quad \\quad \\quad  (28)$$给定一个已知的评分$r_{u\\alpha}$，slope one 预测用户 $u$ 对商品 $\\beta$ 的评分为 $r_{u \\alpha}+dev_{\\beta \\alpha}$，改变公式28中的 $\\alpha$ ，我们会得到不同的预测结果，所以一个更加合理的全面的预测方法是对他们做平均。$$\\bar r_{u\\alpha} = \\frac{1}{|R(u,\\alpha)|} \\sum_{\\alpha \\in R(u,\\alpha)} (r_{u \\alpha} +  dev_{\\alpha \\beta} ) \\quad \\quad \\quad  (29)$$，其中 $R(u,\\alpha)$ 是用户 $u$  评价的商品集合，需要注意的是无论多少用户共同参与对商品 $\\alpha \\beta$ 打分,算法对不同的商品 $\\alpha$ 的权重是相同的。考虑到实际上 $dev_{\\alpha \\beta}$ 依赖于 $|S(\\alpha ,\\beta)|$(重合的越多，信任度越高)，我们可以得到一个加权的 slope one算法 $$ \\bar r_{u\\alpha}^w = \\frac{ \\sum_{\\alpha} |S(\\alpha ,\\beta)|(r_{u \\alpha} +  dev_{\\alpha \\beta} ) }{\\sum_\\alpha S(\\alpha ,\\beta)}\n\\quad \\quad \\quad  (30)$$ 基本Slope One算法的另一个改进是将所有商品集合划分为用户喜欢和不喜欢的（一个来识别喜欢和不喜欢的项目直接标准是检查他们的评分是高于还是低于给定用户的平均评分）。从这些喜欢的和不喜欢的集合导出2个单独的预测然后结合在一起来预测。用 $S^{+1}(\\alpha , \\beta) ,S^{-1}(\\alpha , \\beta)$ 分布代表用喜欢和不喜欢的集合，喜欢和不喜欢的偏差定义为 $$ dev_{\\beta \\alpha}^{+1} = \\frac{1}{|S^{+1}(\\alpha ,\\beta)|}{\\sum_{i \\in S(\\alpha ,\\beta)} (r_{i \\beta} -r_{i \\alpha} )}   \\quad \\quad   dev_{\\beta \\alpha}^{-1} = \\frac{1}{|S^{-1}(\\alpha ,\\beta)|}{\\sum_{i \\in S(\\alpha ,\\beta)} (r_{i \\beta} -r_{i \\alpha} )}  \\quad  (31)$$ 基于商品$\\alpha$的打分对商品$\\beta$的打分预测是 $dev_{\\beta \\alpha}^{+1}$ 或者 $dev_{\\beta \\alpha}^{-1}$ 这取决于目标用户 $j$ 喜欢或者不喜欢商品$\\alpha$，于是定义 Bi-Polar Slope One为 $$ p_{j\\beta}^{bi} = \\frac {\\sum_{\\alpha} |S^{+1}(\\beta ,\\alpha)|(r_{j\\alpha}+dev^{+1}_{\\\\beta \\alpha})+\\sum_{\\alpha} |S^{-1}(\\beta ,\\alpha)|(r_{j\\alpha}+dev^{-1}_{\\\\beta \\alpha})}   {\\sum_{\\alpha} |S^{+1}(\\beta ,\\alpha)|+\\sum_{\\alpha} |S^{-1}(\\beta ,\\alpha)|} \\quad \\quad \\quad (32)$$ ，其中权重部分和带权重的Slope One相似。\n\n实践表明，slope one算法能够比线性回归（即通过$f(x) = ax+b$的估计）得到更好的结果，这个简单的方法也减少了存储成本和降低推荐系统的延迟性。Slope One已被用作积木来改进其他算法[134-136]。 例如，它可以与基于用户的协同过滤组合，以通过 slope one 方案填充用户商品矩阵的空白评分来解决数据稀疏问题，从而提高预测精度[134]。\n\n\n###如何定义相似\n\n基于相似度算法的关键问题是如何定义用户或对象之间的相似性。 当显式评级可用时，通常使用诸如Pearson之类的相关指标来定义相似度（如果两个用户倾向于对他们评估的对象给出类似的评级，则认为两个用户相似）。 当没有可用的评估信息时，可以从输入数据的结构属性推断出相似性（当他们喜欢/购买了许多共同的对象时，两个用户被认为是相似的）。 此外，可以利用诸如用户属性，标签和对象的内容元信息之类的外部信息来更好地估计相似性。\n\n####基于打分的相似\n\n在许多在线电子商务服务中，用户可以通过打分对消费对象进行评价。 例如，在雅虎音乐中，用户用一到五颗星给每首歌曲投票，1星-“再也不播放” ，2星-“可以”，3星-“喜欢”，4星-“爱它”和5星-“非常爱”。 通过显性的评分信息，我们可以通过余弦指数[15,137]来测量两个用户之间或两个对象之间的相似度，余弦指数定义如下：$$ S_{xy}^{cos} = \\frac{r_x \\bullet r_y}{| r_x || r_Y|} \\quad \\quad \\quad (33)$$计算用户之间的相似性时，$r_x，r_y$是N维商品空间中的评估向量，而当计算商品之间的相似性，$r_x，r_y$ 是M维度用户空间中的向量。 请注意，在计算基于评分的相似度时，有必要消除用户和/或商品的评级倾向，否则相似性结果没意义。 实际上，根据最近报道的智能方法，在一些评分系统中，通过适当使用评分趋势，预测未知评分的时候可以比基于相似度的简单方法准确性高得多[116]。\n\n评分相关性也可以通过person系数来计算。通过公式$$ s_{uv}^{PC}  = \\frac {\\sum_{\\alpha \\in O_{uv}} (r_{u\\alpha} - \\bar r_u)(r_{v\\alpha} - \\bar r_v)} {  \\sqrt{\\sum_{\\alpha \\in O_{uv}} (r_{u\\alpha} - \\bar r_u)^2}   \\sqrt{\\sum_{\\alpha \\in O_{uv}} (r_{v\\alpha} - \\bar r_v)^2}   } \\quad \\quad \\quad(34)$$来量化用户 $u$ 和 $v$ 之间的相似性，其中 $O_{uv} = \\Gamma_u \\cap \\Gamma_v$ 表示被用户$u,v$同时评分的商品集合。由Shardanand和Maes提出的约束Pearson系数[127]用“中心”(central)评分（例如，从1到5的评分，可以将中心评分设置为3）来代替公式34中的用户平均值。 这个想法是考虑到积极（高于中心评分）和负面评分（低于中心评分）之间的差异。 加权Pearson系数是基于捕获可以放在相似度值上的置信度的想法（当两个用户只评分了几个共同的商品时，它们的潜在的高相似性不应该 和具有许多共同商品评分的一对用户可信度一样）。 [138]提出将皮尔逊系数加权为$$S_{uv}^{WPC} = \\begin{cases} S_{uv}^{PC}\\frac{O_{uv}}{H} &  for \\space |O_{uv}| \\leq H \\\\\\\\ S_{uv}^{PC} & otherwise\\end{cases} \\quad \\quad \\quad(35)$$其中H是阈值，通过实验确定，超过该阈值的相关性可信。\n\n类似的，商品之间的person相似性溃疡定义为 $$ s_{\\alpha \\beta}^{PC}  = \\frac {\\sum_{u \\in U_{\\alpha \\beta}} (r_{u\\alpha} - \\bar r_{\\alpha})(r_{u\\beta} - \\bar r_{\\beta})} {  \\sqrt{\\sum_{\\alpha \\in O_{uv}} (r_{u\\alpha} - \\bar r_{\\alpha})^2}   \\sqrt{\\sum_{\\alpha \\in O_{uv}} (r_{u\\beta} - \\bar r_{\\beta})^2}   } \\quad \\quad \\quad(36)$$ 其中 $U_{\\alpha \\beta}$是同时给商品 $\\alpha ,\\beta$ 评分的用户集合， $\\bar r_{\\beta}$是商品 $\\beta$ 评分的平均值。试验证明Pearson系数比向量的余弦指数效果更好。当只有二元评分（喜欢和不喜欢，购买了和米有购买，点击或者没有点击）的时候，余弦和pearson系数依旧可以量化二元向量的相似性。 例如，亚马逊的专利算法[117]通过计算代表用户购买情况的二元向量的余弦相似性来做基于商品的协同过滤。\n\n\n####结构相似性，主要是基于复杂网络的一些技术\n\n如上所述，可以使用诸如标签和内容信息之类的外部属性来定义相似度。然而，所需的数据通常很难收集。另一个简单而有效量化相似性的方法是结构相似性[139]，它是完全基于数据的网络结构。最近的研究表明，相对于Pearson相关系数相似性方法，基于结构的相似性可以产生更好的推荐结果，特别是当输入数据非常稀疏时[122]。\n\n为了计算用户或者商品之间的结构相似度，我们通常将包含系统完整信息的用户商品二分网络投入到用户-用户或商品-商品网络中（有关相似性方面的更多信息，请参见[103]）。在最简单的情况下，如果两个用户至少投票一个相同商品，那么两个用户被认为是相似的（类似地，如果两个商品被至少一个用户共同投票，则被认为是相似的）。更精细的相似性度量可以粗略地分类为依赖于路径的路径，本地与全局，无参数与参数相关，等等。我们将回顾其中的一些。\n\n（i）节点依赖相似性。最简单的加权相似性指数是相同的邻居（CN），其中两个节点的相似性由公共邻居的数量直接给出（考虑同时购买$\\alpha \\beta$两个商品的用户数量和/或用户u和v都购买的商品数量）。通过考虑两个目标节点的度，得出了CN的六个变体：Salton指数[140]，Jaccard指数[141]，Sørensen指数[142]，Hub推荐指数（HPI）[143]，Hub Depressed Index（HDI）和Leicht-Holme-Newman指数（LHN16）[144]。可以进一步考虑各个共同邻居的度来奖励具有较高权重的较少连接的邻居，如在Adamic-Adar指数（AA）[145]和资源分配指数（RA）[102]。注意，由于AA使用对数加权，因此对于高度共同邻居惩罚小于RA的。最后，优先连接 (PA)指数建立在网络科学中的经典优先连接规则的基础上[146]。该指标已被用于量化各种基于网络动态的链路的功能意义，如渗透[147]，同步[148]和运输[149]（This index has been used to quantify the functional significance of links subject to various network- based dynamics, such as percolation [147], synchronization [148] and transportation [149]. ）。请注意，当计算用户和商品相似度，这些相似度也可以用于公共邻居是对象和用户的二分网络。这些相似性指数的数学定义的总结如表4所示。\n\n![](/images/table4.png)\n\n（ii）基于边的相似性。 这里的基本假设是，如果两个节点通过许多边连接，则它们是相似的。 由于相邻矩阵$A_n$的n次方的元素等于各对节点之间不同路径的数量，所以路径相关相似性度量通常可以以紧凑形式写成，例如$$ S_{xy}^{LP} = (A^2)_{xy}+ \\epsilon(A^3)_{xy} \\quad \\quad \\quad(37)$$对于局部路径指数[150]，其中只有长度为2和3的路径和 $\\epsilon$ 是阻尼参数。 （请注意，在一个二分网络中，同类型节点之间只能有一个偶数长度的路径。）通过包括所有长度的路径，我们获得经典的Katz相似度[151]，其被定义为$$ S_{xy}^{Katz} = \\beta A_{xy}+\\beta^2(A^2)_{xy}+ \\beta^3(A^3)_{xy} + \\cdots \\quad \\quad \\quad(38)$$ $\\beta $ 其中是阻尼系数控制路径的权重，这个公式可以改写为 $S^{Katz} = (I - \\beta A)^{-1} -I $ 。Leicht-Holme-Newman指数（LHN2）[144]是Katz指数的变体，其中 $（A^l)_{xy}$ 被  $（A^l)_{xy} / E[(A^l_{xy}]$代替，其中$E[X]$是X的期望。\n\n（iii）基于随机游走的相似性。 该类方法是基于网络上的随机游走。\n\n***平均到达时间***：节点x和y之间的平均通勤时间被定义为随机步行者从节点x开始到达节点y加上从y到x所需的平均步数。 可以通过网络的拉普拉斯矩阵 $L^+$ 的伪逆来获得，如[152,153] $$n(x,y) = ((L^+)_{xx} +(L^+)_{yy} - 2(L^+)_{xy})E $$ 其中E是网络中的边数量。 假设当两个节点的平均通勤时间很小时两个节点相似，节点x和y之间的相似性可以被定义为它们的平均通勤时间的倒数 $$ S_{xy}^{ACT}=\\frac{1}{((L^+)_{xx} +(L^+)_{yy} - 2(L^+)_{xy})} $$ 其中常量 $E$ 被移除\n\n***基于 $L^+$ 的余弦***：该指标是基于內积的一个度量方式。 在欧几里德空间中$v_x = \\Lambda^{\\frac{1}{2}}U^T e_x $ ，U是由其特征值x的递减顺序排列的$L^+$的特征向量组成的正交矩阵，$\\Lambda= diag(x)$，$e_x$是列基向量 $（(e_x)_y = xy)$ 和T是矩阵转置，拉普拉斯矩阵的伪逆的元素由节点的向量內积构成，$（L^+)_{xy} = v_x^T v_y$。因此余弦相似度定义为[153]\n$$S^{cos+}_{xy} = \\frac{v^t_xv_y}{|v_x|v_y|} = \\frac{(L^+)_{xy}}{(L^+)_{xx}(L^+)_{yy}}$$\n\n***带重启的随机游走***\n $$q_x  =cP^Tq_x +(1-c)e_x $$ 其中P是 如果x和y连接而 $P_{xy} = 1 / k_x $ 的转置矩阵，否则为$P_{xy} = 0$。 解决方案这个方程是\n\n***SimRank***\n\n***局部随机游走***","slug":"推荐系统2","published":1,"updated":"2020-03-28T15:55:31.633Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8cgqo7r000i3szyc2dm960o","content":"<h3 id=\"基于相似的算法\">基于相似的算法</h3>\n<p>基于相似的推荐算法代表着推荐系统中最成功的一种，他们已经被广泛研究并在电子商务中的建立了各种应用[117,118]。这类算法可以进一步分为基于用户（user-base）和基于项目(item-base)相似度的方法。基于用户相似性的方法的基本假设是，在过去的评价一致的人在未来的评价中往往会再次一致。因此，对于目标用户，根据与目标用户相似的用户（“品味对象”）的评价来估计对象的潜在评价（参见图5作为示意图）。与用户相似度不同，基于项目相似度的算法向用户推荐与用户之前收集的对象相似的对象。请注意，有时来自不相似用户（兴趣不同）[119]或负面评价[120,121]的意见在确定推荐系统过程中可能发挥重要（甚至是积极的）作用，特别是当数据集非常稀疏时，因此关联性的信息比相似性信息更加重要[122]。有关更多信息，请参阅最近的回顾文章[123,124]，[125]是一个很好的综述，其中包含许多相似性指数。</p>\n<div class=\"figure\">\n<img src=\"/images/fig5.png\" />\n\n</div>\n<h4 id=\"算法\">算法</h4>\n<p>这里我们简要的介绍常规的基于相似度的算法即常说的基于记忆的协同过滤技术。 “协同过滤”一词由第一个商业推荐系统的创作者Tapestry [126]引入，他源于这样一个事实：它需要多个代理人协作共享他们的数据以获得更好的推荐。 在以下部分中，我们描述了基本算法以及计算相似度的主要方法，这是推荐过程的关键组成部分。</p>\n<h5 id=\"用户相似度\">用户相似度</h5>\n<p>该算法的目的是通过收集其他用户尤其是那些和目标用户具有相同评价的用户的评价来自动预测目标用户的偏好。设<span class=\"math inline\">\\(r_{u\\alpha}\\)</span>表示用户<span class=\"math inline\">\\(u\\)</span>对商品<span class=\"math inline\">\\(\\alpha\\)</span>的评价，<span class=\"math inline\">\\(\\Gamma_u\\)</span>表示用户<span class=\"math inline\">\\(u\\)</span>已经评价过的商品的集合。用户评价的平均值计算方式为<span class=\"math inline\">\\(\\bar {r_u} = \\frac {1} {|\\Gamma_u|} \\sum_{a \\in \\Gamma_u} r_{u\\alpha}\\)</span>。根据标准的协同过滤算法，预测的用户<span class=\"math inline\">\\(u\\)</span>对商品<span class=\"math inline\">\\(\\alpha\\)</span>的评价是<span class=\"math display\">\\[\\bar {r}_{u\\alpha}=\\bar {r}_u+K\\sum_{v \\in \\hat{U}_u} S_{uv}(r_{v\\alpha} - \\bar r_v ) \\quad \\quad \\quad  (25) \\]</span>其中<span class=\"math inline\">\\(\\hat{U}_u\\)</span>代表与目标用户<span class=\"math inline\">\\(u\\)</span>高度相似的用户集合，<span class=\"math inline\">\\(S_{uv}\\)</span>代表用户<span class=\"math inline\">\\(u\\)</span>和用户<span class=\"math inline\">\\(v\\)</span>之间的相似度,<span class=\"math inline\">\\(K = \\frac {1} {\\sum_v|S_{uv}|}\\)</span>是一个标准化的因子。如果没有显性的评价，只知道用户收集的对象（商品）的集合（隐性评价），我们的目标则是去预测用户未来最有可能会收集的对象，根据[119]，公式25应该被替换为<span class=\"math display\">\\[P_{u\\alpha} = \\sum_{v \\in \\hat{U}_u} S_{uv} \\alpha_{v\\alpha} \\quad \\quad \\quad  (26)\\]</span>其中<span class=\"math inline\">\\(P_{u\\alpha}\\)</span>是对用户<span class=\"math inline\">\\(u\\)</span>推荐商品<span class=\"math inline\">\\(\\alpha\\)</span>的分数，$_{v} $ 是“用户-商品”二部图的邻接矩阵的元素（如果用户<span class=\"math inline\">\\(u\\)</span>收集过对象<span class=\"math inline\">\\(\\alpha\\)</span> 则 <span class=\"math inline\">\\(\\alpha_{v\\alpha} =1\\)</span> 否则 <span class=\"math inline\">\\(\\alpha_{v\\alpha} =0\\)</span>）</p>\n<p>公式25和26已经明确说明了该算法只考虑那些和目标用户<span class=\"math inline\">\\(u\\)</span>相似的用户，通常有2种方法来获取<span class=\"math inline\">\\(\\hat U_u\\)</span> ：（i）相似系数阈值[127]通过选择相似度<span class=\"math inline\">\\(s_{uv}\\)</span>大于阈值的用户<span class=\"math inline\">\\(v\\)</span>，（ii）最大数量邻居方法[128]通过选择<span class=\"math inline\">\\(k\\)</span>个与用户<span class=\"math inline\">\\(u\\)</span>最相似的用户（<span class=\"math inline\">\\(k\\)</span>在这里是算法 的一个参数）。限制在只计算那些最相似的用户不仅有利于计算也能够获得更好的结果。</p>\n<h4 id=\"商品相似\">商品相似</h4>\n<p>在该算法中，商品之间的相似度<span class=\"math inline\">\\(S_{\\alpha \\beta}\\)</span>被引进代替用户之间的相似度<span class=\"math inline\">\\(S_{uv}\\)</span>，最简单的办法就是通过加权平均来估计那些未知的评价[130]<span class=\"math display\">\\[\\widetilde{r}_{\\alpha \\beta} = \\frac {\\sum_{\\beta \\in \\Gamma_u} S_{\\alpha \\beta} r_{u \\beta}} {\\sum_{\\beta \\in \\Gamma_u} |S_{\\alpha \\beta}|} \\quad \\quad \\quad  (27)\\]</span>其中<span class=\"math inline\">\\(\\Gamma_u\\)</span>表示用户<span class=\"math inline\">\\(u\\)</span>评级过的对象集合，和上面的用户相似度一样，在计算$_{} <span class=\"math inline\">\\(的时候将对象限制为那些和对象\\)</span>$最相似的的。相对于基于用户间的用户相似度方法，该算法的的好处是对象之间的相似度趋向于稳定的，允许离线计算其值和邻居 its values and neighborhoods（换言之，可以在用户请求推荐之前计算–这样可以缩短获取推荐的时间）。混合基于对象的和基于用户或基于用户属性的协同推荐算法在[131,132]中被提出来，他们的结果表明，该方法不但能够提高预测的精准性，而且对于那些稀疏的数据鲁棒性更好。</p>\n<h4 id=\"slope-one-predictor\">Slope One predictor</h4>\n<p>该算法是形式为 <span class=\"math inline\">\\(f(x) = x + b\\)</span> 的算法，其中<span class=\"math inline\">\\(b\\)</span>是常量<span class=\"math inline\">\\(x\\)</span>是代表打分的变量,他是最简单的基于打分的基于商品的协同过滤算法。它减掉两个商品的平均评分，以衡量一个商品在平均值上比另外一个商品喜好程度多多少。这个差别被用来预测用户对一个商品的评分当他对另外一个商品的评分已知的时候。举例来说，用户<span class=\"math inline\">\\(i\\)</span> 对商品$ $ 打分分别是1和2，用户 <span class=\"math inline\">\\(j\\)</span> 给商品 <span class=\"math inline\">\\(\\alpha\\)</span> 打了2分,Slope one 就会预测用户 <span class=\"math inline\">\\(j\\)</span> 对商品 <span class=\"math inline\">\\(\\beta\\)</span> 的打分为 $2+(1.5-1) =2.5 $(参考图6具体的说明)</p>\n<div class=\"figure\">\n<img src=\"/images/fig6.png\" />\n\n</div>\n<p>Slope one 算法同时考虑了对相同商品评分的其他用户和被同一用户评分的其他商品的信息，尤其在预测的过程中只考虑和目标用户有共同商品评分的用户和目标用户已经评分过的商品。用 <span class=\"math inline\">\\(S(\\alpha ,\\beta)\\)</span> 表示同时评价商品 $$ 和 <span class=\"math inline\">\\(\\beta\\)</span> 的用户集合，商品 <span class=\"math inline\">\\(\\beta\\)</span> 相对于商品 <span class=\"math inline\">\\(\\alpha\\)</span> 的平均偏差被定义为<span class=\"math display\">\\[dev_{\\beta \\alpha} = \\frac{\\sum_{i \\in S(\\alpha ,\\beta)} r_{i \\beta} -r_{i \\alpha} }{|S(\\alpha ,\\beta)|} \\quad \\quad \\quad  (28)\\]</span>给定一个已知的评分<span class=\"math inline\">\\(r_{u\\alpha}\\)</span>，slope one 预测用户 <span class=\"math inline\">\\(u\\)</span> 对商品 <span class=\"math inline\">\\(\\beta\\)</span> 的评分为 <span class=\"math inline\">\\(r_{u \\alpha}+dev_{\\beta \\alpha}\\)</span>，改变公式28中的 <span class=\"math inline\">\\(\\alpha\\)</span> ，我们会得到不同的预测结果，所以一个更加合理的全面的预测方法是对他们做平均。<span class=\"math display\">\\[\\bar r_{u\\alpha} = \\frac{1}{|R(u,\\alpha)|} \\sum_{\\alpha \\in R(u,\\alpha)} (r_{u \\alpha} +  dev_{\\alpha \\beta} ) \\quad \\quad \\quad  (29)\\]</span>，其中 <span class=\"math inline\">\\(R(u,\\alpha)\\)</span> 是用户 <span class=\"math inline\">\\(u\\)</span> 评价的商品集合，需要注意的是无论多少用户共同参与对商品 <span class=\"math inline\">\\(\\alpha \\beta\\)</span> 打分,算法对不同的商品 <span class=\"math inline\">\\(\\alpha\\)</span> 的权重是相同的。考虑到实际上 <span class=\"math inline\">\\(dev_{\\alpha \\beta}\\)</span> 依赖于 <span class=\"math inline\">\\(|S(\\alpha ,\\beta)|\\)</span>(重合的越多，信任度越高)，我们可以得到一个加权的 slope one算法 <span class=\"math display\">\\[ \\bar r_{u\\alpha}^w = \\frac{ \\sum_{\\alpha} |S(\\alpha ,\\beta)|(r_{u \\alpha} +  dev_{\\alpha \\beta} ) }{\\sum_\\alpha S(\\alpha ,\\beta)}\n\\quad \\quad \\quad  (30)\\]</span> 基本Slope One算法的另一个改进是将所有商品集合划分为用户喜欢和不喜欢的（一个来识别喜欢和不喜欢的项目直接标准是检查他们的评分是高于还是低于给定用户的平均评分）。从这些喜欢的和不喜欢的集合导出2个单独的预测然后结合在一起来预测。用 <span class=\"math inline\">\\(S^{+1}(\\alpha , \\beta) ,S^{-1}(\\alpha , \\beta)\\)</span> 分布代表用喜欢和不喜欢的集合，喜欢和不喜欢的偏差定义为 <span class=\"math display\">\\[ dev_{\\beta \\alpha}^{+1} = \\frac{1}{|S^{+1}(\\alpha ,\\beta)|}{\\sum_{i \\in S(\\alpha ,\\beta)} (r_{i \\beta} -r_{i \\alpha} )}   \\quad \\quad   dev_{\\beta \\alpha}^{-1} = \\frac{1}{|S^{-1}(\\alpha ,\\beta)|}{\\sum_{i \\in S(\\alpha ,\\beta)} (r_{i \\beta} -r_{i \\alpha} )}  \\quad  (31)\\]</span> 基于商品<span class=\"math inline\">\\(\\alpha\\)</span>的打分对商品<span class=\"math inline\">\\(\\beta\\)</span>的打分预测是 <span class=\"math inline\">\\(dev_{\\beta \\alpha}^{+1}\\)</span> 或者 <span class=\"math inline\">\\(dev_{\\beta \\alpha}^{-1}\\)</span> 这取决于目标用户 <span class=\"math inline\">\\(j\\)</span> 喜欢或者不喜欢商品<span class=\"math inline\">\\(\\alpha\\)</span>，于是定义 Bi-Polar Slope One为 <span class=\"math display\">\\[ p_{j\\beta}^{bi} = \\frac {\\sum_{\\alpha} |S^{+1}(\\beta ,\\alpha)|(r_{j\\alpha}+dev^{+1}_{\\\\beta \\alpha})+\\sum_{\\alpha} |S^{-1}(\\beta ,\\alpha)|(r_{j\\alpha}+dev^{-1}_{\\\\beta \\alpha})}   {\\sum_{\\alpha} |S^{+1}(\\beta ,\\alpha)|+\\sum_{\\alpha} |S^{-1}(\\beta ,\\alpha)|} \\quad \\quad \\quad (32)\\]</span> ，其中权重部分和带权重的Slope One相似。</p>\n<p>实践表明，slope one算法能够比线性回归（即通过<span class=\"math inline\">\\(f(x) = ax+b\\)</span>的估计）得到更好的结果，这个简单的方法也减少了存储成本和降低推荐系统的延迟性。Slope One已被用作积木来改进其他算法[134-136]。 例如，它可以与基于用户的协同过滤组合，以通过 slope one 方案填充用户商品矩阵的空白评分来解决数据稀疏问题，从而提高预测精度[134]。</p>\n<h3 id=\"如何定义相似\">如何定义相似</h3>\n<p>基于相似度算法的关键问题是如何定义用户或对象之间的相似性。 当显式评级可用时，通常使用诸如Pearson之类的相关指标来定义相似度（如果两个用户倾向于对他们评估的对象给出类似的评级，则认为两个用户相似）。 当没有可用的评估信息时，可以从输入数据的结构属性推断出相似性（当他们喜欢/购买了许多共同的对象时，两个用户被认为是相似的）。 此外，可以利用诸如用户属性，标签和对象的内容元信息之类的外部信息来更好地估计相似性。</p>\n<h4 id=\"基于打分的相似\">基于打分的相似</h4>\n<p>在许多在线电子商务服务中，用户可以通过打分对消费对象进行评价。 例如，在雅虎音乐中，用户用一到五颗星给每首歌曲投票，1星-“再也不播放” ，2星-“可以”，3星-“喜欢”，4星-“爱它”和5星-“非常爱”。 通过显性的评分信息，我们可以通过余弦指数[15,137]来测量两个用户之间或两个对象之间的相似度，余弦指数定义如下：<span class=\"math display\">\\[ S_{xy}^{cos} = \\frac{r_x \\bullet r_y}{| r_x || r_Y|} \\quad \\quad \\quad (33)\\]</span>计算用户之间的相似性时，<span class=\"math inline\">\\(r_x，r_y\\)</span>是N维商品空间中的评估向量，而当计算商品之间的相似性，<span class=\"math inline\">\\(r_x，r_y\\)</span> 是M维度用户空间中的向量。 请注意，在计算基于评分的相似度时，有必要消除用户和/或商品的评级倾向，否则相似性结果没意义。 实际上，根据最近报道的智能方法，在一些评分系统中，通过适当使用评分趋势，预测未知评分的时候可以比基于相似度的简单方法准确性高得多[116]。</p>\n<p>评分相关性也可以通过person系数来计算。通过公式<span class=\"math display\">\\[ s_{uv}^{PC}  = \\frac {\\sum_{\\alpha \\in O_{uv}} (r_{u\\alpha} - \\bar r_u)(r_{v\\alpha} - \\bar r_v)} {  \\sqrt{\\sum_{\\alpha \\in O_{uv}} (r_{u\\alpha} - \\bar r_u)^2}   \\sqrt{\\sum_{\\alpha \\in O_{uv}} (r_{v\\alpha} - \\bar r_v)^2}   } \\quad \\quad \\quad(34)\\]</span>来量化用户 <span class=\"math inline\">\\(u\\)</span> 和 <span class=\"math inline\">\\(v\\)</span> 之间的相似性，其中 <span class=\"math inline\">\\(O_{uv} = \\Gamma_u \\cap \\Gamma_v\\)</span> 表示被用户<span class=\"math inline\">\\(u,v\\)</span>同时评分的商品集合。由Shardanand和Maes提出的约束Pearson系数[127]用“中心”(central)评分（例如，从1到5的评分，可以将中心评分设置为3）来代替公式34中的用户平均值。 这个想法是考虑到积极（高于中心评分）和负面评分（低于中心评分）之间的差异。 加权Pearson系数是基于捕获可以放在相似度值上的置信度的想法（当两个用户只评分了几个共同的商品时，它们的潜在的高相似性不应该 和具有许多共同商品评分的一对用户可信度一样）。 [138]提出将皮尔逊系数加权为<span class=\"math display\">\\[S_{uv}^{WPC} = \\begin{cases} S_{uv}^{PC}\\frac{O_{uv}}{H} &amp;  for \\space |O_{uv}| \\leq H \\\\\\\\ S_{uv}^{PC} &amp; otherwise\\end{cases} \\quad \\quad \\quad(35)\\]</span>其中H是阈值，通过实验确定，超过该阈值的相关性可信。</p>\n<p>类似的，商品之间的person相似性溃疡定义为 <span class=\"math display\">\\[ s_{\\alpha \\beta}^{PC}  = \\frac {\\sum_{u \\in U_{\\alpha \\beta}} (r_{u\\alpha} - \\bar r_{\\alpha})(r_{u\\beta} - \\bar r_{\\beta})} {  \\sqrt{\\sum_{\\alpha \\in O_{uv}} (r_{u\\alpha} - \\bar r_{\\alpha})^2}   \\sqrt{\\sum_{\\alpha \\in O_{uv}} (r_{u\\beta} - \\bar r_{\\beta})^2}   } \\quad \\quad \\quad(36)\\]</span> 其中 <span class=\"math inline\">\\(U_{\\alpha \\beta}\\)</span>是同时给商品 <span class=\"math inline\">\\(\\alpha ,\\beta\\)</span> 评分的用户集合， <span class=\"math inline\">\\(\\bar r_{\\beta}\\)</span>是商品 <span class=\"math inline\">\\(\\beta\\)</span> 评分的平均值。试验证明Pearson系数比向量的余弦指数效果更好。当只有二元评分（喜欢和不喜欢，购买了和米有购买，点击或者没有点击）的时候，余弦和pearson系数依旧可以量化二元向量的相似性。 例如，亚马逊的专利算法[117]通过计算代表用户购买情况的二元向量的余弦相似性来做基于商品的协同过滤。</p>\n<h4 id=\"结构相似性主要是基于复杂网络的一些技术\">结构相似性，主要是基于复杂网络的一些技术</h4>\n<p>如上所述，可以使用诸如标签和内容信息之类的外部属性来定义相似度。然而，所需的数据通常很难收集。另一个简单而有效量化相似性的方法是结构相似性[139]，它是完全基于数据的网络结构。最近的研究表明，相对于Pearson相关系数相似性方法，基于结构的相似性可以产生更好的推荐结果，特别是当输入数据非常稀疏时[122]。</p>\n<p>为了计算用户或者商品之间的结构相似度，我们通常将包含系统完整信息的用户商品二分网络投入到用户-用户或商品-商品网络中（有关相似性方面的更多信息，请参见[103]）。在最简单的情况下，如果两个用户至少投票一个相同商品，那么两个用户被认为是相似的（类似地，如果两个商品被至少一个用户共同投票，则被认为是相似的）。更精细的相似性度量可以粗略地分类为依赖于路径的路径，本地与全局，无参数与参数相关，等等。我们将回顾其中的一些。</p>\n<p>（i）节点依赖相似性。最简单的加权相似性指数是相同的邻居（CN），其中两个节点的相似性由公共邻居的数量直接给出（考虑同时购买<span class=\"math inline\">\\(\\alpha \\beta\\)</span>两个商品的用户数量和/或用户u和v都购买的商品数量）。通过考虑两个目标节点的度，得出了CN的六个变体：Salton指数[140]，Jaccard指数[141]，Sørensen指数[142]，Hub推荐指数（HPI）[143]，Hub Depressed Index（HDI）和Leicht-Holme-Newman指数（LHN16）[144]。可以进一步考虑各个共同邻居的度来奖励具有较高权重的较少连接的邻居，如在Adamic-Adar指数（AA）[145]和资源分配指数（RA）[102]。注意，由于AA使用对数加权，因此对于高度共同邻居惩罚小于RA的。最后，优先连接 (PA)指数建立在网络科学中的经典优先连接规则的基础上[146]。该指标已被用于量化各种基于网络动态的链路的功能意义，如渗透[147]，同步[148]和运输[149]（This index has been used to quantify the functional significance of links subject to various network- based dynamics, such as percolation [147], synchronization [148] and transportation [149]. ）。请注意，当计算用户和商品相似度，这些相似度也可以用于公共邻居是对象和用户的二分网络。这些相似性指数的数学定义的总结如表4所示。</p>\n<div class=\"figure\">\n<img src=\"/images/table4.png\" />\n\n</div>\n<p>（ii）基于边的相似性。 这里的基本假设是，如果两个节点通过许多边连接，则它们是相似的。 由于相邻矩阵<span class=\"math inline\">\\(A_n\\)</span>的n次方的元素等于各对节点之间不同路径的数量，所以路径相关相似性度量通常可以以紧凑形式写成，例如<span class=\"math display\">\\[ S_{xy}^{LP} = (A^2)_{xy}+ \\epsilon(A^3)_{xy} \\quad \\quad \\quad(37)\\]</span>对于局部路径指数[150]，其中只有长度为2和3的路径和 <span class=\"math inline\">\\(\\epsilon\\)</span> 是阻尼参数。 （请注意，在一个二分网络中，同类型节点之间只能有一个偶数长度的路径。）通过包括所有长度的路径，我们获得经典的Katz相似度[151]，其被定义为<span class=\"math display\">\\[ S_{xy}^{Katz} = \\beta A_{xy}+\\beta^2(A^2)_{xy}+ \\beta^3(A^3)_{xy} + \\cdots \\quad \\quad \\quad(38)\\]</span> $$ 其中是阻尼系数控制路径的权重，这个公式可以改写为 $S^{Katz} = (I - A)^{-1} -I $ 。Leicht-Holme-Newman指数（LHN2）[144]是Katz指数的变体，其中 <span class=\"math inline\">\\(（A^l)_{xy}\\)</span> 被 <span class=\"math inline\">\\(（A^l)_{xy} / E[(A^l_{xy}]\\)</span>代替，其中<span class=\"math inline\">\\(E[X]\\)</span>是X的期望。</p>\n<p>（iii）基于随机游走的相似性。 该类方法是基于网络上的随机游走。</p>\n<p><strong><em>平均到达时间</em></strong>：节点x和y之间的平均通勤时间被定义为随机步行者从节点x开始到达节点y加上从y到x所需的平均步数。 可以通过网络的拉普拉斯矩阵 <span class=\"math inline\">\\(L^+\\)</span> 的伪逆来获得，如[152,153] <span class=\"math display\">\\[n(x,y) = ((L^+)_{xx} +(L^+)_{yy} - 2(L^+)_{xy})E \\]</span> 其中E是网络中的边数量。 假设当两个节点的平均通勤时间很小时两个节点相似，节点x和y之间的相似性可以被定义为它们的平均通勤时间的倒数 <span class=\"math display\">\\[ S_{xy}^{ACT}=\\frac{1}{((L^+)_{xx} +(L^+)_{yy} - 2(L^+)_{xy})} \\]</span> 其中常量 <span class=\"math inline\">\\(E\\)</span> 被移除</p>\n<p><strong><em>基于 <span class=\"math inline\">\\(L^+\\)</span> 的余弦</em></strong>：该指标是基于內积的一个度量方式。 在欧几里德空间中$v_x = <sup>{}U</sup>T e_x $ ，U是由其特征值x的递减顺序排列的<span class=\"math inline\">\\(L^+\\)</span>的特征向量组成的正交矩阵，<span class=\"math inline\">\\(\\Lambda= diag(x)\\)</span>，<span class=\"math inline\">\\(e_x\\)</span>是列基向量 <span class=\"math inline\">\\(（(e_x)_y = xy)\\)</span> 和T是矩阵转置，拉普拉斯矩阵的伪逆的元素由节点的向量內积构成，<span class=\"math inline\">\\(（L^+)_{xy} = v_x^T v_y\\)</span>。因此余弦相似度定义为[153] <span class=\"math display\">\\[S^{cos+}_{xy} = \\frac{v^t_xv_y}{|v_x|v_y|} = \\frac{(L^+)_{xy}}{(L^+)_{xx}(L^+)_{yy}}\\]</span></p>\n<p><strong><em>带重启的随机游走</em></strong> <span class=\"math display\">\\[q_x  =cP^Tq_x +(1-c)e_x \\]</span> 其中P是 如果x和y连接而 $P_{xy} = 1 / k_x $ 的转置矩阵，否则为<span class=\"math inline\">\\(P_{xy} = 0\\)</span>。 解决方案这个方程是</p>\n<p><strong><em>SimRank</em></strong></p>\n<p><strong><em>局部随机游走</em></strong></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"基于相似的算法\">基于相似的算法</h3>\n<p>基于相似的推荐算法代表着推荐系统中最成功的一种，他们已经被广泛研究并在电子商务中的建立了各种应用[117,118]。这类算法可以进一步分为基于用户（user-base）和基于项目(item-base)相似度的方法。基于用户相似性的方法的基本假设是，在过去的评价一致的人在未来的评价中往往会再次一致。因此，对于目标用户，根据与目标用户相似的用户（“品味对象”）的评价来估计对象的潜在评价（参见图5作为示意图）。与用户相似度不同，基于项目相似度的算法向用户推荐与用户之前收集的对象相似的对象。请注意，有时来自不相似用户（兴趣不同）[119]或负面评价[120,121]的意见在确定推荐系统过程中可能发挥重要（甚至是积极的）作用，特别是当数据集非常稀疏时，因此关联性的信息比相似性信息更加重要[122]。有关更多信息，请参阅最近的回顾文章[123,124]，[125]是一个很好的综述，其中包含许多相似性指数。</p>\n<div class=\"figure\">\n<img src=\"/images/fig5.png\" />\n\n</div>\n<h4 id=\"算法\">算法</h4>\n<p>这里我们简要的介绍常规的基于相似度的算法即常说的基于记忆的协同过滤技术。 “协同过滤”一词由第一个商业推荐系统的创作者Tapestry [126]引入，他源于这样一个事实：它需要多个代理人协作共享他们的数据以获得更好的推荐。 在以下部分中，我们描述了基本算法以及计算相似度的主要方法，这是推荐过程的关键组成部分。</p>\n<h5 id=\"用户相似度\">用户相似度</h5>\n<p>该算法的目的是通过收集其他用户尤其是那些和目标用户具有相同评价的用户的评价来自动预测目标用户的偏好。设<span class=\"math inline\">\\(r_{u\\alpha}\\)</span>表示用户<span class=\"math inline\">\\(u\\)</span>对商品<span class=\"math inline\">\\(\\alpha\\)</span>的评价，<span class=\"math inline\">\\(\\Gamma_u\\)</span>表示用户<span class=\"math inline\">\\(u\\)</span>已经评价过的商品的集合。用户评价的平均值计算方式为<span class=\"math inline\">\\(\\bar {r_u} = \\frac {1} {|\\Gamma_u|} \\sum_{a \\in \\Gamma_u} r_{u\\alpha}\\)</span>。根据标准的协同过滤算法，预测的用户<span class=\"math inline\">\\(u\\)</span>对商品<span class=\"math inline\">\\(\\alpha\\)</span>的评价是<span class=\"math display\">\\[\\bar {r}_{u\\alpha}=\\bar {r}_u+K\\sum_{v \\in \\hat{U}_u} S_{uv}(r_{v\\alpha} - \\bar r_v ) \\quad \\quad \\quad  (25) \\]</span>其中<span class=\"math inline\">\\(\\hat{U}_u\\)</span>代表与目标用户<span class=\"math inline\">\\(u\\)</span>高度相似的用户集合，<span class=\"math inline\">\\(S_{uv}\\)</span>代表用户<span class=\"math inline\">\\(u\\)</span>和用户<span class=\"math inline\">\\(v\\)</span>之间的相似度,<span class=\"math inline\">\\(K = \\frac {1} {\\sum_v|S_{uv}|}\\)</span>是一个标准化的因子。如果没有显性的评价，只知道用户收集的对象（商品）的集合（隐性评价），我们的目标则是去预测用户未来最有可能会收集的对象，根据[119]，公式25应该被替换为<span class=\"math display\">\\[P_{u\\alpha} = \\sum_{v \\in \\hat{U}_u} S_{uv} \\alpha_{v\\alpha} \\quad \\quad \\quad  (26)\\]</span>其中<span class=\"math inline\">\\(P_{u\\alpha}\\)</span>是对用户<span class=\"math inline\">\\(u\\)</span>推荐商品<span class=\"math inline\">\\(\\alpha\\)</span>的分数，$_{v} $ 是“用户-商品”二部图的邻接矩阵的元素（如果用户<span class=\"math inline\">\\(u\\)</span>收集过对象<span class=\"math inline\">\\(\\alpha\\)</span> 则 <span class=\"math inline\">\\(\\alpha_{v\\alpha} =1\\)</span> 否则 <span class=\"math inline\">\\(\\alpha_{v\\alpha} =0\\)</span>）</p>\n<p>公式25和26已经明确说明了该算法只考虑那些和目标用户<span class=\"math inline\">\\(u\\)</span>相似的用户，通常有2种方法来获取<span class=\"math inline\">\\(\\hat U_u\\)</span> ：（i）相似系数阈值[127]通过选择相似度<span class=\"math inline\">\\(s_{uv}\\)</span>大于阈值的用户<span class=\"math inline\">\\(v\\)</span>，（ii）最大数量邻居方法[128]通过选择<span class=\"math inline\">\\(k\\)</span>个与用户<span class=\"math inline\">\\(u\\)</span>最相似的用户（<span class=\"math inline\">\\(k\\)</span>在这里是算法 的一个参数）。限制在只计算那些最相似的用户不仅有利于计算也能够获得更好的结果。</p>\n<h4 id=\"商品相似\">商品相似</h4>\n<p>在该算法中，商品之间的相似度<span class=\"math inline\">\\(S_{\\alpha \\beta}\\)</span>被引进代替用户之间的相似度<span class=\"math inline\">\\(S_{uv}\\)</span>，最简单的办法就是通过加权平均来估计那些未知的评价[130]<span class=\"math display\">\\[\\widetilde{r}_{\\alpha \\beta} = \\frac {\\sum_{\\beta \\in \\Gamma_u} S_{\\alpha \\beta} r_{u \\beta}} {\\sum_{\\beta \\in \\Gamma_u} |S_{\\alpha \\beta}|} \\quad \\quad \\quad  (27)\\]</span>其中<span class=\"math inline\">\\(\\Gamma_u\\)</span>表示用户<span class=\"math inline\">\\(u\\)</span>评级过的对象集合，和上面的用户相似度一样，在计算$_{} <span class=\"math inline\">\\(的时候将对象限制为那些和对象\\)</span>$最相似的的。相对于基于用户间的用户相似度方法，该算法的的好处是对象之间的相似度趋向于稳定的，允许离线计算其值和邻居 its values and neighborhoods（换言之，可以在用户请求推荐之前计算–这样可以缩短获取推荐的时间）。混合基于对象的和基于用户或基于用户属性的协同推荐算法在[131,132]中被提出来，他们的结果表明，该方法不但能够提高预测的精准性，而且对于那些稀疏的数据鲁棒性更好。</p>\n<h4 id=\"slope-one-predictor\">Slope One predictor</h4>\n<p>该算法是形式为 <span class=\"math inline\">\\(f(x) = x + b\\)</span> 的算法，其中<span class=\"math inline\">\\(b\\)</span>是常量<span class=\"math inline\">\\(x\\)</span>是代表打分的变量,他是最简单的基于打分的基于商品的协同过滤算法。它减掉两个商品的平均评分，以衡量一个商品在平均值上比另外一个商品喜好程度多多少。这个差别被用来预测用户对一个商品的评分当他对另外一个商品的评分已知的时候。举例来说，用户<span class=\"math inline\">\\(i\\)</span> 对商品$ $ 打分分别是1和2，用户 <span class=\"math inline\">\\(j\\)</span> 给商品 <span class=\"math inline\">\\(\\alpha\\)</span> 打了2分,Slope one 就会预测用户 <span class=\"math inline\">\\(j\\)</span> 对商品 <span class=\"math inline\">\\(\\beta\\)</span> 的打分为 $2+(1.5-1) =2.5 $(参考图6具体的说明)</p>\n<div class=\"figure\">\n<img src=\"/images/fig6.png\" />\n\n</div>\n<p>Slope one 算法同时考虑了对相同商品评分的其他用户和被同一用户评分的其他商品的信息，尤其在预测的过程中只考虑和目标用户有共同商品评分的用户和目标用户已经评分过的商品。用 <span class=\"math inline\">\\(S(\\alpha ,\\beta)\\)</span> 表示同时评价商品 $$ 和 <span class=\"math inline\">\\(\\beta\\)</span> 的用户集合，商品 <span class=\"math inline\">\\(\\beta\\)</span> 相对于商品 <span class=\"math inline\">\\(\\alpha\\)</span> 的平均偏差被定义为<span class=\"math display\">\\[dev_{\\beta \\alpha} = \\frac{\\sum_{i \\in S(\\alpha ,\\beta)} r_{i \\beta} -r_{i \\alpha} }{|S(\\alpha ,\\beta)|} \\quad \\quad \\quad  (28)\\]</span>给定一个已知的评分<span class=\"math inline\">\\(r_{u\\alpha}\\)</span>，slope one 预测用户 <span class=\"math inline\">\\(u\\)</span> 对商品 <span class=\"math inline\">\\(\\beta\\)</span> 的评分为 <span class=\"math inline\">\\(r_{u \\alpha}+dev_{\\beta \\alpha}\\)</span>，改变公式28中的 <span class=\"math inline\">\\(\\alpha\\)</span> ，我们会得到不同的预测结果，所以一个更加合理的全面的预测方法是对他们做平均。<span class=\"math display\">\\[\\bar r_{u\\alpha} = \\frac{1}{|R(u,\\alpha)|} \\sum_{\\alpha \\in R(u,\\alpha)} (r_{u \\alpha} +  dev_{\\alpha \\beta} ) \\quad \\quad \\quad  (29)\\]</span>，其中 <span class=\"math inline\">\\(R(u,\\alpha)\\)</span> 是用户 <span class=\"math inline\">\\(u\\)</span> 评价的商品集合，需要注意的是无论多少用户共同参与对商品 <span class=\"math inline\">\\(\\alpha \\beta\\)</span> 打分,算法对不同的商品 <span class=\"math inline\">\\(\\alpha\\)</span> 的权重是相同的。考虑到实际上 <span class=\"math inline\">\\(dev_{\\alpha \\beta}\\)</span> 依赖于 <span class=\"math inline\">\\(|S(\\alpha ,\\beta)|\\)</span>(重合的越多，信任度越高)，我们可以得到一个加权的 slope one算法 <span class=\"math display\">\\[ \\bar r_{u\\alpha}^w = \\frac{ \\sum_{\\alpha} |S(\\alpha ,\\beta)|(r_{u \\alpha} +  dev_{\\alpha \\beta} ) }{\\sum_\\alpha S(\\alpha ,\\beta)}\n\\quad \\quad \\quad  (30)\\]</span> 基本Slope One算法的另一个改进是将所有商品集合划分为用户喜欢和不喜欢的（一个来识别喜欢和不喜欢的项目直接标准是检查他们的评分是高于还是低于给定用户的平均评分）。从这些喜欢的和不喜欢的集合导出2个单独的预测然后结合在一起来预测。用 <span class=\"math inline\">\\(S^{+1}(\\alpha , \\beta) ,S^{-1}(\\alpha , \\beta)\\)</span> 分布代表用喜欢和不喜欢的集合，喜欢和不喜欢的偏差定义为 <span class=\"math display\">\\[ dev_{\\beta \\alpha}^{+1} = \\frac{1}{|S^{+1}(\\alpha ,\\beta)|}{\\sum_{i \\in S(\\alpha ,\\beta)} (r_{i \\beta} -r_{i \\alpha} )}   \\quad \\quad   dev_{\\beta \\alpha}^{-1} = \\frac{1}{|S^{-1}(\\alpha ,\\beta)|}{\\sum_{i \\in S(\\alpha ,\\beta)} (r_{i \\beta} -r_{i \\alpha} )}  \\quad  (31)\\]</span> 基于商品<span class=\"math inline\">\\(\\alpha\\)</span>的打分对商品<span class=\"math inline\">\\(\\beta\\)</span>的打分预测是 <span class=\"math inline\">\\(dev_{\\beta \\alpha}^{+1}\\)</span> 或者 <span class=\"math inline\">\\(dev_{\\beta \\alpha}^{-1}\\)</span> 这取决于目标用户 <span class=\"math inline\">\\(j\\)</span> 喜欢或者不喜欢商品<span class=\"math inline\">\\(\\alpha\\)</span>，于是定义 Bi-Polar Slope One为 <span class=\"math display\">\\[ p_{j\\beta}^{bi} = \\frac {\\sum_{\\alpha} |S^{+1}(\\beta ,\\alpha)|(r_{j\\alpha}+dev^{+1}_{\\\\beta \\alpha})+\\sum_{\\alpha} |S^{-1}(\\beta ,\\alpha)|(r_{j\\alpha}+dev^{-1}_{\\\\beta \\alpha})}   {\\sum_{\\alpha} |S^{+1}(\\beta ,\\alpha)|+\\sum_{\\alpha} |S^{-1}(\\beta ,\\alpha)|} \\quad \\quad \\quad (32)\\]</span> ，其中权重部分和带权重的Slope One相似。</p>\n<p>实践表明，slope one算法能够比线性回归（即通过<span class=\"math inline\">\\(f(x) = ax+b\\)</span>的估计）得到更好的结果，这个简单的方法也减少了存储成本和降低推荐系统的延迟性。Slope One已被用作积木来改进其他算法[134-136]。 例如，它可以与基于用户的协同过滤组合，以通过 slope one 方案填充用户商品矩阵的空白评分来解决数据稀疏问题，从而提高预测精度[134]。</p>\n<h3 id=\"如何定义相似\">如何定义相似</h3>\n<p>基于相似度算法的关键问题是如何定义用户或对象之间的相似性。 当显式评级可用时，通常使用诸如Pearson之类的相关指标来定义相似度（如果两个用户倾向于对他们评估的对象给出类似的评级，则认为两个用户相似）。 当没有可用的评估信息时，可以从输入数据的结构属性推断出相似性（当他们喜欢/购买了许多共同的对象时，两个用户被认为是相似的）。 此外，可以利用诸如用户属性，标签和对象的内容元信息之类的外部信息来更好地估计相似性。</p>\n<h4 id=\"基于打分的相似\">基于打分的相似</h4>\n<p>在许多在线电子商务服务中，用户可以通过打分对消费对象进行评价。 例如，在雅虎音乐中，用户用一到五颗星给每首歌曲投票，1星-“再也不播放” ，2星-“可以”，3星-“喜欢”，4星-“爱它”和5星-“非常爱”。 通过显性的评分信息，我们可以通过余弦指数[15,137]来测量两个用户之间或两个对象之间的相似度，余弦指数定义如下：<span class=\"math display\">\\[ S_{xy}^{cos} = \\frac{r_x \\bullet r_y}{| r_x || r_Y|} \\quad \\quad \\quad (33)\\]</span>计算用户之间的相似性时，<span class=\"math inline\">\\(r_x，r_y\\)</span>是N维商品空间中的评估向量，而当计算商品之间的相似性，<span class=\"math inline\">\\(r_x，r_y\\)</span> 是M维度用户空间中的向量。 请注意，在计算基于评分的相似度时，有必要消除用户和/或商品的评级倾向，否则相似性结果没意义。 实际上，根据最近报道的智能方法，在一些评分系统中，通过适当使用评分趋势，预测未知评分的时候可以比基于相似度的简单方法准确性高得多[116]。</p>\n<p>评分相关性也可以通过person系数来计算。通过公式<span class=\"math display\">\\[ s_{uv}^{PC}  = \\frac {\\sum_{\\alpha \\in O_{uv}} (r_{u\\alpha} - \\bar r_u)(r_{v\\alpha} - \\bar r_v)} {  \\sqrt{\\sum_{\\alpha \\in O_{uv}} (r_{u\\alpha} - \\bar r_u)^2}   \\sqrt{\\sum_{\\alpha \\in O_{uv}} (r_{v\\alpha} - \\bar r_v)^2}   } \\quad \\quad \\quad(34)\\]</span>来量化用户 <span class=\"math inline\">\\(u\\)</span> 和 <span class=\"math inline\">\\(v\\)</span> 之间的相似性，其中 <span class=\"math inline\">\\(O_{uv} = \\Gamma_u \\cap \\Gamma_v\\)</span> 表示被用户<span class=\"math inline\">\\(u,v\\)</span>同时评分的商品集合。由Shardanand和Maes提出的约束Pearson系数[127]用“中心”(central)评分（例如，从1到5的评分，可以将中心评分设置为3）来代替公式34中的用户平均值。 这个想法是考虑到积极（高于中心评分）和负面评分（低于中心评分）之间的差异。 加权Pearson系数是基于捕获可以放在相似度值上的置信度的想法（当两个用户只评分了几个共同的商品时，它们的潜在的高相似性不应该 和具有许多共同商品评分的一对用户可信度一样）。 [138]提出将皮尔逊系数加权为<span class=\"math display\">\\[S_{uv}^{WPC} = \\begin{cases} S_{uv}^{PC}\\frac{O_{uv}}{H} &amp;  for \\space |O_{uv}| \\leq H \\\\\\\\ S_{uv}^{PC} &amp; otherwise\\end{cases} \\quad \\quad \\quad(35)\\]</span>其中H是阈值，通过实验确定，超过该阈值的相关性可信。</p>\n<p>类似的，商品之间的person相似性溃疡定义为 <span class=\"math display\">\\[ s_{\\alpha \\beta}^{PC}  = \\frac {\\sum_{u \\in U_{\\alpha \\beta}} (r_{u\\alpha} - \\bar r_{\\alpha})(r_{u\\beta} - \\bar r_{\\beta})} {  \\sqrt{\\sum_{\\alpha \\in O_{uv}} (r_{u\\alpha} - \\bar r_{\\alpha})^2}   \\sqrt{\\sum_{\\alpha \\in O_{uv}} (r_{u\\beta} - \\bar r_{\\beta})^2}   } \\quad \\quad \\quad(36)\\]</span> 其中 <span class=\"math inline\">\\(U_{\\alpha \\beta}\\)</span>是同时给商品 <span class=\"math inline\">\\(\\alpha ,\\beta\\)</span> 评分的用户集合， <span class=\"math inline\">\\(\\bar r_{\\beta}\\)</span>是商品 <span class=\"math inline\">\\(\\beta\\)</span> 评分的平均值。试验证明Pearson系数比向量的余弦指数效果更好。当只有二元评分（喜欢和不喜欢，购买了和米有购买，点击或者没有点击）的时候，余弦和pearson系数依旧可以量化二元向量的相似性。 例如，亚马逊的专利算法[117]通过计算代表用户购买情况的二元向量的余弦相似性来做基于商品的协同过滤。</p>\n<h4 id=\"结构相似性主要是基于复杂网络的一些技术\">结构相似性，主要是基于复杂网络的一些技术</h4>\n<p>如上所述，可以使用诸如标签和内容信息之类的外部属性来定义相似度。然而，所需的数据通常很难收集。另一个简单而有效量化相似性的方法是结构相似性[139]，它是完全基于数据的网络结构。最近的研究表明，相对于Pearson相关系数相似性方法，基于结构的相似性可以产生更好的推荐结果，特别是当输入数据非常稀疏时[122]。</p>\n<p>为了计算用户或者商品之间的结构相似度，我们通常将包含系统完整信息的用户商品二分网络投入到用户-用户或商品-商品网络中（有关相似性方面的更多信息，请参见[103]）。在最简单的情况下，如果两个用户至少投票一个相同商品，那么两个用户被认为是相似的（类似地，如果两个商品被至少一个用户共同投票，则被认为是相似的）。更精细的相似性度量可以粗略地分类为依赖于路径的路径，本地与全局，无参数与参数相关，等等。我们将回顾其中的一些。</p>\n<p>（i）节点依赖相似性。最简单的加权相似性指数是相同的邻居（CN），其中两个节点的相似性由公共邻居的数量直接给出（考虑同时购买<span class=\"math inline\">\\(\\alpha \\beta\\)</span>两个商品的用户数量和/或用户u和v都购买的商品数量）。通过考虑两个目标节点的度，得出了CN的六个变体：Salton指数[140]，Jaccard指数[141]，Sørensen指数[142]，Hub推荐指数（HPI）[143]，Hub Depressed Index（HDI）和Leicht-Holme-Newman指数（LHN16）[144]。可以进一步考虑各个共同邻居的度来奖励具有较高权重的较少连接的邻居，如在Adamic-Adar指数（AA）[145]和资源分配指数（RA）[102]。注意，由于AA使用对数加权，因此对于高度共同邻居惩罚小于RA的。最后，优先连接 (PA)指数建立在网络科学中的经典优先连接规则的基础上[146]。该指标已被用于量化各种基于网络动态的链路的功能意义，如渗透[147]，同步[148]和运输[149]（This index has been used to quantify the functional significance of links subject to various network- based dynamics, such as percolation [147], synchronization [148] and transportation [149]. ）。请注意，当计算用户和商品相似度，这些相似度也可以用于公共邻居是对象和用户的二分网络。这些相似性指数的数学定义的总结如表4所示。</p>\n<div class=\"figure\">\n<img src=\"/images/table4.png\" />\n\n</div>\n<p>（ii）基于边的相似性。 这里的基本假设是，如果两个节点通过许多边连接，则它们是相似的。 由于相邻矩阵<span class=\"math inline\">\\(A_n\\)</span>的n次方的元素等于各对节点之间不同路径的数量，所以路径相关相似性度量通常可以以紧凑形式写成，例如<span class=\"math display\">\\[ S_{xy}^{LP} = (A^2)_{xy}+ \\epsilon(A^3)_{xy} \\quad \\quad \\quad(37)\\]</span>对于局部路径指数[150]，其中只有长度为2和3的路径和 <span class=\"math inline\">\\(\\epsilon\\)</span> 是阻尼参数。 （请注意，在一个二分网络中，同类型节点之间只能有一个偶数长度的路径。）通过包括所有长度的路径，我们获得经典的Katz相似度[151]，其被定义为<span class=\"math display\">\\[ S_{xy}^{Katz} = \\beta A_{xy}+\\beta^2(A^2)_{xy}+ \\beta^3(A^3)_{xy} + \\cdots \\quad \\quad \\quad(38)\\]</span> $$ 其中是阻尼系数控制路径的权重，这个公式可以改写为 $S^{Katz} = (I - A)^{-1} -I $ 。Leicht-Holme-Newman指数（LHN2）[144]是Katz指数的变体，其中 <span class=\"math inline\">\\(（A^l)_{xy}\\)</span> 被 <span class=\"math inline\">\\(（A^l)_{xy} / E[(A^l_{xy}]\\)</span>代替，其中<span class=\"math inline\">\\(E[X]\\)</span>是X的期望。</p>\n<p>（iii）基于随机游走的相似性。 该类方法是基于网络上的随机游走。</p>\n<p><strong><em>平均到达时间</em></strong>：节点x和y之间的平均通勤时间被定义为随机步行者从节点x开始到达节点y加上从y到x所需的平均步数。 可以通过网络的拉普拉斯矩阵 <span class=\"math inline\">\\(L^+\\)</span> 的伪逆来获得，如[152,153] <span class=\"math display\">\\[n(x,y) = ((L^+)_{xx} +(L^+)_{yy} - 2(L^+)_{xy})E \\]</span> 其中E是网络中的边数量。 假设当两个节点的平均通勤时间很小时两个节点相似，节点x和y之间的相似性可以被定义为它们的平均通勤时间的倒数 <span class=\"math display\">\\[ S_{xy}^{ACT}=\\frac{1}{((L^+)_{xx} +(L^+)_{yy} - 2(L^+)_{xy})} \\]</span> 其中常量 <span class=\"math inline\">\\(E\\)</span> 被移除</p>\n<p><strong><em>基于 <span class=\"math inline\">\\(L^+\\)</span> 的余弦</em></strong>：该指标是基于內积的一个度量方式。 在欧几里德空间中$v_x = <sup>{}U</sup>T e_x $ ，U是由其特征值x的递减顺序排列的<span class=\"math inline\">\\(L^+\\)</span>的特征向量组成的正交矩阵，<span class=\"math inline\">\\(\\Lambda= diag(x)\\)</span>，<span class=\"math inline\">\\(e_x\\)</span>是列基向量 <span class=\"math inline\">\\(（(e_x)_y = xy)\\)</span> 和T是矩阵转置，拉普拉斯矩阵的伪逆的元素由节点的向量內积构成，<span class=\"math inline\">\\(（L^+)_{xy} = v_x^T v_y\\)</span>。因此余弦相似度定义为[153] <span class=\"math display\">\\[S^{cos+}_{xy} = \\frac{v^t_xv_y}{|v_x|v_y|} = \\frac{(L^+)_{xy}}{(L^+)_{xx}(L^+)_{yy}}\\]</span></p>\n<p><strong><em>带重启的随机游走</em></strong> <span class=\"math display\">\\[q_x  =cP^Tq_x +(1-c)e_x \\]</span> 其中P是 如果x和y连接而 $P_{xy} = 1 / k_x $ 的转置矩阵，否则为<span class=\"math inline\">\\(P_{xy} = 0\\)</span>。 解决方案这个方程是</p>\n<p><strong><em>SimRank</em></strong></p>\n<p><strong><em>局部随机游走</em></strong></p>\n"},{"title":"推荐系统简介","date":"2017-09-28T11:12:32.000Z","_content":"\n\n\n###摘要\n\n互联网的持续爆发式扩张极大的增加了采用推荐系统过滤大量的信息的必要性，推荐系统被社会学，计算学物理学家和交叉学科等大量学界进行了广泛的研究 ，尽管取得了实质性的理论和实践成果，缺乏统一方法对不同的推荐算法比较，阻碍了其进一步的进步。在本文中，我们回顾了推荐系统的最新进展，并讨论了主要挑战。我们对比并评估了已有的算法，并推测他们在未来的发展中扮演的角色。除了算法之外，我们还从物理的角度来描述推荐系统的宏观行为。我们讨论了推荐系统潜在的影响和未来的发展。我们在此强调：推荐系统有很强的科学深度并结合了不同的研究领域，吸引着物理学家以及交叉学科研究人员的兴趣。\n\n###序言\n\n由于计算机和计算机网络，我们的社会各方面都经历着翻天覆地的变化，我们在线购物，通过搜索引擎搜集信息，在互联网上进行很大部分的社会活动。事实上，我们大量的行为和交互都以电子的方式存储，这给了研究人员机会在更加细尺度来研究社会经济和技术社会系统，传统的“软学科”，比如社会学和经济学，通过对这些已有的新数据的研究已经发展了许许多多的研究分支，在数据驱动研究方面有着长期经验的物理学家，也已经加入了这一趋势，为诸如金融[3,4]，网络理论[5-9]和社会动力学[10]等多个非传统领域做出了贡献。随着过去十几年间物理学家的兴趣的持续增长，推荐系统和信息检索的研究也不例外。推荐系统的任务是利用用户及其偏好的数据预测用户未来可能的喜好和兴趣。推荐系统的研究处于科学和社会经济生活的十字路口，其巨大的潜力首先被信息革命前沿的网络企业家所注意。虽然原本是由计算机科学家主导的领域，但推荐系统需要各领域的贡献，现在它也是数学家，物理学家和心理学家感兴趣的话题。例如，最近在商业公司Netflix [11]组织的的推荐比赛中，基于人类行为的心理学方法获得高分并不是巧合。\n\n当为目标用户做推荐时，最基本的方法是选择与目标用户相似的用户所青睐的对象。即使这种简单的方法也可以通过多种方式实现，这是因为推荐领域缺乏一般性的“第一原则”-从中可以推断出正确的推荐方式。例如，如何最好地衡量用户相似性并评估其不确定性？如何综合各种用户的意见分歧？如何处理少量信息的用户？所有数据是否权重平等，或者是否可以检测到鲁莽或故意误导的意见？当使用比基于用户相似性的方法更复杂的方法时，也出现和这些类似的问题。幸运的是，存在一些可用于测量和比较各种方法的实际数据集。因此，与物理学类似，实验决定哪种推荐方法是好的，哪种不是。\n\n认为推荐系统只有在适当的数据集可用的情况下才会被研究是非常有误导性的。虽然数据的可用性对推荐方法的实证评估很重要，但主要驱动力来自实践：电子系统给我们太多的选择让我们自己来处理。工业界对推荐的兴趣并不奇怪，一本关于推荐系统领域的早期书《Net Worth by John Hagel III and Marc Singer [12]》明确指出“（info-mediaries）”的巨大经济影响，它可以大大提高个人消费者的信息能力。现在，大多数电子商务网站提供各种形式的推荐--从简单的显示最受欢迎的项目或通过复杂的数据挖掘技术推荐的相同生产者的其他产品。人们很快意识到没有独特的最佳推荐方法， 相反，根据可用数据的上下文和密度，对不同的应用场景采用不同的推荐算法是最有可能成功的。因此，没有灵丹妙药，最好的办法是了解基本的前提（推荐场景）和推荐机制，这样就可以解决来自生活中的各种真实应用问题。 这一点也反映在这篇综述中，我们不试图强调任何推荐算法。 相反，我们回顾基本的思想，方法和工具with particular emphasis on physics-rooted approaches.\n\n撰写此综述的原因是多方面的，首先，虽然计算机科学家对推荐系统的广泛评论已经存在[13-15]，但是物理学家与计算机科学家的观点不同，它们更多的使用复杂网络方法和采用各种经典物理过程（如扩散）来做信息检索。因此，我们相信，该综述（We thus believe that this review with its structure and emphasis on respective topics can provide a novel point of view.）可以提供一个新颖的观点。 其次，过去十年已经看到物理学家对推荐系统的兴趣越来越大，我们希望通过用物理学界更熟悉的语言来描述最先进的技术的这篇综述可以成为他们的有用来源。 最后，这里介绍的跨学科方法可能为信息检索领域的开放性问题和挑战提供新的见解和解决方案。\n\n本篇综述结构如下：为了激发研究问题的积极性，我们首先在第2章讨论了推荐系统的实际应用。接着在第3节中，我们介绍了基本概念，例如复杂网络，推荐系统和评估指标，这些概念构成了后续阐述的基础。 然后，我们开始讨论推荐算法，首先是传统方法（第4节中基于相似性的方法和第5节中的维数降低技术），然后是起源于随机游走过程被物理学所熟知的基于网络的方法（在第6节）。还包括基于外部信息的方法，如社交关系（第7节），关键字或时间戳（第8节）。 我们最后在第9节中对推荐算法的性能进行简要评估，并在第10节讨论了该领域的前景。\n\n###推荐系统应用真实场景\n\n####Netflix prize\n\n####主要挑战\n\n推荐系统领域的研究人员面临着许多挑战，这些挑战对其使用和执行算法构成风险。这里我们只提到主要的：\n\n1. 数据稀疏\n 由于可用数据量非常大（比如，大型的在线书店经常有几百万的书），导致用户之间的交集十分小甚至没有。此外，即便每个用户/商品平均评估次数很高，但是由于每个商品/用户的评估次数分布非常不均匀（通常是power-law或者weibull分布），大部分的商品只有极少的评分，所以一个有效的推荐系统必须考虑到数据的稀疏性问题。\n\n1. 可扩展性\n 尽管数据经常是稀疏的，但是对于那些大型的网站拥有百万的用户和商品。因此必须考虑计算成本的问题，寻找计算要求不高的或者易于并行化的推荐算法。另一种可能的解决方案是基于使用增量数据的算法（增量学习算法），随着数据的增长，算法不会在全局重新计算，而是逐步增量计算[29,30]，这种增量方法类似于在物理和数学广泛应用的扰动技术[31]。\n \n1. 冷启动\n 当新的用户进入一个系统，系统中没有任何有用的信息来产生推荐结果给用户，通常的解决办法是通过结合基于内容的和协同过滤的混合推荐技术（参考 8.4 节），有时还需要获取用户的一些基本信息（如年龄，位置和偏好等）来配合。另外的一个方法是识别不同web服务中的同一个用户。比如说百分点开发了一个可以跟踪同一个用户在不通电商网站行为的技术，那么一个在A网站作为冷启动的用户可以通过他在B，C，D 网站的行为来进行相关的推荐。\n \n\n1. 多样性与精确性的两难困境\n 当推荐任务是为特定用户赞赏的项目时，通常最有效的方法是推荐流行的和高评分的项目，但是这样的推荐对用户来说没有什么价值，因为即便在没有推荐系统的情况下，流向的项目也很容易被找到（甚至难以避免），因此一个好的推荐项目列表也应该包括那些用户自己本身无法找到的隐藏项目[35]。对于这个问题的解决办法有：直接增加推荐列表的多样性[36-38]和使用混合的推荐算法[39]\n  \n1. 攻击的脆弱性\n 受推荐系统在电子商务领域重大的经济利益的驱动，一些心怀不轨的用户通过提供一些虚假恶意的信息，故意增加或者压制某些商品被推荐的可能性[44]。从阻止恶意评估进入系统到复杂的抵抗推荐技术[41]，有大量的工具可以防止这样的行为。然而，这并不是一件容易的事情，因为随着防作弊的工具的升级，攻击者的策略也越来越先进。例如，Burke等人[42]引入了八个攻击策略，进一步可以分为四个类：基本攻击（包括随机和平均攻击），低认知攻击，核攻击和知情攻击。（basic attack, low-acknowledge attack, nuke attack and informed attack.需要看引文来翻译）\n \n1. 时间的价值（好像是讲兴趣漂移问题）\n 一个真实用户的兴趣是和时间尺度相关的（举例来说，短期感兴趣与旅行计划相关，长期兴趣和居住地或者政治相关），大多数的推荐算法评估的时候都忽略了时间的影响。旧的想法是否会随着时间衰减，怎么衰减，以及用户评估和项目相关性中的典型临时模式是什么，这些都还需要持续的研究\n \n1. 推荐的评估\n 虽然我们有很多不同的指标（见第3.4节），但是如何根据给定的情况和任务选择最好的指标仍然是一个悬而未决的问题。不同推荐算法的比较也存在问题的，因为不同的算法可以简单地解决不同的任务，最后，推荐系统的整体用户体验（包括用户对推荐结果的满意程度和用户对系统的信任）难以在“离线”评估中进行测量。因此，在推荐系统中，实证用户的研究仍然是一个受欢迎的反馈来源。\n\n1. 用户界面\n 实践表明，为了促进用户接受推荐结果，推荐过程需要透明化：用户明白为什么特定的项目被推荐给他们。除此之外，通常潜在的感兴趣项目列表会很长，因此它需要简单的方式来展现，并且可以轻松的通过他去浏览由不同方法给出的推荐结果。\n \n 除了以上的长期挑战，推荐系统近期出现了许多新颖的问题，由于相关科学的方法论的发展，特别是网络分析的新工具，科学家开始考虑网络结构对推荐的影响，以及如何利用已知的结构特征来改进推荐。例如，Huang等人[47]分析了消费者-商品网络，并提出了一种改进的推荐算法，这种算法偏向增强局部聚类属性的边。Sahebi等[48]设计了一种利用社区结构的改进算法。新技术的进步和传播也带来新的挑战。例如，配备GPS的手机已经成为主流，互联网的被普遍的接入，因此基于位置的推荐现在是可行的并且越来越显有意义，精准的推荐要求人类的运动的高可预测性和定量方式来定义地点和人之间的相似之处。最后，智能推荐系统应考虑不同人群的不同行为模式。例如，新用户倾向于访问非常受欢迎的项目并选择类似的项目，而老用户通常具有更具体的兴趣[53,54]，并且用户在低风险（例如收集书签，下载音乐等）和高风险（例如购买电脑，租房等）活动之间的行为差​​异很大。\n\n\n\n其实可以直接看周涛老师的一篇中文论文 [《个性化推荐的十大挑战》](http://blog.sciencenet.cn/blog-3075-588779.html)，里面讲的更加具体，虽然推荐系统经过了这么多年的发展，但是对现在的推荐系统依旧面临着文中的问题。\n\n\n###主题和问题的定义\n\n 我们在本章中简要回顾一下在推荐系统研究中有用的基本概念。\n \n####1.  图\n\n 网络分析是揭示许多复杂系统组织原理的通用工具[5-9]。网络是一组元素（称为节点或顶点），它们之间具有连接（称为边或链接）。许多社会，生物，技术和信息系统可以被描述为具有代表个人或组织的节点和捕获其交互的边缘的网络。 网络研究，即数学文献中的图论，具有悠久的历史，从18世纪欧拉所解决的古典柯尼斯堡桥梁问题开始[57]。用数学的定义，网络$G$是一个有序的不相交的二元组集合$(V,E)$其中$V$是节点的集合$E$是边的集合。在一个无向网络中，一条连接节点$x$和$y$的边表示为$x \\leftrightarrow  y$,$x \\leftrightarrow  y$和$y \\leftrightarrow  x$代表的是同一条边,在一个有向网络中，边是一个关于节点的有序二元组，$x\\rightarrow y$ 代表由$x$指向$y$的一条边，边$x\\rightarrow y$ 和$y\\rightarrow x$是不同的，并且可以同时存在的。除非另有说明，否则我们假设网络不包含自环（连接节点到其自身的“边”）或连接同一对节点的多边（多个“边”）。在多网络（multinetwork）中，允许两个循环和多边。\n  \n 在无向网络$G(V，E)$中，如果$x\\leftrightarrow  y \\in E$，则两个节点$x$和$y$被认为是彼此相邻的。节点$x$的邻域节点集合，或者说$x$邻居集合由$\\Gamma_{x}$来表示,节点$x$的度定义为$k_{x}=|\\Gamma_{x}|$.度分布$P(k)$定义为随机选择的节点的度为$k$的概率.在一个均匀的网站，每一个节点有着相同的度$k_{0}$，所$P_{k}=\\delta_{k,k_{0}}$,在经典的Erdös–Rényi随机网络中，其中每对节点以给定的概率$p$连接生产边，其度分布满足二项式分布。$$P(k)={N-1 \\choose k}p^{k}(1-p)^{n-1-k} \\quad \\quad \\quad (1)$$其中$N=|V|$是网络中节点的数量。这样的分布有一个以平均度$\\bar x = p(N-1)$表示的特征量表.在上个世纪末，研究人员转而对大规模实际网络进行调查，结果发现他们的度分布通常跨越几个数量级，大致遵循幂律形式$$P(k)\\sim k^{-\\gamma} \\quad \\quad \\quad (2) $$其中$\\gamma$为正指数，通常位于2和3之间[5]，这种网络被称为无标度网络，因为他们缺乏度的特征尺度，幂律函数$P(k)$是与规模无关的。注意，实践数据中的幂律分布的检测需要固定的统计工具[62,63]。 对于有向网络，由$k^{out}$表示的节点$x$的出度，是从x开始的边的数量，入度$k^{in}$是以x结束的边的数量。 有向网络的进度和出度分布通常彼此不同。\n\n 一般来说，如果一个网络的高度节点倾向于与高度节点连接，而低度节点倾向于与低度节点连接，那么它被认为是同配assortative的（如果情况相反，那就是异配的)。 该度-度相关性可以由最近邻节点门的平均度[64,65]或皮尔逊系数的变体称为分类系数[66,67]来表征。 分类系数$r$在$-1≤r≤1$的范围内。如果$r> 0$，网络是同配的; 如果$r <0$，则网络是异配的。 请注意，该系数对度非均匀性（heterogeneous degree ）敏感。 例如，无论网络的连接模式如何，r在具有非常非均匀性度分布的网络（例如，因特网）中将为负值[68]。\n\n 连接两个节点的路径中的边数被称为路径的长度，两个节点之间的距离被定义为连接它们的最短路径的长度。 网络的直径是所有节点对之间的最大距离，平均距离是所有节点对上的平均距离平均值$$\\bar d = \\frac{1}{N(N-1)}\\sum_{x \\neq y}d_{x,y} \\quad \\quad \\quad (3) $$其中$d_{x,y}$是$x$和$y$之间的距离.许多真实网络显示出所谓的小世界现象：它们的平均距离不会比网络大小的对数增长得快[70,71]。\n \n 三元聚类在社会互动系统中的重要性的认知已经超过100多年[72]。 在社交网络分析中[73]，这种聚类称为传递性，定义为网络中三角形总数与相连节点的三元组总数之比的三倍。 1998年，Watts和Strogatz [71]提出了一个类似的指数来量化三元聚类，称为聚类系数。 对于给定的节点$x$，该系数被定义为$x$的邻居之间边的数量与邻居对的数量的比率，$$c_x=\\frac{e_x}{\\frac{1}{2}k_x(k_x)-1} \\quad \\quad \\quad (4) $$其中$e_x$表示节点$x$的$k_x$个邻居之间的边数量（该定义仅在$k_x> 1$时有意义）。 网络聚类系数被定义为$k_x> 1$的所有$x$的$c_x$的平均值。也可以将聚类系数定义为网络中三角形数$\\times 3$与连接的三元组顶点数之比，有时也被称为“传递三元组的分数(‘fraction of transitive triples’)”[7]。 请注意，这两个定义可以给出完全不同的结果。\n \n 图1说明了简单无向网络的上述定义。 有关网络测量的更多信息，我们鼓励读者去参考关于网络特征的文章[74]。\n \n ![](/images/fig1.png)\n 图1. 一个拥有6个节点7条边的简单无向网络，节点的度分别为$k_1=1,k_2=k_5=3,k_3=k_4=k_6=2$,对应的节点的度分布$p(1)=\\frac{1}{6},p(2)=\\frac{1}{2},p(3)=\\frac{1}{3}$,网络的直径和平均平均距离为$d_{max}=3,d=1.6$,聚类系数为$c_2=\\frac{1}{6},c_3=c_4=0,c_5=\\frac{1}{3},c_6=1$,平均聚类系数为$C=0.3$\n \n \n####2.  二部图和超图\n\n 如果一个网络$G(V,E)$满足分割为$(V_1,V_2)$后，$V_1\\cup V_2=V$并且$V_1\\cap V_2=\\emptyset$，每一条边由一个$V_1$和一个$V_2$中的节点连接而成,那么这就是一个二部图。许多真实系统自然地被模拟为二部图，比如，由化学物质和化学反应组成的代谢网络[75]，由行为和行为者组成的协作网络[76]，由个人电脑和电话号码[77]的互联网电话网络等等。我们专注于一类特殊的二分网络，称为基于网络的用户商品网络[53]，它们代表在线服务网站中的用户和商品之间的相互影响，例如在Delicious.com中的书签集合以及在amazon.com上购买的书籍。我们将在后面看到，这些网络描述了推荐系统的基本结构。 基于Web的用户商品网络是逐渐演进的，其中节点和链接逐渐被添加。 相比之下，这不可能发生在例如作者合作网络（例如，在发布之后无法将作者添加到科学论文）。\n \n 大多数的基于web的用户商品网络有着共同的结构属性，他们的（object-degree）商品度分布遵循幂律式形式$P(k)\\sim k^{-\\gamma} $,对于互联网电影数据库（IMDb）来说 $\\gamma \\approx 1.6$[78],音乐共享站点audioscrobbler.com的 $\\gamma \\approx 1.8$ [79]，对于电子商务网站amazon.com [53] $\\gamma \\approx 2.3$；对于书签共享网站delicious.com来说 $\\gamma \\approx 2.5$。用户度分布的形式通常在指数和幂律之间[53]，并且可以很好地拟合Weibull分布分布[27]（文献中也称为拉伸指数分布[80]）$$P(k)=k^{\\mu-1}exp[-(k/k_0)^\\mu] \\quad \\quad \\quad (5) $$其中$k_0$是常数，$\\mu$是拉伸指数。 用户和商品之间的连接（边）表现出一种异配（disassortative）混合模式[53,78]。\n 二部图定义的简单扩展是所谓的多部图。对于一个r-partite的图，他存在r个节点集合$V_1,V_2...V_r$，并$V=V_1 \\cup V_2 \\cup...\\cup V_r,V_i\\cap V_j=\\emptyset ,其中i\\neq j$，并且对于所有的节点集合$V_i$，不存在同一集合的节点之间的边。多部网络已经在协作标签系统（文献也称众分类法Folksonomies）[81-84]中找到了应用，用户可以在其中为在线资源分配标签，例如flickr.com中的照片，CiteULike.com中的参考文献和delicious.com中的书签等在线资源分配标签。\n \n 请注意，三部网络表示形式中丢失了一些信息。例如，给定一条连接资源和标签的边，我们不知道哪个用户（或用户们）对此边有贡献。对于这个问题，超图[85]可以用来给出协作标签系统的完整结构的精确表示。在超图$H(V,E)$中，超集$E$是$V$的幂集的子集，即V的所有子集的集合。 因此，边$e$可以连接多个节点。 类似于普通网络，超图中的节点度被定义为与节点相邻的超节点的数量，并且两个节点之间的距离被定义为连接这些节点的最小数量的超边。 聚类系数[82,86]和社区结构[86,87]也可以按照普通网络中的定义进行定义和量化。 请注意，超图和二分网络之间存在一对一的对应关系。给定超图$H（V，E）$，相应的二分网络$G（V^\\prime，E^\\prime）$包含两个节点集，如$V^\\prime= V\\cup E$，而$x \\in V$与$Y \\in E$连接，当且仅当$x \\in Y$（参见图2作为说明）。\n \n ![](/images/fig2.png)图2. 超图（a）和二分网络（b）之间的一一对应的图示。 有三个超边，X = {1,2,4}，Y = {4,5,6}和Z = {2,3,5,6}。\n \n \n 超图已经在铁磁动力学[88,89]，人口分层[90]，蜂窝网络[91]，学术团队形成[92]等许多领域中得到应用。 在这里，我们更关心协作标签系统的超图表示[86,93,94]，其中每个超边连接三个节点（由图3中的三角形表示），用户 $u$ ，资源 $r$ 和标签 $t$ ， 表示用户 $u$ 把标签 $t$ 给了资源 $r$ 。 资源可以由许多用户收集，并且由用户给出几个标签，标签可以与许多资源相关联，这就导致了小世界超图[86,94]（图3显示了基本单元和广泛的描述）此外，协同标签系统的超图已被证明是高度集群化的，它具有长尾度分布和社区结构[86,94]。[94]可以找到超图的演变模型。\n \n ![](/images/fig3.png)图3. 协同标签网络的超图。 （左）一个类似三角形的超边[93]，其中包含三种类型的顶点，一个蓝色圆圈，一个绿色矩形和一个棕色三角形，分别表示用户，资源和标签。 （右）描述由两个用户组成，四个资源和三个标签的超图。 以用户$U_2$和资源$R_1$为例，测量值表示为：（i）$U_2$已经参与在六个超边，这意味着它的超度是6; （ii）$U_2$直接连接到三个资源和三个标签。 按照公式 （6），认为它最大可能有$3 * 3 = 9$ 超边。 因此，其聚类系数等于$6/9=0.667$，其中6是其超度; 相对而言，如定义按式（7），其聚类系数为$D_h(U2)= \\frac {12-6} {6-4} = 0.75$; （iii）从$U_2$到$R_1$的最短路径为$U_2-T_1-R_1$，表示$U2$与$R_1$之间的距离为2\n\n \n  一般来说，以复杂科学角度的评估超图可以从以下几点展开（图3给出这些的详细描述）：\n  \n   1. 超度：超图中的节点的度可以自然地定义为与其相邻的超边的数量。\n   2. 超度分布：定义为每个超度占据的比例，其中超度定义为常规节点参与的超边的数量。\n   3. 聚类系数：定义为节点的实际超边数量与可能的超边数量的比例[82]。 例如，用户的聚类系数$C_u$定义为$$C_u=\\frac{k_0}{R_uT_u} \\quad \\quad \\quad （6）$$其中$k_u$是用户$u$的超度，$R_u$是用户$u$收集的资源的数量，$T_u$是用户$u$拥有的标签的数量。一个较大的$C_u$表示你有更相似的资源主题，这也可能表明你更专注于个性化或特殊的话题，而较小的$C_u$可能表明他/他有更多的兴趣。也可以用类似的定义来衡量资源和标签的聚类系数。\n   Zlati¢等人提出了一种名为超边密度的指标[86]。以用户节点$u$为例，它们将$u$的协调数(the coordination number)定义为 $z(u)= R_u + T_u$。对于一个给定的$k(u)$，配对数最大为 $Z_{max}(u)=2K(u)$ ，对于 $n(n-1)<k(u)<n^2$ 情况最小值是 $Z_{min}(u)=2n$ ，对于 $n^2<k(u)<n(n+1)$ 情况最小值是 $Z_{min}(u)=2n+1$ ，显然，一个局部树结构导致最大协调数，而最大重叠对应于最小协调数。 因此，他们将超边密度定义为[86]：$$D_h(u)=\\frac{Z_{max}(u)-Z(u)}{Z_{max}(u)-Z_{min}(u)} \\quad ,\\quad 0 \\le D_h(u) \\le 1 \\quad \\quad \\quad （7）$$ 资源和标签的超边密度定义是相同的。实证分析表明，这两个指标都表现出高聚类行为[82,86]。 协同标签网络超图的研究刚刚展开，如何正确量化聚类行为，节点之间的相关性和相似性以及社区结构仍然是一个开放的问题。\n   \n   4. 平均距离：定义为整个网络中两个随机节点之间的平均最短路径长度。\n\n \n\n####3.  推荐系统\n\n 推荐系统使用输入数据来预测其用户的潜在未来的喜好和兴趣。用户过去的评价通常是输入数据的重要组成部分。令$M$为用户数，令$N$为可评估和推荐的所有对象的数量。请注意，对象只是一个通用术语，可以表示书籍，电影或任何其他类型的消费内容。为了保持与标准术语的一致性，我们有时使用具有相同含义的词-“项目”。为了使符号更清楚，我们在枚举用户现在索引为拉丁字母 $i$ 和 $j$ ,以及枚举对象索引时限制为希腊字母 $\\alpha$ 和 $\\beta$。用户 $i$ 对对象 $\\alpha$ 的评价/打分表示为$r_{i\\alpha}$。这个评估通常是以整数评分量表（比如亚马逊的五星级制）-在这种情况下，我们会认为是一个显明的评级。请注意，二进制评级（如/不喜欢或好/坏）的常见情况也属于此类别。当只存在收集对象（如在书签共享系统中）或简单地消费（如在没有评级系统的在线报纸或杂志），或者当“喜欢”是唯一可能的表达（如在Facebook上）时，我们只有一元评级。在这种情况下，$r_{i\\alpha}=1$ 表示收集/消耗/喜欢的对象，$r_{i\\alpha}=0$  表示不存在的评估（参见图4）。推测用户对评级的置信区间是一个重要的工作，特别是对于二元或一元评级。用户的访问行为信息可能带来一些帮助，例如，可以通过观看电视节目的时间来估计用户的置信区间(喜好程度)，并且借助于该信息，可以提高推荐质量[95]。即使我们有明确的评级，这并不意味着我们知道用户如何并为什么做出这样的打分-他们是否具有数值上的评分标准，或者只是使用其来表现排序？最近的证据[96]在一定程度上是支持后者的。\n \n  ![](/images/fig4.png)图4. 由五个用户和四本书组成的推荐系统的图示。 每个推荐系统包含的用户和对象之间的基本信息都可以由二部图来表示。 该图还展示了在推荐算法的设计中经常被利用的一些附加信息，包括用户信息，对象的属性和对象内容。\n \n  推荐系统的目标是为用户提供个性化的\"推荐\"对象。 因此，可以对那些用户不知道的对象预测用户的评价或者是计算推荐分数。 被预测为高评价或高推荐分数的对象便构成了呈现给目标用户的推荐列表。 推荐系统有着广泛的性能指标体系（见第3.4节）。 推荐系统的惯用分类如下[15]：\n  \n  1. 基于内容的推荐：推荐的对象是内容类似于目标用户先前喜欢的对象内容的对象。 我们在4.2.3节叙述。\n  2. 协同推荐：根据大量用户过去的评估，选择推荐对象。 在表2中给出一个例子。它们可以分为：\n    * 基于记忆的协同过滤：推荐对象来自于与目标用户有相似偏好的用户喜欢的（user-base），或者是和目标用户之前喜欢的对象相似的对象（item-base）。我们将在第四章节（标准的基于相似的方法）和第七章节（引入社交网络的方法）来具体的阐述。\n    * 基于模型的协同过滤：推荐对象选自训练好的识别输入数据的模式的模型，我们将在第五章（降维方法）和第六章（基于信息传播理论的方法）具体来阐述。\n    \n  3. 混合方法：这类算法通过结合协同方法和基于内容的方法或者是混合多种不同的协同方法。我们将在8.4章节来具体的阐述\n\n####4.  推荐系统评估指标\n\n*其实可以参考看 2012 吕琳媛 [推荐系统评价指标综述](http://blog.sciencenet.cn/home.php?mod=attachment&id=20078)*\n\n 给定目标用户$i$，推荐系统将对所有$i$未收集的对象进行排序，并推荐排名最高的对象。 为了评估推荐算法，数据通常分为两部分：训练集$E^T$和测试组$E^P$。 训练集被视为已知信息，但是不允许使用来自测试组的信息来推荐。在本节中，我们简要回顾了用于衡量推荐质量的基本指标。如何选择特定指标（或指标）来评估推荐性能，这取决于系统应该实现的目标。当然，任何推荐系统的最终评估是由用户的判断决定的。\n \n1. 精度指标类\n \n ***评分精度指标:***  推荐系统的主要目的是预测用户未来的喜好和兴趣。 存在许多指标来评估推荐的各个方面性能。 两个著名的指标：均值绝对误差（MAE）和均方根误差（RMSE）用于测量预测评分与真实评分的接近程度。 如果$ r_{i\\alpha}$ 是用户$i$ 对对象 $α$ 的真实评分，则$\\widetilde r_{i\\alpha}$ 是预测的评分，$E^P$是隐藏的用户商品评分的集合，MAE和RMSE被定义为$$MAE = \\frac{1}{|E^p|} \\sum_{(i,\\alpha)\\in E^p} |r_{i\\alpha} - \\widetilde r_{i\\alpha}| \\quad \\quad \\quad (8) $$  $$RMSE = \\lgroup \\frac{1}{|E^p|} \\sum_{(i,\\alpha)\\in E^p} (r_{i\\alpha} - \\widetilde r_{i\\alpha})^2 \\rgroup ^{1/2} \\quad \\quad \\quad (9) $$ 较低的MAE和RMSE对意味着较高的预测精度。 由于RMSE在求和之前对误差进行平方，所以往往会更大程度地惩罚大错误。 由于这些指标平等对待所有评分，无论他们在推荐列表中的位置如何，所以它们对于某些常见任务，如找到可能被用户偏好的的少量对象（Finding Good Objects）来说并不是最佳的。 然而，由于其简单性，RMSE和MAE被广泛用于推荐系统的评估。\n\n ***评级和排名相关性:*** 评估预测精度的另一种方法是计算预测值和真实值之间的相关性。 有三个着名的相关性测度，即皮尔逊相关系数(the Pearson product-moment correlation)[97]，斯伯曼/斯皮尔曼相关系数 (the Spearman correlation)[98] 和 肯德尔相关系数(Kendall’s Tau )[99]。 Pearson相关性测量两组评分之间线性相关性的程度。它被定义为\n \n $$PCC = \\frac{\\sum_{a}(\\widetilde r_{\\alpha} - \\bar{\\widetilde r} )(r_\\alpha - \\bar r)}{\\sqrt{\\sum_\\alpha(\\widetilde r_{\\alpha}- \\bar{\\widetilde r} )^2}  {\\sqrt{\\sum_\\alpha(r_\\alpha - \\bar r)^2}}}$$\n \n\n \n 其中$r_\\alpha$ 和 $\\widetilde r_\\alpha$ 分布死真实的和预测的评分。Spearman相关系数 $\\rho$ 以与Pearson相同的方式定义，除了$r_\\alpha$ 和$\\widetilde r_\\alpha$ 被各个对象的排序代替。与Spearman相似，Kendall也评估了评分排名一致性程度。它被定义为 $\\tau = (C-D)/(C+D)$其中C是系统以正确的排序顺序预测的对象的数量，D是系统以错误的顺序预测的不一致的数量。当真实和预测的排名相同时，$\\tau = 1$，当它们完全相反时，$\\tau = -1$。 当真实排名或预测排名有并列情况出现时，在[13]中提出了Kendall的的变体， $$\\tau = \\frac {(C-D)}{\\sqrt{(C+D+S_T)(C+D+S_P)}}$$其中$S_T$是真实评分中相同的对象的数量，$S_P$是预测评分相同的对象的数量。Kendall 指标对连续有序对象的任何位置交换给予相等的权重，无论它在哪里发生。 但是，不同地点的交换，例如在1号到2号之间，100到101号之间的交换可能会有不同的影响。 因此，可以对真实排名的顶部给予对象更大的权重来改进指标。与Kendall类似，最初由Yao[100]提出来的归一化基于距离的性能指标（NDPM）用来比较两种不同的弱排序，它是基于统计矛盾对$C^-$(2个排序不一致)和兼容对$C^u$(一个排序是平局，另外一个排序是在所有对象中明显偏向其中一个),值得注意的是，这些预测评分关联性指标都是只关注于预测排序值而不关注具体的预测评分值，所以它们都不适用于那些旨在为用户提供精确预测评分值的系统。假如用$C$表示用户实际评分中具有严格偏好差别的商品对个数，则NDMP指标定义为：$$NDPM=\\frac{2C^-+C^u}{2C}$$\n\n ***分类准确度:*** 分类指标适用于诸如“寻找好对象”这样的任务，特别是当仅有隐含评分可用时（即，我们知道哪些对象受到用户的青睐，而不是他们具体喜欢多少）。当给出排序的对象列表时，推荐的阈值是不明确的或可变的。为了评估这种系统，一个受欢迎的指标是AUC（Area ROC Curve），其中ROC代表接收者操作特征曲线[101]（关于如何绘制ROC曲线见[13]）。 AUC尝试测量推荐系统如何能够成功地将相关对象（用户所赞赏的）与无关对象（所有其他对象）区分开来。计算AUC的最简单方法是将相关对象推荐的概率与不相关对象的概率进行比较。对于n个独立比较（每个比较指的是选择一个相关的和一个不相关的对象），如果有$n^\\prime$次相关对象分数高于不相关对象，$n^{\\prime\\prime}$次不相关对象和相关对象分数一致，根据[102]$$AUC=\\frac{n^\\prime+0.5n^{\\prime\\prime}}{n} \\quad \\quad \\quad (13) $$如果所有的相关对象比不相关对象的分数高那么 $AUC=1$，意味着一个完美的推荐系统。对于一个随机排序的推荐列表 $AUC=0.5$,因此，AUC超过0.5的程度表示推荐算法识别相关对象的能力。类似于AUC是[103]中提出的所谓的排名分数。 对于给定的用户，我们测量该用户推荐列表中相关对象的相对排名：当有$o$个对象被推荐时，具有排名r的相关对象具有相对排名$r/o$。 通过对所有用户及其相关对象进行平均，我们获得平均排名得分RS-排名得分越小，算法的准确性越高，反之亦然。\n \n 由于真正的用户通常仅关注推荐列表的顶部，所以更实际的方法是考虑漂亮在top-L位置前用户相关的对象的数量。基于此，精准率和召回率是最受欢迎的指标。 对于目标用户$i$，推荐的精确度和召回率$P_i(L) $ 和 $R_i(L)$被定义为$$P_i(L)=\\frac{d_i(L)}{L} \\quad , \\quad  R_i(L)=\\frac{d_i(L)}{D_i}  \\quad \\quad \\quad (14)$$其中$d_i(L)$指在长度为L的推荐列表中相关的项目数量，$D_i$是所有的相关项目总数，对所有拥有至少一个相关对象的所有用户的精度和回召率做平均，我们可以得到平均精度和平均回召率$P(L),R(L)$，这些指标可以通过对随机产生的推荐结果进行对比，于是就有了增强版本的精度和回召率指标$$e_P(L)=P(L)\\frac{MN}{D} \\quad , \\quad e_R(L)=R(L)\\frac{N}{L} \\quad \\quad \\quad (15)$$其中$M$和$N$分别是用户和商品的数量，$D$是所有相关商品的数量,通常精度回随着推荐列表长度L增加而下降，召回率随着L的增加而增长，我们可以把他们组合成一个和L弱相关的指标$F_1$-score。$$F_1(L)=\\frac{2PR}{P+R}\\quad \\quad \\quad (16)$$许多其他组合精度和召回率的指标被用在信息检索的有效性，但是很少用在推荐系统中:平均精度，深度精度，R精度，互惠等级[106]，二进制偏好度量[107]。 每个组合指数的详细介绍和讨论可以在[108]中找到。\n \n2. 基于排序加权的指标\n \n 现实生活中用户的耐心往往是有限的，一个人不太可能会不厌其烦地检查推荐列表中的所有商品，所以用户体验的满意度往往会受到用户喜欢的商品在推荐列表中位置的影响，这里介绍3个具有代表性的评价指标，更详细的信息参见文献[13]。\n \n ***半衰期效用指标(half-life utility)[109]*** 是在用户浏览商品的概率与该商品在推荐列表中的具体排序值呈指数递减的假设下提出的，它度量的是推荐系统对一个用户的实用性也即是用户真实评分和系统默认评分值的差别。用户$i$的期望效用定义为：$$HL_i=\\sum^n_\\alpha\\frac{max(r_{i\\alpha}-d,0)}{2^{(o_{i\\alpha}-1)/(h-1)}} \\quad \\quad \\quad (17)$$  推荐结果按照数$\\widetilde r_{i\\alpha}$降序排列，$r_{i\\alpha}$表示用户$i$对商品$\\alpha$的实际评分，而$o_{i\\alpha}$为商品$\\alpha$在用户$i$的推荐列表中的排名；$d$为默认评分(如说平均评分值)；$h$为系统的半衰期，也即是有50%的概率用户会浏览的推荐列表的位置。显然，当用户喜欢的商品都被放在推荐列表的前面时，该用户的半衰期效用指标达到最大值。通过计算有用户$HL_i$值的平均值，我们就得到了系统的整体效果。\n \n ***折扣累计利润(discounted cumulative gain，DCG)[110]*** 对于长度为L的推荐列表，DGG定义为$$DGG(b) = \\sum^b_n r_n+\\sum^L_{n=b+1}\\frac{r_n}{log_bn} \\quad \\quad \\quad (18)$$，其中$r_n$指排序中第n个项目的用户是否喜欢，$r_n=1$代表喜欢，$r_n=0$代表不喜欢，b是自由参数多设为2；DGG的主要思想是用户喜欢的商品被排在推荐列表前面比排在后面会更大程度上增加用户体验。\n \n ***排序偏差准确率（Rank-biased precision）[108]*** 这个指标假设用户往往先浏览排在推荐列表的首位商品然后依次以概率$p$浏览下一个，以$1-p$的概率不再看此推荐列表。对于一个长队为L的推荐来说，RBP定义为$$RBP=(1-p)\\sum^L_{n=1}r_nP^{n-1} \\quad \\quad \\quad (19)$$其中$r_n$和DCG相同,RBP和DCG类似，唯一的不同在于RBP把推荐列表中商品的浏览概率按等比数列递减，而DCG则是按照log调和级数形式。\n \n3. 多样性和新奇\n \n 即便给用户成功推荐一个用户喜欢的项目，但是当项目是众人皆知（流行的）对用户来说的价值也是微乎其微。为了补充上面精度指标，几种多样性和新颖性指标 [35,39,111]在最近被提出，我在这里做一个介绍。\n \n ***多样性*** 推荐系统的多样性是指被推荐项目之间的差异程度，在推荐系统中，多样性体现在以下两个层次，用户间的多样性(inter-user diversity)，衡量推荐系统对不同用户推荐不同商品的能力；另一个是用户内的多样性(intra-user diversity)，衡量推荐系统对一个用户推荐商品的多样性。用户间的多样性通过考虑用户推荐列表的种类来定义。对于用户i，j，可以用汉明距离来评估推荐列表的前L个项目差异性。$$H_{ij}=1 - \\frac{Q_{ij}(L)}{L} \\quad \\quad \\quad (20)$$其中$Q_{ij}(L)$是用户$i,j$之间前$L$个推荐商品中相同商品的数量，如果2个列表完全一致$Q_{ij}(L)=0$，如果没有任何重叠则为$Q_{ij}(L)=1$。所有用户对的$H_{ij}$值的平均值就是系统的$H(L)$值，该值越大，则推荐系统给用户推荐的多样性越好\n \n 将用户$i$的推荐商品表示为$\\{o_1，o_2，...，o_L\\}$，可以使用这些商品的相似度$（o_\\alpha，o_\\beta）$来测量用户内多样性（这种相似性可以直接从评分或对象元数据获取）[113]。 用户$i$推荐商品的平均相似度，$$I_i(L)=\\frac{1}{L(L-1)} \\sum_{\\alpha \\neq \\beta } s(o_\\alpha，o_\\beta) \\quad \\quad \\quad (21)$$，同样，我们可以通过平均所有用户值来获得系统的用户内的多样性值$I(L)$，该值越小说明用户内的多样性越好。值得注意的是，通过避免推荐过度相似的对象，用户内推荐列表多样性可用于增强和改进推荐列表[37]。 可以通过在推荐列表[111]中引入对象排名的折扣函数来获得等级敏感版本。通过引入关于商品排序的折扣函数就可以获得排序敏感的版本(The rank-sensitive version can be obtained by introducing a discount function of the object’s rank in recommendation list [111].)[111]。\n \n ***新颖性和惊喜性*** 推荐系统中的新颖性是指推荐对象与用户以前看过的不同之处。 量化算法产生新颖和意想不到的结果的能力的最简单的方法是测量推荐对象的平均受欢迎程度$$N(L)=\\frac{1}{ML}\\sum^m_{i =1}\\sum_{\\alpha \\in O^i_R}K_\\alpha  \\quad \\quad \\quad (22)$$其中$O^i_R$是用户$i$的推荐列表,$K_\\alpha$是商品$\\alpha$的度(商品的流行性)，低流行性意味着推荐结果的高新颖性。另外一个可以用来评估推荐结果的惊喜性的指标通过计算自信息(self-information)[114]。对于一个商品$\\alpha$，一个随机选取的用户选到他的概率为$k_\\alpha / M $,所以自信息定义为 $$U_\\alpha = \\log_2(M/K_\\alpha)  \\quad \\quad \\quad (23)$$可以通过将观察限制到目标用户，即计算目标用户的top-L商品的平均自我信息来定义基于用户相关的新颖性指标变体。对所有用户进行平均，我们获得了平均top-L惊喜值$U(L)$。通过类似的结果公式，在[111]中提出了一种基于发现的新颖性，通过考虑对象是随机用户已知或熟悉的概率。\n \n4. 覆盖率\n \n 覆盖率指标是指算法向用户推荐的商品能够覆盖全部商品的比例。将所有推荐列表的前L个位置中的不同对象的总数表示为$N_d$，则$L$相关的覆盖率指标定义为$$COV(L)=N_d/N$$低覆盖率表示该算法可以访问并仅推荐少量不同对象（通常是最受欢迎的），这往往导致很少的不同商品。相反，覆盖率较高的算法更有可能提供不同的推荐[115]。从这个观点来看，覆盖率也可以被认为是一种多样性度量。此外，覆盖率有助于更好地评估精度指标的结果[116]：推荐流行的对象可能具有高精度但低覆盖率。一个好的推荐算法应该将同时具有高精度和覆盖率。\n \n 评估推荐系统的特定指标的选取取决于系统需要实现的目标。在实践中，可以为新的和有经验的用户分别指定不同的目标，这进一步使评估过程复杂化。为了更好的概述，表3总结了推荐系统评估指标。\n\nTable3. 推荐系统指标摘要。第三列表示度量的偏好（例如，更小的MAE意味着更高的评级精度）。第四列描述度量的范围。最后两列显示该度量是否从排名获得，以及是否取决于推荐列表L的长度。\n\n|名字|符号|偏好|范围|是否与排名相关|是否依赖长度L|\n----|----|----|----|----|----|\nMAE                        | $MAE$        | Small |Rating accuracy              |No  |No  |\nRMSE                       | $RMSE$       | Small |Rating accuracy              |No  |Yes |\nPearson                    | $PCC$        | Large |Rating correlation           |No  |No  |\nSpearman                   | $\\rho$       | Large |Rating correlation           |No  |Yes |\nKendall’s Tau              | $\\tau$       | Large |Rating correlation           |No  |Yes |\nNDPM                       | $NDPM$       | Small |Ranking correlation          |No  |Yes |\nPrecision                  | $P(L)$       | Large |Classification accuracy      |Yes |Yes |\nRecall                     | $R(L)$       | Large |Classification accuracy      |No  |Yes |\nF1-score                   | $F1(L)$      | Large |Classification               |Yes |Yes |\nAUC                        | $AUC$        | Large |accuracy Classification      |No  |No  |\nRanking score              | $RS$         | Small |accuracy Ranking             |Yes |Yes |\nHalf-life utility          | $HL(L)$      | Large |accuracy Satisfaction        |No  |No  |\nDiscounted Cumulative Gain | $DCG(b, L)$  | Large |Satisfaction and precision   |No  |Yes |\nRank-biased Precision      | $RBP(p,L)$   | Large |Satisfaction and precision   |Yes |No  |\nHamming distance           | $H(L)$       | Large |Inter-diversity              |No  |Yes |\nIntra-similarity           | $I(L)$       | Small |Intra-diversity              |Yes |No  |\nPopularity                 | $N(L)$       | Small |Surprisal and novelty        |No  |Yes |\nSelf-information           | $U(L)$       | Large |Unexpectedness               |Yes |No  |\nCoverag                    | $COV(L)$     | Large |Coverage and diversity       |No  |Yes |\n\n\n![](/images/Summary-recommendation-metrics.png)\n\n\n###基于相似的方法\n###降维技术\n###基于传播的方法\n###社交过滤\n###元方法\n###性能评估\n###展望\n","source":"_posts/推荐系统.md","raw":"---\ntitle: 推荐系统简介\ntags: 推荐系统\ndate: 2017-09-28 19:12:32\n---\n\n\n\n###摘要\n\n互联网的持续爆发式扩张极大的增加了采用推荐系统过滤大量的信息的必要性，推荐系统被社会学，计算学物理学家和交叉学科等大量学界进行了广泛的研究 ，尽管取得了实质性的理论和实践成果，缺乏统一方法对不同的推荐算法比较，阻碍了其进一步的进步。在本文中，我们回顾了推荐系统的最新进展，并讨论了主要挑战。我们对比并评估了已有的算法，并推测他们在未来的发展中扮演的角色。除了算法之外，我们还从物理的角度来描述推荐系统的宏观行为。我们讨论了推荐系统潜在的影响和未来的发展。我们在此强调：推荐系统有很强的科学深度并结合了不同的研究领域，吸引着物理学家以及交叉学科研究人员的兴趣。\n\n###序言\n\n由于计算机和计算机网络，我们的社会各方面都经历着翻天覆地的变化，我们在线购物，通过搜索引擎搜集信息，在互联网上进行很大部分的社会活动。事实上，我们大量的行为和交互都以电子的方式存储，这给了研究人员机会在更加细尺度来研究社会经济和技术社会系统，传统的“软学科”，比如社会学和经济学，通过对这些已有的新数据的研究已经发展了许许多多的研究分支，在数据驱动研究方面有着长期经验的物理学家，也已经加入了这一趋势，为诸如金融[3,4]，网络理论[5-9]和社会动力学[10]等多个非传统领域做出了贡献。随着过去十几年间物理学家的兴趣的持续增长，推荐系统和信息检索的研究也不例外。推荐系统的任务是利用用户及其偏好的数据预测用户未来可能的喜好和兴趣。推荐系统的研究处于科学和社会经济生活的十字路口，其巨大的潜力首先被信息革命前沿的网络企业家所注意。虽然原本是由计算机科学家主导的领域，但推荐系统需要各领域的贡献，现在它也是数学家，物理学家和心理学家感兴趣的话题。例如，最近在商业公司Netflix [11]组织的的推荐比赛中，基于人类行为的心理学方法获得高分并不是巧合。\n\n当为目标用户做推荐时，最基本的方法是选择与目标用户相似的用户所青睐的对象。即使这种简单的方法也可以通过多种方式实现，这是因为推荐领域缺乏一般性的“第一原则”-从中可以推断出正确的推荐方式。例如，如何最好地衡量用户相似性并评估其不确定性？如何综合各种用户的意见分歧？如何处理少量信息的用户？所有数据是否权重平等，或者是否可以检测到鲁莽或故意误导的意见？当使用比基于用户相似性的方法更复杂的方法时，也出现和这些类似的问题。幸运的是，存在一些可用于测量和比较各种方法的实际数据集。因此，与物理学类似，实验决定哪种推荐方法是好的，哪种不是。\n\n认为推荐系统只有在适当的数据集可用的情况下才会被研究是非常有误导性的。虽然数据的可用性对推荐方法的实证评估很重要，但主要驱动力来自实践：电子系统给我们太多的选择让我们自己来处理。工业界对推荐的兴趣并不奇怪，一本关于推荐系统领域的早期书《Net Worth by John Hagel III and Marc Singer [12]》明确指出“（info-mediaries）”的巨大经济影响，它可以大大提高个人消费者的信息能力。现在，大多数电子商务网站提供各种形式的推荐--从简单的显示最受欢迎的项目或通过复杂的数据挖掘技术推荐的相同生产者的其他产品。人们很快意识到没有独特的最佳推荐方法， 相反，根据可用数据的上下文和密度，对不同的应用场景采用不同的推荐算法是最有可能成功的。因此，没有灵丹妙药，最好的办法是了解基本的前提（推荐场景）和推荐机制，这样就可以解决来自生活中的各种真实应用问题。 这一点也反映在这篇综述中，我们不试图强调任何推荐算法。 相反，我们回顾基本的思想，方法和工具with particular emphasis on physics-rooted approaches.\n\n撰写此综述的原因是多方面的，首先，虽然计算机科学家对推荐系统的广泛评论已经存在[13-15]，但是物理学家与计算机科学家的观点不同，它们更多的使用复杂网络方法和采用各种经典物理过程（如扩散）来做信息检索。因此，我们相信，该综述（We thus believe that this review with its structure and emphasis on respective topics can provide a novel point of view.）可以提供一个新颖的观点。 其次，过去十年已经看到物理学家对推荐系统的兴趣越来越大，我们希望通过用物理学界更熟悉的语言来描述最先进的技术的这篇综述可以成为他们的有用来源。 最后，这里介绍的跨学科方法可能为信息检索领域的开放性问题和挑战提供新的见解和解决方案。\n\n本篇综述结构如下：为了激发研究问题的积极性，我们首先在第2章讨论了推荐系统的实际应用。接着在第3节中，我们介绍了基本概念，例如复杂网络，推荐系统和评估指标，这些概念构成了后续阐述的基础。 然后，我们开始讨论推荐算法，首先是传统方法（第4节中基于相似性的方法和第5节中的维数降低技术），然后是起源于随机游走过程被物理学所熟知的基于网络的方法（在第6节）。还包括基于外部信息的方法，如社交关系（第7节），关键字或时间戳（第8节）。 我们最后在第9节中对推荐算法的性能进行简要评估，并在第10节讨论了该领域的前景。\n\n###推荐系统应用真实场景\n\n####Netflix prize\n\n####主要挑战\n\n推荐系统领域的研究人员面临着许多挑战，这些挑战对其使用和执行算法构成风险。这里我们只提到主要的：\n\n1. 数据稀疏\n 由于可用数据量非常大（比如，大型的在线书店经常有几百万的书），导致用户之间的交集十分小甚至没有。此外，即便每个用户/商品平均评估次数很高，但是由于每个商品/用户的评估次数分布非常不均匀（通常是power-law或者weibull分布），大部分的商品只有极少的评分，所以一个有效的推荐系统必须考虑到数据的稀疏性问题。\n\n1. 可扩展性\n 尽管数据经常是稀疏的，但是对于那些大型的网站拥有百万的用户和商品。因此必须考虑计算成本的问题，寻找计算要求不高的或者易于并行化的推荐算法。另一种可能的解决方案是基于使用增量数据的算法（增量学习算法），随着数据的增长，算法不会在全局重新计算，而是逐步增量计算[29,30]，这种增量方法类似于在物理和数学广泛应用的扰动技术[31]。\n \n1. 冷启动\n 当新的用户进入一个系统，系统中没有任何有用的信息来产生推荐结果给用户，通常的解决办法是通过结合基于内容的和协同过滤的混合推荐技术（参考 8.4 节），有时还需要获取用户的一些基本信息（如年龄，位置和偏好等）来配合。另外的一个方法是识别不同web服务中的同一个用户。比如说百分点开发了一个可以跟踪同一个用户在不通电商网站行为的技术，那么一个在A网站作为冷启动的用户可以通过他在B，C，D 网站的行为来进行相关的推荐。\n \n\n1. 多样性与精确性的两难困境\n 当推荐任务是为特定用户赞赏的项目时，通常最有效的方法是推荐流行的和高评分的项目，但是这样的推荐对用户来说没有什么价值，因为即便在没有推荐系统的情况下，流向的项目也很容易被找到（甚至难以避免），因此一个好的推荐项目列表也应该包括那些用户自己本身无法找到的隐藏项目[35]。对于这个问题的解决办法有：直接增加推荐列表的多样性[36-38]和使用混合的推荐算法[39]\n  \n1. 攻击的脆弱性\n 受推荐系统在电子商务领域重大的经济利益的驱动，一些心怀不轨的用户通过提供一些虚假恶意的信息，故意增加或者压制某些商品被推荐的可能性[44]。从阻止恶意评估进入系统到复杂的抵抗推荐技术[41]，有大量的工具可以防止这样的行为。然而，这并不是一件容易的事情，因为随着防作弊的工具的升级，攻击者的策略也越来越先进。例如，Burke等人[42]引入了八个攻击策略，进一步可以分为四个类：基本攻击（包括随机和平均攻击），低认知攻击，核攻击和知情攻击。（basic attack, low-acknowledge attack, nuke attack and informed attack.需要看引文来翻译）\n \n1. 时间的价值（好像是讲兴趣漂移问题）\n 一个真实用户的兴趣是和时间尺度相关的（举例来说，短期感兴趣与旅行计划相关，长期兴趣和居住地或者政治相关），大多数的推荐算法评估的时候都忽略了时间的影响。旧的想法是否会随着时间衰减，怎么衰减，以及用户评估和项目相关性中的典型临时模式是什么，这些都还需要持续的研究\n \n1. 推荐的评估\n 虽然我们有很多不同的指标（见第3.4节），但是如何根据给定的情况和任务选择最好的指标仍然是一个悬而未决的问题。不同推荐算法的比较也存在问题的，因为不同的算法可以简单地解决不同的任务，最后，推荐系统的整体用户体验（包括用户对推荐结果的满意程度和用户对系统的信任）难以在“离线”评估中进行测量。因此，在推荐系统中，实证用户的研究仍然是一个受欢迎的反馈来源。\n\n1. 用户界面\n 实践表明，为了促进用户接受推荐结果，推荐过程需要透明化：用户明白为什么特定的项目被推荐给他们。除此之外，通常潜在的感兴趣项目列表会很长，因此它需要简单的方式来展现，并且可以轻松的通过他去浏览由不同方法给出的推荐结果。\n \n 除了以上的长期挑战，推荐系统近期出现了许多新颖的问题，由于相关科学的方法论的发展，特别是网络分析的新工具，科学家开始考虑网络结构对推荐的影响，以及如何利用已知的结构特征来改进推荐。例如，Huang等人[47]分析了消费者-商品网络，并提出了一种改进的推荐算法，这种算法偏向增强局部聚类属性的边。Sahebi等[48]设计了一种利用社区结构的改进算法。新技术的进步和传播也带来新的挑战。例如，配备GPS的手机已经成为主流，互联网的被普遍的接入，因此基于位置的推荐现在是可行的并且越来越显有意义，精准的推荐要求人类的运动的高可预测性和定量方式来定义地点和人之间的相似之处。最后，智能推荐系统应考虑不同人群的不同行为模式。例如，新用户倾向于访问非常受欢迎的项目并选择类似的项目，而老用户通常具有更具体的兴趣[53,54]，并且用户在低风险（例如收集书签，下载音乐等）和高风险（例如购买电脑，租房等）活动之间的行为差​​异很大。\n\n\n\n其实可以直接看周涛老师的一篇中文论文 [《个性化推荐的十大挑战》](http://blog.sciencenet.cn/blog-3075-588779.html)，里面讲的更加具体，虽然推荐系统经过了这么多年的发展，但是对现在的推荐系统依旧面临着文中的问题。\n\n\n###主题和问题的定义\n\n 我们在本章中简要回顾一下在推荐系统研究中有用的基本概念。\n \n####1.  图\n\n 网络分析是揭示许多复杂系统组织原理的通用工具[5-9]。网络是一组元素（称为节点或顶点），它们之间具有连接（称为边或链接）。许多社会，生物，技术和信息系统可以被描述为具有代表个人或组织的节点和捕获其交互的边缘的网络。 网络研究，即数学文献中的图论，具有悠久的历史，从18世纪欧拉所解决的古典柯尼斯堡桥梁问题开始[57]。用数学的定义，网络$G$是一个有序的不相交的二元组集合$(V,E)$其中$V$是节点的集合$E$是边的集合。在一个无向网络中，一条连接节点$x$和$y$的边表示为$x \\leftrightarrow  y$,$x \\leftrightarrow  y$和$y \\leftrightarrow  x$代表的是同一条边,在一个有向网络中，边是一个关于节点的有序二元组，$x\\rightarrow y$ 代表由$x$指向$y$的一条边，边$x\\rightarrow y$ 和$y\\rightarrow x$是不同的，并且可以同时存在的。除非另有说明，否则我们假设网络不包含自环（连接节点到其自身的“边”）或连接同一对节点的多边（多个“边”）。在多网络（multinetwork）中，允许两个循环和多边。\n  \n 在无向网络$G(V，E)$中，如果$x\\leftrightarrow  y \\in E$，则两个节点$x$和$y$被认为是彼此相邻的。节点$x$的邻域节点集合，或者说$x$邻居集合由$\\Gamma_{x}$来表示,节点$x$的度定义为$k_{x}=|\\Gamma_{x}|$.度分布$P(k)$定义为随机选择的节点的度为$k$的概率.在一个均匀的网站，每一个节点有着相同的度$k_{0}$，所$P_{k}=\\delta_{k,k_{0}}$,在经典的Erdös–Rényi随机网络中，其中每对节点以给定的概率$p$连接生产边，其度分布满足二项式分布。$$P(k)={N-1 \\choose k}p^{k}(1-p)^{n-1-k} \\quad \\quad \\quad (1)$$其中$N=|V|$是网络中节点的数量。这样的分布有一个以平均度$\\bar x = p(N-1)$表示的特征量表.在上个世纪末，研究人员转而对大规模实际网络进行调查，结果发现他们的度分布通常跨越几个数量级，大致遵循幂律形式$$P(k)\\sim k^{-\\gamma} \\quad \\quad \\quad (2) $$其中$\\gamma$为正指数，通常位于2和3之间[5]，这种网络被称为无标度网络，因为他们缺乏度的特征尺度，幂律函数$P(k)$是与规模无关的。注意，实践数据中的幂律分布的检测需要固定的统计工具[62,63]。 对于有向网络，由$k^{out}$表示的节点$x$的出度，是从x开始的边的数量，入度$k^{in}$是以x结束的边的数量。 有向网络的进度和出度分布通常彼此不同。\n\n 一般来说，如果一个网络的高度节点倾向于与高度节点连接，而低度节点倾向于与低度节点连接，那么它被认为是同配assortative的（如果情况相反，那就是异配的)。 该度-度相关性可以由最近邻节点门的平均度[64,65]或皮尔逊系数的变体称为分类系数[66,67]来表征。 分类系数$r$在$-1≤r≤1$的范围内。如果$r> 0$，网络是同配的; 如果$r <0$，则网络是异配的。 请注意，该系数对度非均匀性（heterogeneous degree ）敏感。 例如，无论网络的连接模式如何，r在具有非常非均匀性度分布的网络（例如，因特网）中将为负值[68]。\n\n 连接两个节点的路径中的边数被称为路径的长度，两个节点之间的距离被定义为连接它们的最短路径的长度。 网络的直径是所有节点对之间的最大距离，平均距离是所有节点对上的平均距离平均值$$\\bar d = \\frac{1}{N(N-1)}\\sum_{x \\neq y}d_{x,y} \\quad \\quad \\quad (3) $$其中$d_{x,y}$是$x$和$y$之间的距离.许多真实网络显示出所谓的小世界现象：它们的平均距离不会比网络大小的对数增长得快[70,71]。\n \n 三元聚类在社会互动系统中的重要性的认知已经超过100多年[72]。 在社交网络分析中[73]，这种聚类称为传递性，定义为网络中三角形总数与相连节点的三元组总数之比的三倍。 1998年，Watts和Strogatz [71]提出了一个类似的指数来量化三元聚类，称为聚类系数。 对于给定的节点$x$，该系数被定义为$x$的邻居之间边的数量与邻居对的数量的比率，$$c_x=\\frac{e_x}{\\frac{1}{2}k_x(k_x)-1} \\quad \\quad \\quad (4) $$其中$e_x$表示节点$x$的$k_x$个邻居之间的边数量（该定义仅在$k_x> 1$时有意义）。 网络聚类系数被定义为$k_x> 1$的所有$x$的$c_x$的平均值。也可以将聚类系数定义为网络中三角形数$\\times 3$与连接的三元组顶点数之比，有时也被称为“传递三元组的分数(‘fraction of transitive triples’)”[7]。 请注意，这两个定义可以给出完全不同的结果。\n \n 图1说明了简单无向网络的上述定义。 有关网络测量的更多信息，我们鼓励读者去参考关于网络特征的文章[74]。\n \n ![](/images/fig1.png)\n 图1. 一个拥有6个节点7条边的简单无向网络，节点的度分别为$k_1=1,k_2=k_5=3,k_3=k_4=k_6=2$,对应的节点的度分布$p(1)=\\frac{1}{6},p(2)=\\frac{1}{2},p(3)=\\frac{1}{3}$,网络的直径和平均平均距离为$d_{max}=3,d=1.6$,聚类系数为$c_2=\\frac{1}{6},c_3=c_4=0,c_5=\\frac{1}{3},c_6=1$,平均聚类系数为$C=0.3$\n \n \n####2.  二部图和超图\n\n 如果一个网络$G(V,E)$满足分割为$(V_1,V_2)$后，$V_1\\cup V_2=V$并且$V_1\\cap V_2=\\emptyset$，每一条边由一个$V_1$和一个$V_2$中的节点连接而成,那么这就是一个二部图。许多真实系统自然地被模拟为二部图，比如，由化学物质和化学反应组成的代谢网络[75]，由行为和行为者组成的协作网络[76]，由个人电脑和电话号码[77]的互联网电话网络等等。我们专注于一类特殊的二分网络，称为基于网络的用户商品网络[53]，它们代表在线服务网站中的用户和商品之间的相互影响，例如在Delicious.com中的书签集合以及在amazon.com上购买的书籍。我们将在后面看到，这些网络描述了推荐系统的基本结构。 基于Web的用户商品网络是逐渐演进的，其中节点和链接逐渐被添加。 相比之下，这不可能发生在例如作者合作网络（例如，在发布之后无法将作者添加到科学论文）。\n \n 大多数的基于web的用户商品网络有着共同的结构属性，他们的（object-degree）商品度分布遵循幂律式形式$P(k)\\sim k^{-\\gamma} $,对于互联网电影数据库（IMDb）来说 $\\gamma \\approx 1.6$[78],音乐共享站点audioscrobbler.com的 $\\gamma \\approx 1.8$ [79]，对于电子商务网站amazon.com [53] $\\gamma \\approx 2.3$；对于书签共享网站delicious.com来说 $\\gamma \\approx 2.5$。用户度分布的形式通常在指数和幂律之间[53]，并且可以很好地拟合Weibull分布分布[27]（文献中也称为拉伸指数分布[80]）$$P(k)=k^{\\mu-1}exp[-(k/k_0)^\\mu] \\quad \\quad \\quad (5) $$其中$k_0$是常数，$\\mu$是拉伸指数。 用户和商品之间的连接（边）表现出一种异配（disassortative）混合模式[53,78]。\n 二部图定义的简单扩展是所谓的多部图。对于一个r-partite的图，他存在r个节点集合$V_1,V_2...V_r$，并$V=V_1 \\cup V_2 \\cup...\\cup V_r,V_i\\cap V_j=\\emptyset ,其中i\\neq j$，并且对于所有的节点集合$V_i$，不存在同一集合的节点之间的边。多部网络已经在协作标签系统（文献也称众分类法Folksonomies）[81-84]中找到了应用，用户可以在其中为在线资源分配标签，例如flickr.com中的照片，CiteULike.com中的参考文献和delicious.com中的书签等在线资源分配标签。\n \n 请注意，三部网络表示形式中丢失了一些信息。例如，给定一条连接资源和标签的边，我们不知道哪个用户（或用户们）对此边有贡献。对于这个问题，超图[85]可以用来给出协作标签系统的完整结构的精确表示。在超图$H(V,E)$中，超集$E$是$V$的幂集的子集，即V的所有子集的集合。 因此，边$e$可以连接多个节点。 类似于普通网络，超图中的节点度被定义为与节点相邻的超节点的数量，并且两个节点之间的距离被定义为连接这些节点的最小数量的超边。 聚类系数[82,86]和社区结构[86,87]也可以按照普通网络中的定义进行定义和量化。 请注意，超图和二分网络之间存在一对一的对应关系。给定超图$H（V，E）$，相应的二分网络$G（V^\\prime，E^\\prime）$包含两个节点集，如$V^\\prime= V\\cup E$，而$x \\in V$与$Y \\in E$连接，当且仅当$x \\in Y$（参见图2作为说明）。\n \n ![](/images/fig2.png)图2. 超图（a）和二分网络（b）之间的一一对应的图示。 有三个超边，X = {1,2,4}，Y = {4,5,6}和Z = {2,3,5,6}。\n \n \n 超图已经在铁磁动力学[88,89]，人口分层[90]，蜂窝网络[91]，学术团队形成[92]等许多领域中得到应用。 在这里，我们更关心协作标签系统的超图表示[86,93,94]，其中每个超边连接三个节点（由图3中的三角形表示），用户 $u$ ，资源 $r$ 和标签 $t$ ， 表示用户 $u$ 把标签 $t$ 给了资源 $r$ 。 资源可以由许多用户收集，并且由用户给出几个标签，标签可以与许多资源相关联，这就导致了小世界超图[86,94]（图3显示了基本单元和广泛的描述）此外，协同标签系统的超图已被证明是高度集群化的，它具有长尾度分布和社区结构[86,94]。[94]可以找到超图的演变模型。\n \n ![](/images/fig3.png)图3. 协同标签网络的超图。 （左）一个类似三角形的超边[93]，其中包含三种类型的顶点，一个蓝色圆圈，一个绿色矩形和一个棕色三角形，分别表示用户，资源和标签。 （右）描述由两个用户组成，四个资源和三个标签的超图。 以用户$U_2$和资源$R_1$为例，测量值表示为：（i）$U_2$已经参与在六个超边，这意味着它的超度是6; （ii）$U_2$直接连接到三个资源和三个标签。 按照公式 （6），认为它最大可能有$3 * 3 = 9$ 超边。 因此，其聚类系数等于$6/9=0.667$，其中6是其超度; 相对而言，如定义按式（7），其聚类系数为$D_h(U2)= \\frac {12-6} {6-4} = 0.75$; （iii）从$U_2$到$R_1$的最短路径为$U_2-T_1-R_1$，表示$U2$与$R_1$之间的距离为2\n\n \n  一般来说，以复杂科学角度的评估超图可以从以下几点展开（图3给出这些的详细描述）：\n  \n   1. 超度：超图中的节点的度可以自然地定义为与其相邻的超边的数量。\n   2. 超度分布：定义为每个超度占据的比例，其中超度定义为常规节点参与的超边的数量。\n   3. 聚类系数：定义为节点的实际超边数量与可能的超边数量的比例[82]。 例如，用户的聚类系数$C_u$定义为$$C_u=\\frac{k_0}{R_uT_u} \\quad \\quad \\quad （6）$$其中$k_u$是用户$u$的超度，$R_u$是用户$u$收集的资源的数量，$T_u$是用户$u$拥有的标签的数量。一个较大的$C_u$表示你有更相似的资源主题，这也可能表明你更专注于个性化或特殊的话题，而较小的$C_u$可能表明他/他有更多的兴趣。也可以用类似的定义来衡量资源和标签的聚类系数。\n   Zlati¢等人提出了一种名为超边密度的指标[86]。以用户节点$u$为例，它们将$u$的协调数(the coordination number)定义为 $z(u)= R_u + T_u$。对于一个给定的$k(u)$，配对数最大为 $Z_{max}(u)=2K(u)$ ，对于 $n(n-1)<k(u)<n^2$ 情况最小值是 $Z_{min}(u)=2n$ ，对于 $n^2<k(u)<n(n+1)$ 情况最小值是 $Z_{min}(u)=2n+1$ ，显然，一个局部树结构导致最大协调数，而最大重叠对应于最小协调数。 因此，他们将超边密度定义为[86]：$$D_h(u)=\\frac{Z_{max}(u)-Z(u)}{Z_{max}(u)-Z_{min}(u)} \\quad ,\\quad 0 \\le D_h(u) \\le 1 \\quad \\quad \\quad （7）$$ 资源和标签的超边密度定义是相同的。实证分析表明，这两个指标都表现出高聚类行为[82,86]。 协同标签网络超图的研究刚刚展开，如何正确量化聚类行为，节点之间的相关性和相似性以及社区结构仍然是一个开放的问题。\n   \n   4. 平均距离：定义为整个网络中两个随机节点之间的平均最短路径长度。\n\n \n\n####3.  推荐系统\n\n 推荐系统使用输入数据来预测其用户的潜在未来的喜好和兴趣。用户过去的评价通常是输入数据的重要组成部分。令$M$为用户数，令$N$为可评估和推荐的所有对象的数量。请注意，对象只是一个通用术语，可以表示书籍，电影或任何其他类型的消费内容。为了保持与标准术语的一致性，我们有时使用具有相同含义的词-“项目”。为了使符号更清楚，我们在枚举用户现在索引为拉丁字母 $i$ 和 $j$ ,以及枚举对象索引时限制为希腊字母 $\\alpha$ 和 $\\beta$。用户 $i$ 对对象 $\\alpha$ 的评价/打分表示为$r_{i\\alpha}$。这个评估通常是以整数评分量表（比如亚马逊的五星级制）-在这种情况下，我们会认为是一个显明的评级。请注意，二进制评级（如/不喜欢或好/坏）的常见情况也属于此类别。当只存在收集对象（如在书签共享系统中）或简单地消费（如在没有评级系统的在线报纸或杂志），或者当“喜欢”是唯一可能的表达（如在Facebook上）时，我们只有一元评级。在这种情况下，$r_{i\\alpha}=1$ 表示收集/消耗/喜欢的对象，$r_{i\\alpha}=0$  表示不存在的评估（参见图4）。推测用户对评级的置信区间是一个重要的工作，特别是对于二元或一元评级。用户的访问行为信息可能带来一些帮助，例如，可以通过观看电视节目的时间来估计用户的置信区间(喜好程度)，并且借助于该信息，可以提高推荐质量[95]。即使我们有明确的评级，这并不意味着我们知道用户如何并为什么做出这样的打分-他们是否具有数值上的评分标准，或者只是使用其来表现排序？最近的证据[96]在一定程度上是支持后者的。\n \n  ![](/images/fig4.png)图4. 由五个用户和四本书组成的推荐系统的图示。 每个推荐系统包含的用户和对象之间的基本信息都可以由二部图来表示。 该图还展示了在推荐算法的设计中经常被利用的一些附加信息，包括用户信息，对象的属性和对象内容。\n \n  推荐系统的目标是为用户提供个性化的\"推荐\"对象。 因此，可以对那些用户不知道的对象预测用户的评价或者是计算推荐分数。 被预测为高评价或高推荐分数的对象便构成了呈现给目标用户的推荐列表。 推荐系统有着广泛的性能指标体系（见第3.4节）。 推荐系统的惯用分类如下[15]：\n  \n  1. 基于内容的推荐：推荐的对象是内容类似于目标用户先前喜欢的对象内容的对象。 我们在4.2.3节叙述。\n  2. 协同推荐：根据大量用户过去的评估，选择推荐对象。 在表2中给出一个例子。它们可以分为：\n    * 基于记忆的协同过滤：推荐对象来自于与目标用户有相似偏好的用户喜欢的（user-base），或者是和目标用户之前喜欢的对象相似的对象（item-base）。我们将在第四章节（标准的基于相似的方法）和第七章节（引入社交网络的方法）来具体的阐述。\n    * 基于模型的协同过滤：推荐对象选自训练好的识别输入数据的模式的模型，我们将在第五章（降维方法）和第六章（基于信息传播理论的方法）具体来阐述。\n    \n  3. 混合方法：这类算法通过结合协同方法和基于内容的方法或者是混合多种不同的协同方法。我们将在8.4章节来具体的阐述\n\n####4.  推荐系统评估指标\n\n*其实可以参考看 2012 吕琳媛 [推荐系统评价指标综述](http://blog.sciencenet.cn/home.php?mod=attachment&id=20078)*\n\n 给定目标用户$i$，推荐系统将对所有$i$未收集的对象进行排序，并推荐排名最高的对象。 为了评估推荐算法，数据通常分为两部分：训练集$E^T$和测试组$E^P$。 训练集被视为已知信息，但是不允许使用来自测试组的信息来推荐。在本节中，我们简要回顾了用于衡量推荐质量的基本指标。如何选择特定指标（或指标）来评估推荐性能，这取决于系统应该实现的目标。当然，任何推荐系统的最终评估是由用户的判断决定的。\n \n1. 精度指标类\n \n ***评分精度指标:***  推荐系统的主要目的是预测用户未来的喜好和兴趣。 存在许多指标来评估推荐的各个方面性能。 两个著名的指标：均值绝对误差（MAE）和均方根误差（RMSE）用于测量预测评分与真实评分的接近程度。 如果$ r_{i\\alpha}$ 是用户$i$ 对对象 $α$ 的真实评分，则$\\widetilde r_{i\\alpha}$ 是预测的评分，$E^P$是隐藏的用户商品评分的集合，MAE和RMSE被定义为$$MAE = \\frac{1}{|E^p|} \\sum_{(i,\\alpha)\\in E^p} |r_{i\\alpha} - \\widetilde r_{i\\alpha}| \\quad \\quad \\quad (8) $$  $$RMSE = \\lgroup \\frac{1}{|E^p|} \\sum_{(i,\\alpha)\\in E^p} (r_{i\\alpha} - \\widetilde r_{i\\alpha})^2 \\rgroup ^{1/2} \\quad \\quad \\quad (9) $$ 较低的MAE和RMSE对意味着较高的预测精度。 由于RMSE在求和之前对误差进行平方，所以往往会更大程度地惩罚大错误。 由于这些指标平等对待所有评分，无论他们在推荐列表中的位置如何，所以它们对于某些常见任务，如找到可能被用户偏好的的少量对象（Finding Good Objects）来说并不是最佳的。 然而，由于其简单性，RMSE和MAE被广泛用于推荐系统的评估。\n\n ***评级和排名相关性:*** 评估预测精度的另一种方法是计算预测值和真实值之间的相关性。 有三个着名的相关性测度，即皮尔逊相关系数(the Pearson product-moment correlation)[97]，斯伯曼/斯皮尔曼相关系数 (the Spearman correlation)[98] 和 肯德尔相关系数(Kendall’s Tau )[99]。 Pearson相关性测量两组评分之间线性相关性的程度。它被定义为\n \n $$PCC = \\frac{\\sum_{a}(\\widetilde r_{\\alpha} - \\bar{\\widetilde r} )(r_\\alpha - \\bar r)}{\\sqrt{\\sum_\\alpha(\\widetilde r_{\\alpha}- \\bar{\\widetilde r} )^2}  {\\sqrt{\\sum_\\alpha(r_\\alpha - \\bar r)^2}}}$$\n \n\n \n 其中$r_\\alpha$ 和 $\\widetilde r_\\alpha$ 分布死真实的和预测的评分。Spearman相关系数 $\\rho$ 以与Pearson相同的方式定义，除了$r_\\alpha$ 和$\\widetilde r_\\alpha$ 被各个对象的排序代替。与Spearman相似，Kendall也评估了评分排名一致性程度。它被定义为 $\\tau = (C-D)/(C+D)$其中C是系统以正确的排序顺序预测的对象的数量，D是系统以错误的顺序预测的不一致的数量。当真实和预测的排名相同时，$\\tau = 1$，当它们完全相反时，$\\tau = -1$。 当真实排名或预测排名有并列情况出现时，在[13]中提出了Kendall的的变体， $$\\tau = \\frac {(C-D)}{\\sqrt{(C+D+S_T)(C+D+S_P)}}$$其中$S_T$是真实评分中相同的对象的数量，$S_P$是预测评分相同的对象的数量。Kendall 指标对连续有序对象的任何位置交换给予相等的权重，无论它在哪里发生。 但是，不同地点的交换，例如在1号到2号之间，100到101号之间的交换可能会有不同的影响。 因此，可以对真实排名的顶部给予对象更大的权重来改进指标。与Kendall类似，最初由Yao[100]提出来的归一化基于距离的性能指标（NDPM）用来比较两种不同的弱排序，它是基于统计矛盾对$C^-$(2个排序不一致)和兼容对$C^u$(一个排序是平局，另外一个排序是在所有对象中明显偏向其中一个),值得注意的是，这些预测评分关联性指标都是只关注于预测排序值而不关注具体的预测评分值，所以它们都不适用于那些旨在为用户提供精确预测评分值的系统。假如用$C$表示用户实际评分中具有严格偏好差别的商品对个数，则NDMP指标定义为：$$NDPM=\\frac{2C^-+C^u}{2C}$$\n\n ***分类准确度:*** 分类指标适用于诸如“寻找好对象”这样的任务，特别是当仅有隐含评分可用时（即，我们知道哪些对象受到用户的青睐，而不是他们具体喜欢多少）。当给出排序的对象列表时，推荐的阈值是不明确的或可变的。为了评估这种系统，一个受欢迎的指标是AUC（Area ROC Curve），其中ROC代表接收者操作特征曲线[101]（关于如何绘制ROC曲线见[13]）。 AUC尝试测量推荐系统如何能够成功地将相关对象（用户所赞赏的）与无关对象（所有其他对象）区分开来。计算AUC的最简单方法是将相关对象推荐的概率与不相关对象的概率进行比较。对于n个独立比较（每个比较指的是选择一个相关的和一个不相关的对象），如果有$n^\\prime$次相关对象分数高于不相关对象，$n^{\\prime\\prime}$次不相关对象和相关对象分数一致，根据[102]$$AUC=\\frac{n^\\prime+0.5n^{\\prime\\prime}}{n} \\quad \\quad \\quad (13) $$如果所有的相关对象比不相关对象的分数高那么 $AUC=1$，意味着一个完美的推荐系统。对于一个随机排序的推荐列表 $AUC=0.5$,因此，AUC超过0.5的程度表示推荐算法识别相关对象的能力。类似于AUC是[103]中提出的所谓的排名分数。 对于给定的用户，我们测量该用户推荐列表中相关对象的相对排名：当有$o$个对象被推荐时，具有排名r的相关对象具有相对排名$r/o$。 通过对所有用户及其相关对象进行平均，我们获得平均排名得分RS-排名得分越小，算法的准确性越高，反之亦然。\n \n 由于真正的用户通常仅关注推荐列表的顶部，所以更实际的方法是考虑漂亮在top-L位置前用户相关的对象的数量。基于此，精准率和召回率是最受欢迎的指标。 对于目标用户$i$，推荐的精确度和召回率$P_i(L) $ 和 $R_i(L)$被定义为$$P_i(L)=\\frac{d_i(L)}{L} \\quad , \\quad  R_i(L)=\\frac{d_i(L)}{D_i}  \\quad \\quad \\quad (14)$$其中$d_i(L)$指在长度为L的推荐列表中相关的项目数量，$D_i$是所有的相关项目总数，对所有拥有至少一个相关对象的所有用户的精度和回召率做平均，我们可以得到平均精度和平均回召率$P(L),R(L)$，这些指标可以通过对随机产生的推荐结果进行对比，于是就有了增强版本的精度和回召率指标$$e_P(L)=P(L)\\frac{MN}{D} \\quad , \\quad e_R(L)=R(L)\\frac{N}{L} \\quad \\quad \\quad (15)$$其中$M$和$N$分别是用户和商品的数量，$D$是所有相关商品的数量,通常精度回随着推荐列表长度L增加而下降，召回率随着L的增加而增长，我们可以把他们组合成一个和L弱相关的指标$F_1$-score。$$F_1(L)=\\frac{2PR}{P+R}\\quad \\quad \\quad (16)$$许多其他组合精度和召回率的指标被用在信息检索的有效性，但是很少用在推荐系统中:平均精度，深度精度，R精度，互惠等级[106]，二进制偏好度量[107]。 每个组合指数的详细介绍和讨论可以在[108]中找到。\n \n2. 基于排序加权的指标\n \n 现实生活中用户的耐心往往是有限的，一个人不太可能会不厌其烦地检查推荐列表中的所有商品，所以用户体验的满意度往往会受到用户喜欢的商品在推荐列表中位置的影响，这里介绍3个具有代表性的评价指标，更详细的信息参见文献[13]。\n \n ***半衰期效用指标(half-life utility)[109]*** 是在用户浏览商品的概率与该商品在推荐列表中的具体排序值呈指数递减的假设下提出的，它度量的是推荐系统对一个用户的实用性也即是用户真实评分和系统默认评分值的差别。用户$i$的期望效用定义为：$$HL_i=\\sum^n_\\alpha\\frac{max(r_{i\\alpha}-d,0)}{2^{(o_{i\\alpha}-1)/(h-1)}} \\quad \\quad \\quad (17)$$  推荐结果按照数$\\widetilde r_{i\\alpha}$降序排列，$r_{i\\alpha}$表示用户$i$对商品$\\alpha$的实际评分，而$o_{i\\alpha}$为商品$\\alpha$在用户$i$的推荐列表中的排名；$d$为默认评分(如说平均评分值)；$h$为系统的半衰期，也即是有50%的概率用户会浏览的推荐列表的位置。显然，当用户喜欢的商品都被放在推荐列表的前面时，该用户的半衰期效用指标达到最大值。通过计算有用户$HL_i$值的平均值，我们就得到了系统的整体效果。\n \n ***折扣累计利润(discounted cumulative gain，DCG)[110]*** 对于长度为L的推荐列表，DGG定义为$$DGG(b) = \\sum^b_n r_n+\\sum^L_{n=b+1}\\frac{r_n}{log_bn} \\quad \\quad \\quad (18)$$，其中$r_n$指排序中第n个项目的用户是否喜欢，$r_n=1$代表喜欢，$r_n=0$代表不喜欢，b是自由参数多设为2；DGG的主要思想是用户喜欢的商品被排在推荐列表前面比排在后面会更大程度上增加用户体验。\n \n ***排序偏差准确率（Rank-biased precision）[108]*** 这个指标假设用户往往先浏览排在推荐列表的首位商品然后依次以概率$p$浏览下一个，以$1-p$的概率不再看此推荐列表。对于一个长队为L的推荐来说，RBP定义为$$RBP=(1-p)\\sum^L_{n=1}r_nP^{n-1} \\quad \\quad \\quad (19)$$其中$r_n$和DCG相同,RBP和DCG类似，唯一的不同在于RBP把推荐列表中商品的浏览概率按等比数列递减，而DCG则是按照log调和级数形式。\n \n3. 多样性和新奇\n \n 即便给用户成功推荐一个用户喜欢的项目，但是当项目是众人皆知（流行的）对用户来说的价值也是微乎其微。为了补充上面精度指标，几种多样性和新颖性指标 [35,39,111]在最近被提出，我在这里做一个介绍。\n \n ***多样性*** 推荐系统的多样性是指被推荐项目之间的差异程度，在推荐系统中，多样性体现在以下两个层次，用户间的多样性(inter-user diversity)，衡量推荐系统对不同用户推荐不同商品的能力；另一个是用户内的多样性(intra-user diversity)，衡量推荐系统对一个用户推荐商品的多样性。用户间的多样性通过考虑用户推荐列表的种类来定义。对于用户i，j，可以用汉明距离来评估推荐列表的前L个项目差异性。$$H_{ij}=1 - \\frac{Q_{ij}(L)}{L} \\quad \\quad \\quad (20)$$其中$Q_{ij}(L)$是用户$i,j$之间前$L$个推荐商品中相同商品的数量，如果2个列表完全一致$Q_{ij}(L)=0$，如果没有任何重叠则为$Q_{ij}(L)=1$。所有用户对的$H_{ij}$值的平均值就是系统的$H(L)$值，该值越大，则推荐系统给用户推荐的多样性越好\n \n 将用户$i$的推荐商品表示为$\\{o_1，o_2，...，o_L\\}$，可以使用这些商品的相似度$（o_\\alpha，o_\\beta）$来测量用户内多样性（这种相似性可以直接从评分或对象元数据获取）[113]。 用户$i$推荐商品的平均相似度，$$I_i(L)=\\frac{1}{L(L-1)} \\sum_{\\alpha \\neq \\beta } s(o_\\alpha，o_\\beta) \\quad \\quad \\quad (21)$$，同样，我们可以通过平均所有用户值来获得系统的用户内的多样性值$I(L)$，该值越小说明用户内的多样性越好。值得注意的是，通过避免推荐过度相似的对象，用户内推荐列表多样性可用于增强和改进推荐列表[37]。 可以通过在推荐列表[111]中引入对象排名的折扣函数来获得等级敏感版本。通过引入关于商品排序的折扣函数就可以获得排序敏感的版本(The rank-sensitive version can be obtained by introducing a discount function of the object’s rank in recommendation list [111].)[111]。\n \n ***新颖性和惊喜性*** 推荐系统中的新颖性是指推荐对象与用户以前看过的不同之处。 量化算法产生新颖和意想不到的结果的能力的最简单的方法是测量推荐对象的平均受欢迎程度$$N(L)=\\frac{1}{ML}\\sum^m_{i =1}\\sum_{\\alpha \\in O^i_R}K_\\alpha  \\quad \\quad \\quad (22)$$其中$O^i_R$是用户$i$的推荐列表,$K_\\alpha$是商品$\\alpha$的度(商品的流行性)，低流行性意味着推荐结果的高新颖性。另外一个可以用来评估推荐结果的惊喜性的指标通过计算自信息(self-information)[114]。对于一个商品$\\alpha$，一个随机选取的用户选到他的概率为$k_\\alpha / M $,所以自信息定义为 $$U_\\alpha = \\log_2(M/K_\\alpha)  \\quad \\quad \\quad (23)$$可以通过将观察限制到目标用户，即计算目标用户的top-L商品的平均自我信息来定义基于用户相关的新颖性指标变体。对所有用户进行平均，我们获得了平均top-L惊喜值$U(L)$。通过类似的结果公式，在[111]中提出了一种基于发现的新颖性，通过考虑对象是随机用户已知或熟悉的概率。\n \n4. 覆盖率\n \n 覆盖率指标是指算法向用户推荐的商品能够覆盖全部商品的比例。将所有推荐列表的前L个位置中的不同对象的总数表示为$N_d$，则$L$相关的覆盖率指标定义为$$COV(L)=N_d/N$$低覆盖率表示该算法可以访问并仅推荐少量不同对象（通常是最受欢迎的），这往往导致很少的不同商品。相反，覆盖率较高的算法更有可能提供不同的推荐[115]。从这个观点来看，覆盖率也可以被认为是一种多样性度量。此外，覆盖率有助于更好地评估精度指标的结果[116]：推荐流行的对象可能具有高精度但低覆盖率。一个好的推荐算法应该将同时具有高精度和覆盖率。\n \n 评估推荐系统的特定指标的选取取决于系统需要实现的目标。在实践中，可以为新的和有经验的用户分别指定不同的目标，这进一步使评估过程复杂化。为了更好的概述，表3总结了推荐系统评估指标。\n\nTable3. 推荐系统指标摘要。第三列表示度量的偏好（例如，更小的MAE意味着更高的评级精度）。第四列描述度量的范围。最后两列显示该度量是否从排名获得，以及是否取决于推荐列表L的长度。\n\n|名字|符号|偏好|范围|是否与排名相关|是否依赖长度L|\n----|----|----|----|----|----|\nMAE                        | $MAE$        | Small |Rating accuracy              |No  |No  |\nRMSE                       | $RMSE$       | Small |Rating accuracy              |No  |Yes |\nPearson                    | $PCC$        | Large |Rating correlation           |No  |No  |\nSpearman                   | $\\rho$       | Large |Rating correlation           |No  |Yes |\nKendall’s Tau              | $\\tau$       | Large |Rating correlation           |No  |Yes |\nNDPM                       | $NDPM$       | Small |Ranking correlation          |No  |Yes |\nPrecision                  | $P(L)$       | Large |Classification accuracy      |Yes |Yes |\nRecall                     | $R(L)$       | Large |Classification accuracy      |No  |Yes |\nF1-score                   | $F1(L)$      | Large |Classification               |Yes |Yes |\nAUC                        | $AUC$        | Large |accuracy Classification      |No  |No  |\nRanking score              | $RS$         | Small |accuracy Ranking             |Yes |Yes |\nHalf-life utility          | $HL(L)$      | Large |accuracy Satisfaction        |No  |No  |\nDiscounted Cumulative Gain | $DCG(b, L)$  | Large |Satisfaction and precision   |No  |Yes |\nRank-biased Precision      | $RBP(p,L)$   | Large |Satisfaction and precision   |Yes |No  |\nHamming distance           | $H(L)$       | Large |Inter-diversity              |No  |Yes |\nIntra-similarity           | $I(L)$       | Small |Intra-diversity              |Yes |No  |\nPopularity                 | $N(L)$       | Small |Surprisal and novelty        |No  |Yes |\nSelf-information           | $U(L)$       | Large |Unexpectedness               |Yes |No  |\nCoverag                    | $COV(L)$     | Large |Coverage and diversity       |No  |Yes |\n\n\n![](/images/Summary-recommendation-metrics.png)\n\n\n###基于相似的方法\n###降维技术\n###基于传播的方法\n###社交过滤\n###元方法\n###性能评估\n###展望\n","slug":"推荐系统","published":1,"updated":"2017-09-30T03:33:01.076Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8cgqo7s000k3szya3x6bchs","content":"<h3 id=\"摘要\">摘要</h3>\n<p>互联网的持续爆发式扩张极大的增加了采用推荐系统过滤大量的信息的必要性，推荐系统被社会学，计算学物理学家和交叉学科等大量学界进行了广泛的研究 ，尽管取得了实质性的理论和实践成果，缺乏统一方法对不同的推荐算法比较，阻碍了其进一步的进步。在本文中，我们回顾了推荐系统的最新进展，并讨论了主要挑战。我们对比并评估了已有的算法，并推测他们在未来的发展中扮演的角色。除了算法之外，我们还从物理的角度来描述推荐系统的宏观行为。我们讨论了推荐系统潜在的影响和未来的发展。我们在此强调：推荐系统有很强的科学深度并结合了不同的研究领域，吸引着物理学家以及交叉学科研究人员的兴趣。</p>\n<h3 id=\"序言\">序言</h3>\n<p>由于计算机和计算机网络，我们的社会各方面都经历着翻天覆地的变化，我们在线购物，通过搜索引擎搜集信息，在互联网上进行很大部分的社会活动。事实上，我们大量的行为和交互都以电子的方式存储，这给了研究人员机会在更加细尺度来研究社会经济和技术社会系统，传统的“软学科”，比如社会学和经济学，通过对这些已有的新数据的研究已经发展了许许多多的研究分支，在数据驱动研究方面有着长期经验的物理学家，也已经加入了这一趋势，为诸如金融[3,4]，网络理论[5-9]和社会动力学[10]等多个非传统领域做出了贡献。随着过去十几年间物理学家的兴趣的持续增长，推荐系统和信息检索的研究也不例外。推荐系统的任务是利用用户及其偏好的数据预测用户未来可能的喜好和兴趣。推荐系统的研究处于科学和社会经济生活的十字路口，其巨大的潜力首先被信息革命前沿的网络企业家所注意。虽然原本是由计算机科学家主导的领域，但推荐系统需要各领域的贡献，现在它也是数学家，物理学家和心理学家感兴趣的话题。例如，最近在商业公司Netflix [11]组织的的推荐比赛中，基于人类行为的心理学方法获得高分并不是巧合。</p>\n<p>当为目标用户做推荐时，最基本的方法是选择与目标用户相似的用户所青睐的对象。即使这种简单的方法也可以通过多种方式实现，这是因为推荐领域缺乏一般性的“第一原则”-从中可以推断出正确的推荐方式。例如，如何最好地衡量用户相似性并评估其不确定性？如何综合各种用户的意见分歧？如何处理少量信息的用户？所有数据是否权重平等，或者是否可以检测到鲁莽或故意误导的意见？当使用比基于用户相似性的方法更复杂的方法时，也出现和这些类似的问题。幸运的是，存在一些可用于测量和比较各种方法的实际数据集。因此，与物理学类似，实验决定哪种推荐方法是好的，哪种不是。</p>\n<p>认为推荐系统只有在适当的数据集可用的情况下才会被研究是非常有误导性的。虽然数据的可用性对推荐方法的实证评估很重要，但主要驱动力来自实践：电子系统给我们太多的选择让我们自己来处理。工业界对推荐的兴趣并不奇怪，一本关于推荐系统领域的早期书《Net Worth by John Hagel III and Marc Singer [12]》明确指出“（info-mediaries）”的巨大经济影响，它可以大大提高个人消费者的信息能力。现在，大多数电子商务网站提供各种形式的推荐–从简单的显示最受欢迎的项目或通过复杂的数据挖掘技术推荐的相同生产者的其他产品。人们很快意识到没有独特的最佳推荐方法， 相反，根据可用数据的上下文和密度，对不同的应用场景采用不同的推荐算法是最有可能成功的。因此，没有灵丹妙药，最好的办法是了解基本的前提（推荐场景）和推荐机制，这样就可以解决来自生活中的各种真实应用问题。 这一点也反映在这篇综述中，我们不试图强调任何推荐算法。 相反，我们回顾基本的思想，方法和工具with particular emphasis on physics-rooted approaches.</p>\n<p>撰写此综述的原因是多方面的，首先，虽然计算机科学家对推荐系统的广泛评论已经存在[13-15]，但是物理学家与计算机科学家的观点不同，它们更多的使用复杂网络方法和采用各种经典物理过程（如扩散）来做信息检索。因此，我们相信，该综述（We thus believe that this review with its structure and emphasis on respective topics can provide a novel point of view.）可以提供一个新颖的观点。 其次，过去十年已经看到物理学家对推荐系统的兴趣越来越大，我们希望通过用物理学界更熟悉的语言来描述最先进的技术的这篇综述可以成为他们的有用来源。 最后，这里介绍的跨学科方法可能为信息检索领域的开放性问题和挑战提供新的见解和解决方案。</p>\n<p>本篇综述结构如下：为了激发研究问题的积极性，我们首先在第2章讨论了推荐系统的实际应用。接着在第3节中，我们介绍了基本概念，例如复杂网络，推荐系统和评估指标，这些概念构成了后续阐述的基础。 然后，我们开始讨论推荐算法，首先是传统方法（第4节中基于相似性的方法和第5节中的维数降低技术），然后是起源于随机游走过程被物理学所熟知的基于网络的方法（在第6节）。还包括基于外部信息的方法，如社交关系（第7节），关键字或时间戳（第8节）。 我们最后在第9节中对推荐算法的性能进行简要评估，并在第10节讨论了该领域的前景。</p>\n<h3 id=\"推荐系统应用真实场景\">推荐系统应用真实场景</h3>\n<h4 id=\"netflix-prize\">Netflix prize</h4>\n<h4 id=\"主要挑战\">主要挑战</h4>\n<p>推荐系统领域的研究人员面临着许多挑战，这些挑战对其使用和执行算法构成风险。这里我们只提到主要的：</p>\n<ol style=\"list-style-type: decimal\">\n<li><p>数据稀疏 由于可用数据量非常大（比如，大型的在线书店经常有几百万的书），导致用户之间的交集十分小甚至没有。此外，即便每个用户/商品平均评估次数很高，但是由于每个商品/用户的评估次数分布非常不均匀（通常是power-law或者weibull分布），大部分的商品只有极少的评分，所以一个有效的推荐系统必须考虑到数据的稀疏性问题。</p></li>\n<li><p>可扩展性 尽管数据经常是稀疏的，但是对于那些大型的网站拥有百万的用户和商品。因此必须考虑计算成本的问题，寻找计算要求不高的或者易于并行化的推荐算法。另一种可能的解决方案是基于使用增量数据的算法（增量学习算法），随着数据的增长，算法不会在全局重新计算，而是逐步增量计算[29,30]，这种增量方法类似于在物理和数学广泛应用的扰动技术[31]。</p></li>\n<li><p>冷启动 当新的用户进入一个系统，系统中没有任何有用的信息来产生推荐结果给用户，通常的解决办法是通过结合基于内容的和协同过滤的混合推荐技术（参考 8.4 节），有时还需要获取用户的一些基本信息（如年龄，位置和偏好等）来配合。另外的一个方法是识别不同web服务中的同一个用户。比如说百分点开发了一个可以跟踪同一个用户在不通电商网站行为的技术，那么一个在A网站作为冷启动的用户可以通过他在B，C，D 网站的行为来进行相关的推荐。</p></li>\n<li><p>多样性与精确性的两难困境 当推荐任务是为特定用户赞赏的项目时，通常最有效的方法是推荐流行的和高评分的项目，但是这样的推荐对用户来说没有什么价值，因为即便在没有推荐系统的情况下，流向的项目也很容易被找到（甚至难以避免），因此一个好的推荐项目列表也应该包括那些用户自己本身无法找到的隐藏项目[35]。对于这个问题的解决办法有：直接增加推荐列表的多样性[36-38]和使用混合的推荐算法[39]</p></li>\n<li><p>攻击的脆弱性 受推荐系统在电子商务领域重大的经济利益的驱动，一些心怀不轨的用户通过提供一些虚假恶意的信息，故意增加或者压制某些商品被推荐的可能性[44]。从阻止恶意评估进入系统到复杂的抵抗推荐技术[41]，有大量的工具可以防止这样的行为。然而，这并不是一件容易的事情，因为随着防作弊的工具的升级，攻击者的策略也越来越先进。例如，Burke等人[42]引入了八个攻击策略，进一步可以分为四个类：基本攻击（包括随机和平均攻击），低认知攻击，核攻击和知情攻击。（basic attack, low-acknowledge attack, nuke attack and informed attack.需要看引文来翻译）</p></li>\n<li><p>时间的价值（好像是讲兴趣漂移问题） 一个真实用户的兴趣是和时间尺度相关的（举例来说，短期感兴趣与旅行计划相关，长期兴趣和居住地或者政治相关），大多数的推荐算法评估的时候都忽略了时间的影响。旧的想法是否会随着时间衰减，怎么衰减，以及用户评估和项目相关性中的典型临时模式是什么，这些都还需要持续的研究</p></li>\n<li><p>推荐的评估 虽然我们有很多不同的指标（见第3.4节），但是如何根据给定的情况和任务选择最好的指标仍然是一个悬而未决的问题。不同推荐算法的比较也存在问题的，因为不同的算法可以简单地解决不同的任务，最后，推荐系统的整体用户体验（包括用户对推荐结果的满意程度和用户对系统的信任）难以在“离线”评估中进行测量。因此，在推荐系统中，实证用户的研究仍然是一个受欢迎的反馈来源。</p></li>\n<li><p>用户界面 实践表明，为了促进用户接受推荐结果，推荐过程需要透明化：用户明白为什么特定的项目被推荐给他们。除此之外，通常潜在的感兴趣项目列表会很长，因此它需要简单的方式来展现，并且可以轻松的通过他去浏览由不同方法给出的推荐结果。</p></li>\n</ol>\n<p>除了以上的长期挑战，推荐系统近期出现了许多新颖的问题，由于相关科学的方法论的发展，特别是网络分析的新工具，科学家开始考虑网络结构对推荐的影响，以及如何利用已知的结构特征来改进推荐。例如，Huang等人[47]分析了消费者-商品网络，并提出了一种改进的推荐算法，这种算法偏向增强局部聚类属性的边。Sahebi等[48]设计了一种利用社区结构的改进算法。新技术的进步和传播也带来新的挑战。例如，配备GPS的手机已经成为主流，互联网的被普遍的接入，因此基于位置的推荐现在是可行的并且越来越显有意义，精准的推荐要求人类的运动的高可预测性和定量方式来定义地点和人之间的相似之处。最后，智能推荐系统应考虑不同人群的不同行为模式。例如，新用户倾向于访问非常受欢迎的项目并选择类似的项目，而老用户通常具有更具体的兴趣[53,54]，并且用户在低风险（例如收集书签，下载音乐等）和高风险（例如购买电脑，租房等）活动之间的行为差​​异很大。</p>\n<p>其实可以直接看周涛老师的一篇中文论文 <a href=\"http://blog.sciencenet.cn/blog-3075-588779.html\" target=\"_blank\" rel=\"noopener\">《个性化推荐的十大挑战》</a>，里面讲的更加具体，虽然推荐系统经过了这么多年的发展，但是对现在的推荐系统依旧面临着文中的问题。</p>\n<h3 id=\"主题和问题的定义\">主题和问题的定义</h3>\n<p>我们在本章中简要回顾一下在推荐系统研究中有用的基本概念。</p>\n<h4 id=\"图\">1. 图</h4>\n<p>网络分析是揭示许多复杂系统组织原理的通用工具[5-9]。网络是一组元素（称为节点或顶点），它们之间具有连接（称为边或链接）。许多社会，生物，技术和信息系统可以被描述为具有代表个人或组织的节点和捕获其交互的边缘的网络。 网络研究，即数学文献中的图论，具有悠久的历史，从18世纪欧拉所解决的古典柯尼斯堡桥梁问题开始[57]。用数学的定义，网络<span class=\"math inline\">\\(G\\)</span>是一个有序的不相交的二元组集合<span class=\"math inline\">\\((V,E)\\)</span>其中<span class=\"math inline\">\\(V\\)</span>是节点的集合<span class=\"math inline\">\\(E\\)</span>是边的集合。在一个无向网络中，一条连接节点<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>的边表示为<span class=\"math inline\">\\(x \\leftrightarrow y\\)</span>,<span class=\"math inline\">\\(x \\leftrightarrow y\\)</span>和<span class=\"math inline\">\\(y \\leftrightarrow x\\)</span>代表的是同一条边,在一个有向网络中，边是一个关于节点的有序二元组，<span class=\"math inline\">\\(x\\rightarrow y\\)</span> 代表由<span class=\"math inline\">\\(x\\)</span>指向<span class=\"math inline\">\\(y\\)</span>的一条边，边<span class=\"math inline\">\\(x\\rightarrow y\\)</span> 和<span class=\"math inline\">\\(y\\rightarrow x\\)</span>是不同的，并且可以同时存在的。除非另有说明，否则我们假设网络不包含自环（连接节点到其自身的“边”）或连接同一对节点的多边（多个“边”）。在多网络（multinetwork）中，允许两个循环和多边。</p>\n<p>在无向网络<span class=\"math inline\">\\(G(V，E)\\)</span>中，如果<span class=\"math inline\">\\(x\\leftrightarrow y \\in E\\)</span>，则两个节点<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>被认为是彼此相邻的。节点<span class=\"math inline\">\\(x\\)</span>的邻域节点集合，或者说<span class=\"math inline\">\\(x\\)</span>邻居集合由<span class=\"math inline\">\\(\\Gamma_{x}\\)</span>来表示,节点<span class=\"math inline\">\\(x\\)</span>的度定义为<span class=\"math inline\">\\(k_{x}=|\\Gamma_{x}|\\)</span>.度分布<span class=\"math inline\">\\(P(k)\\)</span>定义为随机选择的节点的度为<span class=\"math inline\">\\(k\\)</span>的概率.在一个均匀的网站，每一个节点有着相同的度<span class=\"math inline\">\\(k_{0}\\)</span>，所<span class=\"math inline\">\\(P_{k}=\\delta_{k,k_{0}}\\)</span>,在经典的Erdös–Rényi随机网络中，其中每对节点以给定的概率<span class=\"math inline\">\\(p\\)</span>连接生产边，其度分布满足二项式分布。<span class=\"math display\">\\[P(k)={N-1 \\choose k}p^{k}(1-p)^{n-1-k} \\quad \\quad \\quad (1)\\]</span>其中<span class=\"math inline\">\\(N=|V|\\)</span>是网络中节点的数量。这样的分布有一个以平均度<span class=\"math inline\">\\(\\bar x = p(N-1)\\)</span>表示的特征量表.在上个世纪末，研究人员转而对大规模实际网络进行调查，结果发现他们的度分布通常跨越几个数量级，大致遵循幂律形式<span class=\"math display\">\\[P(k)\\sim k^{-\\gamma} \\quad \\quad \\quad (2) \\]</span>其中<span class=\"math inline\">\\(\\gamma\\)</span>为正指数，通常位于2和3之间[5]，这种网络被称为无标度网络，因为他们缺乏度的特征尺度，幂律函数<span class=\"math inline\">\\(P(k)\\)</span>是与规模无关的。注意，实践数据中的幂律分布的检测需要固定的统计工具[62,63]。 对于有向网络，由<span class=\"math inline\">\\(k^{out}\\)</span>表示的节点<span class=\"math inline\">\\(x\\)</span>的出度，是从x开始的边的数量，入度<span class=\"math inline\">\\(k^{in}\\)</span>是以x结束的边的数量。 有向网络的进度和出度分布通常彼此不同。</p>\n<p>一般来说，如果一个网络的高度节点倾向于与高度节点连接，而低度节点倾向于与低度节点连接，那么它被认为是同配assortative的（如果情况相反，那就是异配的)。 该度-度相关性可以由最近邻节点门的平均度[64,65]或皮尔逊系数的变体称为分类系数[66,67]来表征。 分类系数<span class=\"math inline\">\\(r\\)</span>在<span class=\"math inline\">\\(-1≤r≤1\\)</span>的范围内。如果<span class=\"math inline\">\\(r&gt; 0\\)</span>，网络是同配的; 如果<span class=\"math inline\">\\(r &lt;0\\)</span>，则网络是异配的。 请注意，该系数对度非均匀性（heterogeneous degree ）敏感。 例如，无论网络的连接模式如何，r在具有非常非均匀性度分布的网络（例如，因特网）中将为负值[68]。</p>\n<p>连接两个节点的路径中的边数被称为路径的长度，两个节点之间的距离被定义为连接它们的最短路径的长度。 网络的直径是所有节点对之间的最大距离，平均距离是所有节点对上的平均距离平均值<span class=\"math display\">\\[\\bar d = \\frac{1}{N(N-1)}\\sum_{x \\neq y}d_{x,y} \\quad \\quad \\quad (3) \\]</span>其中<span class=\"math inline\">\\(d_{x,y}\\)</span>是<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>之间的距离.许多真实网络显示出所谓的小世界现象：它们的平均距离不会比网络大小的对数增长得快[70,71]。</p>\n<p>三元聚类在社会互动系统中的重要性的认知已经超过100多年[72]。 在社交网络分析中[73]，这种聚类称为传递性，定义为网络中三角形总数与相连节点的三元组总数之比的三倍。 1998年，Watts和Strogatz [71]提出了一个类似的指数来量化三元聚类，称为聚类系数。 对于给定的节点<span class=\"math inline\">\\(x\\)</span>，该系数被定义为<span class=\"math inline\">\\(x\\)</span>的邻居之间边的数量与邻居对的数量的比率，<span class=\"math display\">\\[c_x=\\frac{e_x}{\\frac{1}{2}k_x(k_x)-1} \\quad \\quad \\quad (4) \\]</span>其中<span class=\"math inline\">\\(e_x\\)</span>表示节点<span class=\"math inline\">\\(x\\)</span>的<span class=\"math inline\">\\(k_x\\)</span>个邻居之间的边数量（该定义仅在<span class=\"math inline\">\\(k_x&gt; 1\\)</span>时有意义）。 网络聚类系数被定义为<span class=\"math inline\">\\(k_x&gt; 1\\)</span>的所有<span class=\"math inline\">\\(x\\)</span>的<span class=\"math inline\">\\(c_x\\)</span>的平均值。也可以将聚类系数定义为网络中三角形数<span class=\"math inline\">\\(\\times 3\\)</span>与连接的三元组顶点数之比，有时也被称为“传递三元组的分数(‘fraction of transitive triples’)”[7]。 请注意，这两个定义可以给出完全不同的结果。</p>\n<p>图1说明了简单无向网络的上述定义。 有关网络测量的更多信息，我们鼓励读者去参考关于网络特征的文章[74]。</p>\n<p><img src=\"/images/fig1.png\" /> 图1. 一个拥有6个节点7条边的简单无向网络，节点的度分别为<span class=\"math inline\">\\(k_1=1,k_2=k_5=3,k_3=k_4=k_6=2\\)</span>,对应的节点的度分布<span class=\"math inline\">\\(p(1)=\\frac{1}{6},p(2)=\\frac{1}{2},p(3)=\\frac{1}{3}\\)</span>,网络的直径和平均平均距离为<span class=\"math inline\">\\(d_{max}=3,d=1.6\\)</span>,聚类系数为<span class=\"math inline\">\\(c_2=\\frac{1}{6},c_3=c_4=0,c_5=\\frac{1}{3},c_6=1\\)</span>,平均聚类系数为<span class=\"math inline\">\\(C=0.3\\)</span></p>\n<h4 id=\"二部图和超图\">2. 二部图和超图</h4>\n<p>如果一个网络<span class=\"math inline\">\\(G(V,E)\\)</span>满足分割为<span class=\"math inline\">\\((V_1,V_2)\\)</span>后，<span class=\"math inline\">\\(V_1\\cup V_2=V\\)</span>并且<span class=\"math inline\">\\(V_1\\cap V_2=\\emptyset\\)</span>，每一条边由一个<span class=\"math inline\">\\(V_1\\)</span>和一个<span class=\"math inline\">\\(V_2\\)</span>中的节点连接而成,那么这就是一个二部图。许多真实系统自然地被模拟为二部图，比如，由化学物质和化学反应组成的代谢网络[75]，由行为和行为者组成的协作网络[76]，由个人电脑和电话号码[77]的互联网电话网络等等。我们专注于一类特殊的二分网络，称为基于网络的用户商品网络[53]，它们代表在线服务网站中的用户和商品之间的相互影响，例如在Delicious.com中的书签集合以及在amazon.com上购买的书籍。我们将在后面看到，这些网络描述了推荐系统的基本结构。 基于Web的用户商品网络是逐渐演进的，其中节点和链接逐渐被添加。 相比之下，这不可能发生在例如作者合作网络（例如，在发布之后无法将作者添加到科学论文）。</p>\n<p>大多数的基于web的用户商品网络有着共同的结构属性，他们的（object-degree）商品度分布遵循幂律式形式$P(k)k^{-} $,对于互联网电影数据库（IMDb）来说 <span class=\"math inline\">\\(\\gamma \\approx 1.6\\)</span>[78],音乐共享站点audioscrobbler.com的 <span class=\"math inline\">\\(\\gamma \\approx 1.8\\)</span> [79]，对于电子商务网站amazon.com [53] <span class=\"math inline\">\\(\\gamma \\approx 2.3\\)</span>；对于书签共享网站delicious.com来说 <span class=\"math inline\">\\(\\gamma \\approx 2.5\\)</span>。用户度分布的形式通常在指数和幂律之间[53]，并且可以很好地拟合Weibull分布分布[27]（文献中也称为拉伸指数分布[80]）<span class=\"math display\">\\[P(k)=k^{\\mu-1}exp[-(k/k_0)^\\mu] \\quad \\quad \\quad (5) \\]</span>其中<span class=\"math inline\">\\(k_0\\)</span>是常数，<span class=\"math inline\">\\(\\mu\\)</span>是拉伸指数。 用户和商品之间的连接（边）表现出一种异配（disassortative）混合模式[53,78]。 二部图定义的简单扩展是所谓的多部图。对于一个r-partite的图，他存在r个节点集合<span class=\"math inline\">\\(V_1,V_2...V_r\\)</span>，并<span class=\"math inline\">\\(V=V_1 \\cup V_2 \\cup...\\cup V_r,V_i\\cap V_j=\\emptyset ,其中i\\neq j\\)</span>，并且对于所有的节点集合<span class=\"math inline\">\\(V_i\\)</span>，不存在同一集合的节点之间的边。多部网络已经在协作标签系统（文献也称众分类法Folksonomies）[81-84]中找到了应用，用户可以在其中为在线资源分配标签，例如flickr.com中的照片，CiteULike.com中的参考文献和delicious.com中的书签等在线资源分配标签。</p>\n<p>请注意，三部网络表示形式中丢失了一些信息。例如，给定一条连接资源和标签的边，我们不知道哪个用户（或用户们）对此边有贡献。对于这个问题，超图[85]可以用来给出协作标签系统的完整结构的精确表示。在超图<span class=\"math inline\">\\(H(V,E)\\)</span>中，超集<span class=\"math inline\">\\(E\\)</span>是<span class=\"math inline\">\\(V\\)</span>的幂集的子集，即V的所有子集的集合。 因此，边<span class=\"math inline\">\\(e\\)</span>可以连接多个节点。 类似于普通网络，超图中的节点度被定义为与节点相邻的超节点的数量，并且两个节点之间的距离被定义为连接这些节点的最小数量的超边。 聚类系数[82,86]和社区结构[86,87]也可以按照普通网络中的定义进行定义和量化。 请注意，超图和二分网络之间存在一对一的对应关系。给定超图<span class=\"math inline\">\\(H（V，E）\\)</span>，相应的二分网络<span class=\"math inline\">\\(G（V^\\prime，E^\\prime）\\)</span>包含两个节点集，如<span class=\"math inline\">\\(V^\\prime= V\\cup E\\)</span>，而<span class=\"math inline\">\\(x \\in V\\)</span>与<span class=\"math inline\">\\(Y \\in E\\)</span>连接，当且仅当<span class=\"math inline\">\\(x \\in Y\\)</span>（参见图2作为说明）。</p>\n<p><img src=\"/images/fig2.png\" />图2. 超图（a）和二分网络（b）之间的一一对应的图示。 有三个超边，X = {1,2,4}，Y = {4,5,6}和Z = {2,3,5,6}。</p>\n<p>超图已经在铁磁动力学[88,89]，人口分层[90]，蜂窝网络[91]，学术团队形成[92]等许多领域中得到应用。 在这里，我们更关心协作标签系统的超图表示[86,93,94]，其中每个超边连接三个节点（由图3中的三角形表示），用户 <span class=\"math inline\">\\(u\\)</span> ，资源 <span class=\"math inline\">\\(r\\)</span> 和标签 <span class=\"math inline\">\\(t\\)</span> ， 表示用户 <span class=\"math inline\">\\(u\\)</span> 把标签 <span class=\"math inline\">\\(t\\)</span> 给了资源 <span class=\"math inline\">\\(r\\)</span> 。 资源可以由许多用户收集，并且由用户给出几个标签，标签可以与许多资源相关联，这就导致了小世界超图[86,94]（图3显示了基本单元和广泛的描述）此外，协同标签系统的超图已被证明是高度集群化的，它具有长尾度分布和社区结构[86,94]。[94]可以找到超图的演变模型。</p>\n<p><img src=\"/images/fig3.png\" />图3. 协同标签网络的超图。 （左）一个类似三角形的超边[93]，其中包含三种类型的顶点，一个蓝色圆圈，一个绿色矩形和一个棕色三角形，分别表示用户，资源和标签。 （右）描述由两个用户组成，四个资源和三个标签的超图。 以用户<span class=\"math inline\">\\(U_2\\)</span>和资源<span class=\"math inline\">\\(R_1\\)</span>为例，测量值表示为：（i）<span class=\"math inline\">\\(U_2\\)</span>已经参与在六个超边，这意味着它的超度是6; （ii）<span class=\"math inline\">\\(U_2\\)</span>直接连接到三个资源和三个标签。 按照公式 （6），认为它最大可能有<span class=\"math inline\">\\(3 * 3 = 9\\)</span> 超边。 因此，其聚类系数等于<span class=\"math inline\">\\(6/9=0.667\\)</span>，其中6是其超度; 相对而言，如定义按式（7），其聚类系数为<span class=\"math inline\">\\(D_h(U2)= \\frac {12-6} {6-4} = 0.75\\)</span>; （iii）从<span class=\"math inline\">\\(U_2\\)</span>到<span class=\"math inline\">\\(R_1\\)</span>的最短路径为<span class=\"math inline\">\\(U_2-T_1-R_1\\)</span>，表示<span class=\"math inline\">\\(U2\\)</span>与<span class=\"math inline\">\\(R_1\\)</span>之间的距离为2</p>\n<p>一般来说，以复杂科学角度的评估超图可以从以下几点展开（图3给出这些的详细描述）：</p>\n<ol style=\"list-style-type: decimal\">\n<li>超度：超图中的节点的度可以自然地定义为与其相邻的超边的数量。</li>\n<li>超度分布：定义为每个超度占据的比例，其中超度定义为常规节点参与的超边的数量。</li>\n<li><p>聚类系数：定义为节点的实际超边数量与可能的超边数量的比例[82]。 例如，用户的聚类系数<span class=\"math inline\">\\(C_u\\)</span>定义为<span class=\"math display\">\\[C_u=\\frac{k_0}{R_uT_u} \\quad \\quad \\quad （6）\\]</span>其中<span class=\"math inline\">\\(k_u\\)</span>是用户<span class=\"math inline\">\\(u\\)</span>的超度，<span class=\"math inline\">\\(R_u\\)</span>是用户<span class=\"math inline\">\\(u\\)</span>收集的资源的数量，<span class=\"math inline\">\\(T_u\\)</span>是用户<span class=\"math inline\">\\(u\\)</span>拥有的标签的数量。一个较大的<span class=\"math inline\">\\(C_u\\)</span>表示你有更相似的资源主题，这也可能表明你更专注于个性化或特殊的话题，而较小的<span class=\"math inline\">\\(C_u\\)</span>可能表明他/他有更多的兴趣。也可以用类似的定义来衡量资源和标签的聚类系数。 Zlati¢等人提出了一种名为超边密度的指标[86]。以用户节点<span class=\"math inline\">\\(u\\)</span>为例，它们将<span class=\"math inline\">\\(u\\)</span>的协调数(the coordination number)定义为 <span class=\"math inline\">\\(z(u)= R_u + T_u\\)</span>。对于一个给定的<span class=\"math inline\">\\(k(u)\\)</span>，配对数最大为 <span class=\"math inline\">\\(Z_{max}(u)=2K(u)\\)</span> ，对于 <span class=\"math inline\">\\(n(n-1)&lt;k(u)&lt;n^2\\)</span> 情况最小值是 <span class=\"math inline\">\\(Z_{min}(u)=2n\\)</span> ，对于 <span class=\"math inline\">\\(n^2&lt;k(u)&lt;n(n+1)\\)</span> 情况最小值是 <span class=\"math inline\">\\(Z_{min}(u)=2n+1\\)</span> ，显然，一个局部树结构导致最大协调数，而最大重叠对应于最小协调数。 因此，他们将超边密度定义为[86]：<span class=\"math display\">\\[D_h(u)=\\frac{Z_{max}(u)-Z(u)}{Z_{max}(u)-Z_{min}(u)} \\quad ,\\quad 0 \\le D_h(u) \\le 1 \\quad \\quad \\quad （7）\\]</span> 资源和标签的超边密度定义是相同的。实证分析表明，这两个指标都表现出高聚类行为[82,86]。 协同标签网络超图的研究刚刚展开，如何正确量化聚类行为，节点之间的相关性和相似性以及社区结构仍然是一个开放的问题。</p></li>\n<li><p>平均距离：定义为整个网络中两个随机节点之间的平均最短路径长度。</p></li>\n</ol>\n<h4 id=\"推荐系统\">3. 推荐系统</h4>\n<p>推荐系统使用输入数据来预测其用户的潜在未来的喜好和兴趣。用户过去的评价通常是输入数据的重要组成部分。令<span class=\"math inline\">\\(M\\)</span>为用户数，令<span class=\"math inline\">\\(N\\)</span>为可评估和推荐的所有对象的数量。请注意，对象只是一个通用术语，可以表示书籍，电影或任何其他类型的消费内容。为了保持与标准术语的一致性，我们有时使用具有相同含义的词-“项目”。为了使符号更清楚，我们在枚举用户现在索引为拉丁字母 <span class=\"math inline\">\\(i\\)</span> 和 <span class=\"math inline\">\\(j\\)</span> ,以及枚举对象索引时限制为希腊字母 <span class=\"math inline\">\\(\\alpha\\)</span> 和 <span class=\"math inline\">\\(\\beta\\)</span>。用户 <span class=\"math inline\">\\(i\\)</span> 对对象 <span class=\"math inline\">\\(\\alpha\\)</span> 的评价/打分表示为<span class=\"math inline\">\\(r_{i\\alpha}\\)</span>。这个评估通常是以整数评分量表（比如亚马逊的五星级制）-在这种情况下，我们会认为是一个显明的评级。请注意，二进制评级（如/不喜欢或好/坏）的常见情况也属于此类别。当只存在收集对象（如在书签共享系统中）或简单地消费（如在没有评级系统的在线报纸或杂志），或者当“喜欢”是唯一可能的表达（如在Facebook上）时，我们只有一元评级。在这种情况下，<span class=\"math inline\">\\(r_{i\\alpha}=1\\)</span> 表示收集/消耗/喜欢的对象，<span class=\"math inline\">\\(r_{i\\alpha}=0\\)</span> 表示不存在的评估（参见图4）。推测用户对评级的置信区间是一个重要的工作，特别是对于二元或一元评级。用户的访问行为信息可能带来一些帮助，例如，可以通过观看电视节目的时间来估计用户的置信区间(喜好程度)，并且借助于该信息，可以提高推荐质量[95]。即使我们有明确的评级，这并不意味着我们知道用户如何并为什么做出这样的打分-他们是否具有数值上的评分标准，或者只是使用其来表现排序？最近的证据[96]在一定程度上是支持后者的。</p>\n<p><img src=\"/images/fig4.png\" />图4. 由五个用户和四本书组成的推荐系统的图示。 每个推荐系统包含的用户和对象之间的基本信息都可以由二部图来表示。 该图还展示了在推荐算法的设计中经常被利用的一些附加信息，包括用户信息，对象的属性和对象内容。</p>\n<p>推荐系统的目标是为用户提供个性化的“推荐”对象。 因此，可以对那些用户不知道的对象预测用户的评价或者是计算推荐分数。 被预测为高评价或高推荐分数的对象便构成了呈现给目标用户的推荐列表。 推荐系统有着广泛的性能指标体系（见第3.4节）。 推荐系统的惯用分类如下[15]：</p>\n<ol style=\"list-style-type: decimal\">\n<li>基于内容的推荐：推荐的对象是内容类似于目标用户先前喜欢的对象内容的对象。 我们在4.2.3节叙述。</li>\n<li>协同推荐：根据大量用户过去的评估，选择推荐对象。 在表2中给出一个例子。它们可以分为：\n<ul>\n<li>基于记忆的协同过滤：推荐对象来自于与目标用户有相似偏好的用户喜欢的（user-base），或者是和目标用户之前喜欢的对象相似的对象（item-base）。我们将在第四章节（标准的基于相似的方法）和第七章节（引入社交网络的方法）来具体的阐述。</li>\n<li>基于模型的协同过滤：推荐对象选自训练好的识别输入数据的模式的模型，我们将在第五章（降维方法）和第六章（基于信息传播理论的方法）具体来阐述。</li>\n</ul></li>\n<li>混合方法：这类算法通过结合协同方法和基于内容的方法或者是混合多种不同的协同方法。我们将在8.4章节来具体的阐述</li>\n</ol>\n<h4 id=\"推荐系统评估指标\">4. 推荐系统评估指标</h4>\n<p><em>其实可以参考看 2012 吕琳媛 <a href=\"http://blog.sciencenet.cn/home.php?mod=attachment&amp;id=20078\" target=\"_blank\" rel=\"noopener\">推荐系统评价指标综述</a></em></p>\n<p>给定目标用户<span class=\"math inline\">\\(i\\)</span>，推荐系统将对所有<span class=\"math inline\">\\(i\\)</span>未收集的对象进行排序，并推荐排名最高的对象。 为了评估推荐算法，数据通常分为两部分：训练集<span class=\"math inline\">\\(E^T\\)</span>和测试组<span class=\"math inline\">\\(E^P\\)</span>。 训练集被视为已知信息，但是不允许使用来自测试组的信息来推荐。在本节中，我们简要回顾了用于衡量推荐质量的基本指标。如何选择特定指标（或指标）来评估推荐性能，这取决于系统应该实现的目标。当然，任何推荐系统的最终评估是由用户的判断决定的。</p>\n<ol style=\"list-style-type: decimal\">\n<li>精度指标类</li>\n</ol>\n<p><strong><em>评分精度指标:</em></strong> 推荐系统的主要目的是预测用户未来的喜好和兴趣。 存在许多指标来评估推荐的各个方面性能。 两个著名的指标：均值绝对误差（MAE）和均方根误差（RMSE）用于测量预测评分与真实评分的接近程度。 如果$ r_{i}$ 是用户<span class=\"math inline\">\\(i\\)</span> 对对象 <span class=\"math inline\">\\(α\\)</span> 的真实评分，则<span class=\"math inline\">\\(\\widetilde r_{i\\alpha}\\)</span> 是预测的评分，<span class=\"math inline\">\\(E^P\\)</span>是隐藏的用户商品评分的集合，MAE和RMSE被定义为<span class=\"math display\">\\[MAE = \\frac{1}{|E^p|} \\sum_{(i,\\alpha)\\in E^p} |r_{i\\alpha} - \\widetilde r_{i\\alpha}| \\quad \\quad \\quad (8) \\]</span> <span class=\"math display\">\\[RMSE = \\lgroup \\frac{1}{|E^p|} \\sum_{(i,\\alpha)\\in E^p} (r_{i\\alpha} - \\widetilde r_{i\\alpha})^2 \\rgroup ^{1/2} \\quad \\quad \\quad (9) \\]</span> 较低的MAE和RMSE对意味着较高的预测精度。 由于RMSE在求和之前对误差进行平方，所以往往会更大程度地惩罚大错误。 由于这些指标平等对待所有评分，无论他们在推荐列表中的位置如何，所以它们对于某些常见任务，如找到可能被用户偏好的的少量对象（Finding Good Objects）来说并不是最佳的。 然而，由于其简单性，RMSE和MAE被广泛用于推荐系统的评估。</p>\n<p><strong><em>评级和排名相关性:</em></strong> 评估预测精度的另一种方法是计算预测值和真实值之间的相关性。 有三个着名的相关性测度，即皮尔逊相关系数(the Pearson product-moment correlation)[97]，斯伯曼/斯皮尔曼相关系数 (the Spearman correlation)[98] 和 肯德尔相关系数(Kendall’s Tau )[99]。 Pearson相关性测量两组评分之间线性相关性的程度。它被定义为</p>\n<p><span class=\"math display\">\\[PCC = \\frac{\\sum_{a}(\\widetilde r_{\\alpha} - \\bar{\\widetilde r} )(r_\\alpha - \\bar r)}{\\sqrt{\\sum_\\alpha(\\widetilde r_{\\alpha}- \\bar{\\widetilde r} )^2}  {\\sqrt{\\sum_\\alpha(r_\\alpha - \\bar r)^2}}}\\]</span></p>\n<p>其中<span class=\"math inline\">\\(r_\\alpha\\)</span> 和 <span class=\"math inline\">\\(\\widetilde r_\\alpha\\)</span> 分布死真实的和预测的评分。Spearman相关系数 <span class=\"math inline\">\\(\\rho\\)</span> 以与Pearson相同的方式定义，除了<span class=\"math inline\">\\(r_\\alpha\\)</span> 和<span class=\"math inline\">\\(\\widetilde r_\\alpha\\)</span> 被各个对象的排序代替。与Spearman相似，Kendall也评估了评分排名一致性程度。它被定义为 <span class=\"math inline\">\\(\\tau = (C-D)/(C+D)\\)</span>其中C是系统以正确的排序顺序预测的对象的数量，D是系统以错误的顺序预测的不一致的数量。当真实和预测的排名相同时，<span class=\"math inline\">\\(\\tau = 1\\)</span>，当它们完全相反时，<span class=\"math inline\">\\(\\tau = -1\\)</span>。 当真实排名或预测排名有并列情况出现时，在[13]中提出了Kendall的的变体， <span class=\"math display\">\\[\\tau = \\frac {(C-D)}{\\sqrt{(C+D+S_T)(C+D+S_P)}}\\]</span>其中<span class=\"math inline\">\\(S_T\\)</span>是真实评分中相同的对象的数量，<span class=\"math inline\">\\(S_P\\)</span>是预测评分相同的对象的数量。Kendall 指标对连续有序对象的任何位置交换给予相等的权重，无论它在哪里发生。 但是，不同地点的交换，例如在1号到2号之间，100到101号之间的交换可能会有不同的影响。 因此，可以对真实排名的顶部给予对象更大的权重来改进指标。与Kendall类似，最初由Yao[100]提出来的归一化基于距离的性能指标（NDPM）用来比较两种不同的弱排序，它是基于统计矛盾对<span class=\"math inline\">\\(C^-\\)</span>(2个排序不一致)和兼容对<span class=\"math inline\">\\(C^u\\)</span>(一个排序是平局，另外一个排序是在所有对象中明显偏向其中一个),值得注意的是，这些预测评分关联性指标都是只关注于预测排序值而不关注具体的预测评分值，所以它们都不适用于那些旨在为用户提供精确预测评分值的系统。假如用<span class=\"math inline\">\\(C\\)</span>表示用户实际评分中具有严格偏好差别的商品对个数，则NDMP指标定义为：<span class=\"math display\">\\[NDPM=\\frac{2C^-+C^u}{2C}\\]</span></p>\n<p><strong><em>分类准确度:</em></strong> 分类指标适用于诸如“寻找好对象”这样的任务，特别是当仅有隐含评分可用时（即，我们知道哪些对象受到用户的青睐，而不是他们具体喜欢多少）。当给出排序的对象列表时，推荐的阈值是不明确的或可变的。为了评估这种系统，一个受欢迎的指标是AUC（Area ROC Curve），其中ROC代表接收者操作特征曲线[101]（关于如何绘制ROC曲线见[13]）。 AUC尝试测量推荐系统如何能够成功地将相关对象（用户所赞赏的）与无关对象（所有其他对象）区分开来。计算AUC的最简单方法是将相关对象推荐的概率与不相关对象的概率进行比较。对于n个独立比较（每个比较指的是选择一个相关的和一个不相关的对象），如果有<span class=\"math inline\">\\(n^\\prime\\)</span>次相关对象分数高于不相关对象，<span class=\"math inline\">\\(n^{\\prime\\prime}\\)</span>次不相关对象和相关对象分数一致，根据[102]<span class=\"math display\">\\[AUC=\\frac{n^\\prime+0.5n^{\\prime\\prime}}{n} \\quad \\quad \\quad (13) \\]</span>如果所有的相关对象比不相关对象的分数高那么 <span class=\"math inline\">\\(AUC=1\\)</span>，意味着一个完美的推荐系统。对于一个随机排序的推荐列表 <span class=\"math inline\">\\(AUC=0.5\\)</span>,因此，AUC超过0.5的程度表示推荐算法识别相关对象的能力。类似于AUC是[103]中提出的所谓的排名分数。 对于给定的用户，我们测量该用户推荐列表中相关对象的相对排名：当有<span class=\"math inline\">\\(o\\)</span>个对象被推荐时，具有排名r的相关对象具有相对排名<span class=\"math inline\">\\(r/o\\)</span>。 通过对所有用户及其相关对象进行平均，我们获得平均排名得分RS-排名得分越小，算法的准确性越高，反之亦然。</p>\n<p>由于真正的用户通常仅关注推荐列表的顶部，所以更实际的方法是考虑漂亮在top-L位置前用户相关的对象的数量。基于此，精准率和召回率是最受欢迎的指标。 对于目标用户<span class=\"math inline\">\\(i\\)</span>，推荐的精确度和召回率$P_i(L) $ 和 <span class=\"math inline\">\\(R_i(L)\\)</span>被定义为<span class=\"math display\">\\[P_i(L)=\\frac{d_i(L)}{L} \\quad , \\quad  R_i(L)=\\frac{d_i(L)}{D_i}  \\quad \\quad \\quad (14)\\]</span>其中<span class=\"math inline\">\\(d_i(L)\\)</span>指在长度为L的推荐列表中相关的项目数量，<span class=\"math inline\">\\(D_i\\)</span>是所有的相关项目总数，对所有拥有至少一个相关对象的所有用户的精度和回召率做平均，我们可以得到平均精度和平均回召率<span class=\"math inline\">\\(P(L),R(L)\\)</span>，这些指标可以通过对随机产生的推荐结果进行对比，于是就有了增强版本的精度和回召率指标<span class=\"math display\">\\[e_P(L)=P(L)\\frac{MN}{D} \\quad , \\quad e_R(L)=R(L)\\frac{N}{L} \\quad \\quad \\quad (15)\\]</span>其中<span class=\"math inline\">\\(M\\)</span>和<span class=\"math inline\">\\(N\\)</span>分别是用户和商品的数量，<span class=\"math inline\">\\(D\\)</span>是所有相关商品的数量,通常精度回随着推荐列表长度L增加而下降，召回率随着L的增加而增长，我们可以把他们组合成一个和L弱相关的指标<span class=\"math inline\">\\(F_1\\)</span>-score。<span class=\"math display\">\\[F_1(L)=\\frac{2PR}{P+R}\\quad \\quad \\quad (16)\\]</span>许多其他组合精度和召回率的指标被用在信息检索的有效性，但是很少用在推荐系统中:平均精度，深度精度，R精度，互惠等级[106]，二进制偏好度量[107]。 每个组合指数的详细介绍和讨论可以在[108]中找到。</p>\n<ol start=\"2\" style=\"list-style-type: decimal\">\n<li>基于排序加权的指标</li>\n</ol>\n<p>现实生活中用户的耐心往往是有限的，一个人不太可能会不厌其烦地检查推荐列表中的所有商品，所以用户体验的满意度往往会受到用户喜欢的商品在推荐列表中位置的影响，这里介绍3个具有代表性的评价指标，更详细的信息参见文献[13]。</p>\n<p><strong><em>半衰期效用指标(half-life utility)[109]</em></strong> 是在用户浏览商品的概率与该商品在推荐列表中的具体排序值呈指数递减的假设下提出的，它度量的是推荐系统对一个用户的实用性也即是用户真实评分和系统默认评分值的差别。用户<span class=\"math inline\">\\(i\\)</span>的期望效用定义为：<span class=\"math display\">\\[HL_i=\\sum^n_\\alpha\\frac{max(r_{i\\alpha}-d,0)}{2^{(o_{i\\alpha}-1)/(h-1)}} \\quad \\quad \\quad (17)\\]</span> 推荐结果按照数<span class=\"math inline\">\\(\\widetilde r_{i\\alpha}\\)</span>降序排列，<span class=\"math inline\">\\(r_{i\\alpha}\\)</span>表示用户<span class=\"math inline\">\\(i\\)</span>对商品<span class=\"math inline\">\\(\\alpha\\)</span>的实际评分，而<span class=\"math inline\">\\(o_{i\\alpha}\\)</span>为商品<span class=\"math inline\">\\(\\alpha\\)</span>在用户<span class=\"math inline\">\\(i\\)</span>的推荐列表中的排名；<span class=\"math inline\">\\(d\\)</span>为默认评分(如说平均评分值)；<span class=\"math inline\">\\(h\\)</span>为系统的半衰期，也即是有50%的概率用户会浏览的推荐列表的位置。显然，当用户喜欢的商品都被放在推荐列表的前面时，该用户的半衰期效用指标达到最大值。通过计算有用户<span class=\"math inline\">\\(HL_i\\)</span>值的平均值，我们就得到了系统的整体效果。</p>\n<p><strong><em>折扣累计利润(discounted cumulative gain，DCG)[110]</em></strong> 对于长度为L的推荐列表，DGG定义为<span class=\"math display\">\\[DGG(b) = \\sum^b_n r_n+\\sum^L_{n=b+1}\\frac{r_n}{log_bn} \\quad \\quad \\quad (18)\\]</span>，其中<span class=\"math inline\">\\(r_n\\)</span>指排序中第n个项目的用户是否喜欢，<span class=\"math inline\">\\(r_n=1\\)</span>代表喜欢，<span class=\"math inline\">\\(r_n=0\\)</span>代表不喜欢，b是自由参数多设为2；DGG的主要思想是用户喜欢的商品被排在推荐列表前面比排在后面会更大程度上增加用户体验。</p>\n<p><strong><em>排序偏差准确率（Rank-biased precision）[108]</em></strong> 这个指标假设用户往往先浏览排在推荐列表的首位商品然后依次以概率<span class=\"math inline\">\\(p\\)</span>浏览下一个，以<span class=\"math inline\">\\(1-p\\)</span>的概率不再看此推荐列表。对于一个长队为L的推荐来说，RBP定义为<span class=\"math display\">\\[RBP=(1-p)\\sum^L_{n=1}r_nP^{n-1} \\quad \\quad \\quad (19)\\]</span>其中<span class=\"math inline\">\\(r_n\\)</span>和DCG相同,RBP和DCG类似，唯一的不同在于RBP把推荐列表中商品的浏览概率按等比数列递减，而DCG则是按照log调和级数形式。</p>\n<ol start=\"3\" style=\"list-style-type: decimal\">\n<li>多样性和新奇</li>\n</ol>\n<p>即便给用户成功推荐一个用户喜欢的项目，但是当项目是众人皆知（流行的）对用户来说的价值也是微乎其微。为了补充上面精度指标，几种多样性和新颖性指标 [35,39,111]在最近被提出，我在这里做一个介绍。</p>\n<p><strong><em>多样性</em></strong> 推荐系统的多样性是指被推荐项目之间的差异程度，在推荐系统中，多样性体现在以下两个层次，用户间的多样性(inter-user diversity)，衡量推荐系统对不同用户推荐不同商品的能力；另一个是用户内的多样性(intra-user diversity)，衡量推荐系统对一个用户推荐商品的多样性。用户间的多样性通过考虑用户推荐列表的种类来定义。对于用户i，j，可以用汉明距离来评估推荐列表的前L个项目差异性。<span class=\"math display\">\\[H_{ij}=1 - \\frac{Q_{ij}(L)}{L} \\quad \\quad \\quad (20)\\]</span>其中<span class=\"math inline\">\\(Q_{ij}(L)\\)</span>是用户<span class=\"math inline\">\\(i,j\\)</span>之间前<span class=\"math inline\">\\(L\\)</span>个推荐商品中相同商品的数量，如果2个列表完全一致<span class=\"math inline\">\\(Q_{ij}(L)=0\\)</span>，如果没有任何重叠则为<span class=\"math inline\">\\(Q_{ij}(L)=1\\)</span>。所有用户对的<span class=\"math inline\">\\(H_{ij}\\)</span>值的平均值就是系统的<span class=\"math inline\">\\(H(L)\\)</span>值，该值越大，则推荐系统给用户推荐的多样性越好</p>\n<p>将用户<span class=\"math inline\">\\(i\\)</span>的推荐商品表示为<span class=\"math inline\">\\(\\{o_1，o_2，...，o_L\\}\\)</span>，可以使用这些商品的相似度<span class=\"math inline\">\\(（o_\\alpha，o_\\beta）\\)</span>来测量用户内多样性（这种相似性可以直接从评分或对象元数据获取）[113]。 用户<span class=\"math inline\">\\(i\\)</span>推荐商品的平均相似度，<span class=\"math display\">\\[I_i(L)=\\frac{1}{L(L-1)} \\sum_{\\alpha \\neq \\beta } s(o_\\alpha，o_\\beta) \\quad \\quad \\quad (21)\\]</span>，同样，我们可以通过平均所有用户值来获得系统的用户内的多样性值<span class=\"math inline\">\\(I(L)\\)</span>，该值越小说明用户内的多样性越好。值得注意的是，通过避免推荐过度相似的对象，用户内推荐列表多样性可用于增强和改进推荐列表[37]。 可以通过在推荐列表[111]中引入对象排名的折扣函数来获得等级敏感版本。通过引入关于商品排序的折扣函数就可以获得排序敏感的版本(The rank-sensitive version can be obtained by introducing a discount function of the object’s rank in recommendation list [111].)[111]。</p>\n<p><strong><em>新颖性和惊喜性</em></strong> 推荐系统中的新颖性是指推荐对象与用户以前看过的不同之处。 量化算法产生新颖和意想不到的结果的能力的最简单的方法是测量推荐对象的平均受欢迎程度<span class=\"math display\">\\[N(L)=\\frac{1}{ML}\\sum^m_{i =1}\\sum_{\\alpha \\in O^i_R}K_\\alpha  \\quad \\quad \\quad (22)\\]</span>其中<span class=\"math inline\">\\(O^i_R\\)</span>是用户<span class=\"math inline\">\\(i\\)</span>的推荐列表,<span class=\"math inline\">\\(K_\\alpha\\)</span>是商品<span class=\"math inline\">\\(\\alpha\\)</span>的度(商品的流行性)，低流行性意味着推荐结果的高新颖性。另外一个可以用来评估推荐结果的惊喜性的指标通过计算自信息(self-information)[114]。对于一个商品<span class=\"math inline\">\\(\\alpha\\)</span>，一个随机选取的用户选到他的概率为$k_/ M $,所以自信息定义为 <span class=\"math display\">\\[U_\\alpha = \\log_2(M/K_\\alpha)  \\quad \\quad \\quad (23)\\]</span>可以通过将观察限制到目标用户，即计算目标用户的top-L商品的平均自我信息来定义基于用户相关的新颖性指标变体。对所有用户进行平均，我们获得了平均top-L惊喜值<span class=\"math inline\">\\(U(L)\\)</span>。通过类似的结果公式，在[111]中提出了一种基于发现的新颖性，通过考虑对象是随机用户已知或熟悉的概率。</p>\n<ol start=\"4\" style=\"list-style-type: decimal\">\n<li>覆盖率</li>\n</ol>\n<p>覆盖率指标是指算法向用户推荐的商品能够覆盖全部商品的比例。将所有推荐列表的前L个位置中的不同对象的总数表示为<span class=\"math inline\">\\(N_d\\)</span>，则<span class=\"math inline\">\\(L\\)</span>相关的覆盖率指标定义为<span class=\"math display\">\\[COV(L)=N_d/N\\]</span>低覆盖率表示该算法可以访问并仅推荐少量不同对象（通常是最受欢迎的），这往往导致很少的不同商品。相反，覆盖率较高的算法更有可能提供不同的推荐[115]。从这个观点来看，覆盖率也可以被认为是一种多样性度量。此外，覆盖率有助于更好地评估精度指标的结果[116]：推荐流行的对象可能具有高精度但低覆盖率。一个好的推荐算法应该将同时具有高精度和覆盖率。</p>\n<p>评估推荐系统的特定指标的选取取决于系统需要实现的目标。在实践中，可以为新的和有经验的用户分别指定不同的目标，这进一步使评估过程复杂化。为了更好的概述，表3总结了推荐系统评估指标。</p>\n<p>Table3. 推荐系统指标摘要。第三列表示度量的偏好（例如，更小的MAE意味着更高的评级精度）。第四列描述度量的范围。最后两列显示该度量是否从排名获得，以及是否取决于推荐列表L的长度。</p>\n<table>\n<thead>\n<tr class=\"header\">\n<th>名字</th>\n<th>符号</th>\n<th>偏好</th>\n<th>范围</th>\n<th>是否与排名相关</th>\n<th>是否依赖长度L</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td>MAE</td>\n<td><span class=\"math inline\">\\(MAE\\)</span></td>\n<td>Small</td>\n<td>Rating accuracy</td>\n<td>No</td>\n<td>No</td>\n</tr>\n<tr class=\"even\">\n<td>RMSE</td>\n<td><span class=\"math inline\">\\(RMSE\\)</span></td>\n<td>Small</td>\n<td>Rating accuracy</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr class=\"odd\">\n<td>Pearson</td>\n<td><span class=\"math inline\">\\(PCC\\)</span></td>\n<td>Large</td>\n<td>Rating correlation</td>\n<td>No</td>\n<td>No</td>\n</tr>\n<tr class=\"even\">\n<td>Spearman</td>\n<td><span class=\"math inline\">\\(\\rho\\)</span></td>\n<td>Large</td>\n<td>Rating correlation</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr class=\"odd\">\n<td>Kendall’s Tau</td>\n<td><span class=\"math inline\">\\(\\tau\\)</span></td>\n<td>Large</td>\n<td>Rating correlation</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr class=\"even\">\n<td>NDPM</td>\n<td><span class=\"math inline\">\\(NDPM\\)</span></td>\n<td>Small</td>\n<td>Ranking correlation</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr class=\"odd\">\n<td>Precision</td>\n<td><span class=\"math inline\">\\(P(L)\\)</span></td>\n<td>Large</td>\n<td>Classification accuracy</td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr class=\"even\">\n<td>Recall</td>\n<td><span class=\"math inline\">\\(R(L)\\)</span></td>\n<td>Large</td>\n<td>Classification accuracy</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr class=\"odd\">\n<td>F1-score</td>\n<td><span class=\"math inline\">\\(F1(L)\\)</span></td>\n<td>Large</td>\n<td>Classification</td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr class=\"even\">\n<td>AUC</td>\n<td><span class=\"math inline\">\\(AUC\\)</span></td>\n<td>Large</td>\n<td>accuracy Classification</td>\n<td>No</td>\n<td>No</td>\n</tr>\n<tr class=\"odd\">\n<td>Ranking score</td>\n<td><span class=\"math inline\">\\(RS\\)</span></td>\n<td>Small</td>\n<td>accuracy Ranking</td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr class=\"even\">\n<td>Half-life utility</td>\n<td><span class=\"math inline\">\\(HL(L)\\)</span></td>\n<td>Large</td>\n<td>accuracy Satisfaction</td>\n<td>No</td>\n<td>No</td>\n</tr>\n<tr class=\"odd\">\n<td>Discounted Cumulative Gain</td>\n<td><span class=\"math inline\">\\(DCG(b, L)\\)</span></td>\n<td>Large</td>\n<td>Satisfaction and precision</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr class=\"even\">\n<td>Rank-biased Precision</td>\n<td><span class=\"math inline\">\\(RBP(p,L)\\)</span></td>\n<td>Large</td>\n<td>Satisfaction and precision</td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr class=\"odd\">\n<td>Hamming distance</td>\n<td><span class=\"math inline\">\\(H(L)\\)</span></td>\n<td>Large</td>\n<td>Inter-diversity</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr class=\"even\">\n<td>Intra-similarity</td>\n<td><span class=\"math inline\">\\(I(L)\\)</span></td>\n<td>Small</td>\n<td>Intra-diversity</td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr class=\"odd\">\n<td>Popularity</td>\n<td><span class=\"math inline\">\\(N(L)\\)</span></td>\n<td>Small</td>\n<td>Surprisal and novelty</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr class=\"even\">\n<td>Self-information</td>\n<td><span class=\"math inline\">\\(U(L)\\)</span></td>\n<td>Large</td>\n<td>Unexpectedness</td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr class=\"odd\">\n<td>Coverag</td>\n<td><span class=\"math inline\">\\(COV(L)\\)</span></td>\n<td>Large</td>\n<td>Coverage and diversity</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n</tbody>\n</table>\n<div class=\"figure\">\n<img src=\"/images/Summary-recommendation-metrics.png\" />\n\n</div>\n<h3 id=\"基于相似的方法\">基于相似的方法</h3>\n<h3 id=\"降维技术\">降维技术</h3>\n<h3 id=\"基于传播的方法\">基于传播的方法</h3>\n<h3 id=\"社交过滤\">社交过滤</h3>\n<h3 id=\"元方法\">元方法</h3>\n<h3 id=\"性能评估\">性能评估</h3>\n<h3 id=\"展望\">展望</h3>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"摘要\">摘要</h3>\n<p>互联网的持续爆发式扩张极大的增加了采用推荐系统过滤大量的信息的必要性，推荐系统被社会学，计算学物理学家和交叉学科等大量学界进行了广泛的研究 ，尽管取得了实质性的理论和实践成果，缺乏统一方法对不同的推荐算法比较，阻碍了其进一步的进步。在本文中，我们回顾了推荐系统的最新进展，并讨论了主要挑战。我们对比并评估了已有的算法，并推测他们在未来的发展中扮演的角色。除了算法之外，我们还从物理的角度来描述推荐系统的宏观行为。我们讨论了推荐系统潜在的影响和未来的发展。我们在此强调：推荐系统有很强的科学深度并结合了不同的研究领域，吸引着物理学家以及交叉学科研究人员的兴趣。</p>\n<h3 id=\"序言\">序言</h3>\n<p>由于计算机和计算机网络，我们的社会各方面都经历着翻天覆地的变化，我们在线购物，通过搜索引擎搜集信息，在互联网上进行很大部分的社会活动。事实上，我们大量的行为和交互都以电子的方式存储，这给了研究人员机会在更加细尺度来研究社会经济和技术社会系统，传统的“软学科”，比如社会学和经济学，通过对这些已有的新数据的研究已经发展了许许多多的研究分支，在数据驱动研究方面有着长期经验的物理学家，也已经加入了这一趋势，为诸如金融[3,4]，网络理论[5-9]和社会动力学[10]等多个非传统领域做出了贡献。随着过去十几年间物理学家的兴趣的持续增长，推荐系统和信息检索的研究也不例外。推荐系统的任务是利用用户及其偏好的数据预测用户未来可能的喜好和兴趣。推荐系统的研究处于科学和社会经济生活的十字路口，其巨大的潜力首先被信息革命前沿的网络企业家所注意。虽然原本是由计算机科学家主导的领域，但推荐系统需要各领域的贡献，现在它也是数学家，物理学家和心理学家感兴趣的话题。例如，最近在商业公司Netflix [11]组织的的推荐比赛中，基于人类行为的心理学方法获得高分并不是巧合。</p>\n<p>当为目标用户做推荐时，最基本的方法是选择与目标用户相似的用户所青睐的对象。即使这种简单的方法也可以通过多种方式实现，这是因为推荐领域缺乏一般性的“第一原则”-从中可以推断出正确的推荐方式。例如，如何最好地衡量用户相似性并评估其不确定性？如何综合各种用户的意见分歧？如何处理少量信息的用户？所有数据是否权重平等，或者是否可以检测到鲁莽或故意误导的意见？当使用比基于用户相似性的方法更复杂的方法时，也出现和这些类似的问题。幸运的是，存在一些可用于测量和比较各种方法的实际数据集。因此，与物理学类似，实验决定哪种推荐方法是好的，哪种不是。</p>\n<p>认为推荐系统只有在适当的数据集可用的情况下才会被研究是非常有误导性的。虽然数据的可用性对推荐方法的实证评估很重要，但主要驱动力来自实践：电子系统给我们太多的选择让我们自己来处理。工业界对推荐的兴趣并不奇怪，一本关于推荐系统领域的早期书《Net Worth by John Hagel III and Marc Singer [12]》明确指出“（info-mediaries）”的巨大经济影响，它可以大大提高个人消费者的信息能力。现在，大多数电子商务网站提供各种形式的推荐–从简单的显示最受欢迎的项目或通过复杂的数据挖掘技术推荐的相同生产者的其他产品。人们很快意识到没有独特的最佳推荐方法， 相反，根据可用数据的上下文和密度，对不同的应用场景采用不同的推荐算法是最有可能成功的。因此，没有灵丹妙药，最好的办法是了解基本的前提（推荐场景）和推荐机制，这样就可以解决来自生活中的各种真实应用问题。 这一点也反映在这篇综述中，我们不试图强调任何推荐算法。 相反，我们回顾基本的思想，方法和工具with particular emphasis on physics-rooted approaches.</p>\n<p>撰写此综述的原因是多方面的，首先，虽然计算机科学家对推荐系统的广泛评论已经存在[13-15]，但是物理学家与计算机科学家的观点不同，它们更多的使用复杂网络方法和采用各种经典物理过程（如扩散）来做信息检索。因此，我们相信，该综述（We thus believe that this review with its structure and emphasis on respective topics can provide a novel point of view.）可以提供一个新颖的观点。 其次，过去十年已经看到物理学家对推荐系统的兴趣越来越大，我们希望通过用物理学界更熟悉的语言来描述最先进的技术的这篇综述可以成为他们的有用来源。 最后，这里介绍的跨学科方法可能为信息检索领域的开放性问题和挑战提供新的见解和解决方案。</p>\n<p>本篇综述结构如下：为了激发研究问题的积极性，我们首先在第2章讨论了推荐系统的实际应用。接着在第3节中，我们介绍了基本概念，例如复杂网络，推荐系统和评估指标，这些概念构成了后续阐述的基础。 然后，我们开始讨论推荐算法，首先是传统方法（第4节中基于相似性的方法和第5节中的维数降低技术），然后是起源于随机游走过程被物理学所熟知的基于网络的方法（在第6节）。还包括基于外部信息的方法，如社交关系（第7节），关键字或时间戳（第8节）。 我们最后在第9节中对推荐算法的性能进行简要评估，并在第10节讨论了该领域的前景。</p>\n<h3 id=\"推荐系统应用真实场景\">推荐系统应用真实场景</h3>\n<h4 id=\"netflix-prize\">Netflix prize</h4>\n<h4 id=\"主要挑战\">主要挑战</h4>\n<p>推荐系统领域的研究人员面临着许多挑战，这些挑战对其使用和执行算法构成风险。这里我们只提到主要的：</p>\n<ol style=\"list-style-type: decimal\">\n<li><p>数据稀疏 由于可用数据量非常大（比如，大型的在线书店经常有几百万的书），导致用户之间的交集十分小甚至没有。此外，即便每个用户/商品平均评估次数很高，但是由于每个商品/用户的评估次数分布非常不均匀（通常是power-law或者weibull分布），大部分的商品只有极少的评分，所以一个有效的推荐系统必须考虑到数据的稀疏性问题。</p></li>\n<li><p>可扩展性 尽管数据经常是稀疏的，但是对于那些大型的网站拥有百万的用户和商品。因此必须考虑计算成本的问题，寻找计算要求不高的或者易于并行化的推荐算法。另一种可能的解决方案是基于使用增量数据的算法（增量学习算法），随着数据的增长，算法不会在全局重新计算，而是逐步增量计算[29,30]，这种增量方法类似于在物理和数学广泛应用的扰动技术[31]。</p></li>\n<li><p>冷启动 当新的用户进入一个系统，系统中没有任何有用的信息来产生推荐结果给用户，通常的解决办法是通过结合基于内容的和协同过滤的混合推荐技术（参考 8.4 节），有时还需要获取用户的一些基本信息（如年龄，位置和偏好等）来配合。另外的一个方法是识别不同web服务中的同一个用户。比如说百分点开发了一个可以跟踪同一个用户在不通电商网站行为的技术，那么一个在A网站作为冷启动的用户可以通过他在B，C，D 网站的行为来进行相关的推荐。</p></li>\n<li><p>多样性与精确性的两难困境 当推荐任务是为特定用户赞赏的项目时，通常最有效的方法是推荐流行的和高评分的项目，但是这样的推荐对用户来说没有什么价值，因为即便在没有推荐系统的情况下，流向的项目也很容易被找到（甚至难以避免），因此一个好的推荐项目列表也应该包括那些用户自己本身无法找到的隐藏项目[35]。对于这个问题的解决办法有：直接增加推荐列表的多样性[36-38]和使用混合的推荐算法[39]</p></li>\n<li><p>攻击的脆弱性 受推荐系统在电子商务领域重大的经济利益的驱动，一些心怀不轨的用户通过提供一些虚假恶意的信息，故意增加或者压制某些商品被推荐的可能性[44]。从阻止恶意评估进入系统到复杂的抵抗推荐技术[41]，有大量的工具可以防止这样的行为。然而，这并不是一件容易的事情，因为随着防作弊的工具的升级，攻击者的策略也越来越先进。例如，Burke等人[42]引入了八个攻击策略，进一步可以分为四个类：基本攻击（包括随机和平均攻击），低认知攻击，核攻击和知情攻击。（basic attack, low-acknowledge attack, nuke attack and informed attack.需要看引文来翻译）</p></li>\n<li><p>时间的价值（好像是讲兴趣漂移问题） 一个真实用户的兴趣是和时间尺度相关的（举例来说，短期感兴趣与旅行计划相关，长期兴趣和居住地或者政治相关），大多数的推荐算法评估的时候都忽略了时间的影响。旧的想法是否会随着时间衰减，怎么衰减，以及用户评估和项目相关性中的典型临时模式是什么，这些都还需要持续的研究</p></li>\n<li><p>推荐的评估 虽然我们有很多不同的指标（见第3.4节），但是如何根据给定的情况和任务选择最好的指标仍然是一个悬而未决的问题。不同推荐算法的比较也存在问题的，因为不同的算法可以简单地解决不同的任务，最后，推荐系统的整体用户体验（包括用户对推荐结果的满意程度和用户对系统的信任）难以在“离线”评估中进行测量。因此，在推荐系统中，实证用户的研究仍然是一个受欢迎的反馈来源。</p></li>\n<li><p>用户界面 实践表明，为了促进用户接受推荐结果，推荐过程需要透明化：用户明白为什么特定的项目被推荐给他们。除此之外，通常潜在的感兴趣项目列表会很长，因此它需要简单的方式来展现，并且可以轻松的通过他去浏览由不同方法给出的推荐结果。</p></li>\n</ol>\n<p>除了以上的长期挑战，推荐系统近期出现了许多新颖的问题，由于相关科学的方法论的发展，特别是网络分析的新工具，科学家开始考虑网络结构对推荐的影响，以及如何利用已知的结构特征来改进推荐。例如，Huang等人[47]分析了消费者-商品网络，并提出了一种改进的推荐算法，这种算法偏向增强局部聚类属性的边。Sahebi等[48]设计了一种利用社区结构的改进算法。新技术的进步和传播也带来新的挑战。例如，配备GPS的手机已经成为主流，互联网的被普遍的接入，因此基于位置的推荐现在是可行的并且越来越显有意义，精准的推荐要求人类的运动的高可预测性和定量方式来定义地点和人之间的相似之处。最后，智能推荐系统应考虑不同人群的不同行为模式。例如，新用户倾向于访问非常受欢迎的项目并选择类似的项目，而老用户通常具有更具体的兴趣[53,54]，并且用户在低风险（例如收集书签，下载音乐等）和高风险（例如购买电脑，租房等）活动之间的行为差​​异很大。</p>\n<p>其实可以直接看周涛老师的一篇中文论文 <a href=\"http://blog.sciencenet.cn/blog-3075-588779.html\" target=\"_blank\" rel=\"noopener\">《个性化推荐的十大挑战》</a>，里面讲的更加具体，虽然推荐系统经过了这么多年的发展，但是对现在的推荐系统依旧面临着文中的问题。</p>\n<h3 id=\"主题和问题的定义\">主题和问题的定义</h3>\n<p>我们在本章中简要回顾一下在推荐系统研究中有用的基本概念。</p>\n<h4 id=\"图\">1. 图</h4>\n<p>网络分析是揭示许多复杂系统组织原理的通用工具[5-9]。网络是一组元素（称为节点或顶点），它们之间具有连接（称为边或链接）。许多社会，生物，技术和信息系统可以被描述为具有代表个人或组织的节点和捕获其交互的边缘的网络。 网络研究，即数学文献中的图论，具有悠久的历史，从18世纪欧拉所解决的古典柯尼斯堡桥梁问题开始[57]。用数学的定义，网络<span class=\"math inline\">\\(G\\)</span>是一个有序的不相交的二元组集合<span class=\"math inline\">\\((V,E)\\)</span>其中<span class=\"math inline\">\\(V\\)</span>是节点的集合<span class=\"math inline\">\\(E\\)</span>是边的集合。在一个无向网络中，一条连接节点<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>的边表示为<span class=\"math inline\">\\(x \\leftrightarrow y\\)</span>,<span class=\"math inline\">\\(x \\leftrightarrow y\\)</span>和<span class=\"math inline\">\\(y \\leftrightarrow x\\)</span>代表的是同一条边,在一个有向网络中，边是一个关于节点的有序二元组，<span class=\"math inline\">\\(x\\rightarrow y\\)</span> 代表由<span class=\"math inline\">\\(x\\)</span>指向<span class=\"math inline\">\\(y\\)</span>的一条边，边<span class=\"math inline\">\\(x\\rightarrow y\\)</span> 和<span class=\"math inline\">\\(y\\rightarrow x\\)</span>是不同的，并且可以同时存在的。除非另有说明，否则我们假设网络不包含自环（连接节点到其自身的“边”）或连接同一对节点的多边（多个“边”）。在多网络（multinetwork）中，允许两个循环和多边。</p>\n<p>在无向网络<span class=\"math inline\">\\(G(V，E)\\)</span>中，如果<span class=\"math inline\">\\(x\\leftrightarrow y \\in E\\)</span>，则两个节点<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>被认为是彼此相邻的。节点<span class=\"math inline\">\\(x\\)</span>的邻域节点集合，或者说<span class=\"math inline\">\\(x\\)</span>邻居集合由<span class=\"math inline\">\\(\\Gamma_{x}\\)</span>来表示,节点<span class=\"math inline\">\\(x\\)</span>的度定义为<span class=\"math inline\">\\(k_{x}=|\\Gamma_{x}|\\)</span>.度分布<span class=\"math inline\">\\(P(k)\\)</span>定义为随机选择的节点的度为<span class=\"math inline\">\\(k\\)</span>的概率.在一个均匀的网站，每一个节点有着相同的度<span class=\"math inline\">\\(k_{0}\\)</span>，所<span class=\"math inline\">\\(P_{k}=\\delta_{k,k_{0}}\\)</span>,在经典的Erdös–Rényi随机网络中，其中每对节点以给定的概率<span class=\"math inline\">\\(p\\)</span>连接生产边，其度分布满足二项式分布。<span class=\"math display\">\\[P(k)={N-1 \\choose k}p^{k}(1-p)^{n-1-k} \\quad \\quad \\quad (1)\\]</span>其中<span class=\"math inline\">\\(N=|V|\\)</span>是网络中节点的数量。这样的分布有一个以平均度<span class=\"math inline\">\\(\\bar x = p(N-1)\\)</span>表示的特征量表.在上个世纪末，研究人员转而对大规模实际网络进行调查，结果发现他们的度分布通常跨越几个数量级，大致遵循幂律形式<span class=\"math display\">\\[P(k)\\sim k^{-\\gamma} \\quad \\quad \\quad (2) \\]</span>其中<span class=\"math inline\">\\(\\gamma\\)</span>为正指数，通常位于2和3之间[5]，这种网络被称为无标度网络，因为他们缺乏度的特征尺度，幂律函数<span class=\"math inline\">\\(P(k)\\)</span>是与规模无关的。注意，实践数据中的幂律分布的检测需要固定的统计工具[62,63]。 对于有向网络，由<span class=\"math inline\">\\(k^{out}\\)</span>表示的节点<span class=\"math inline\">\\(x\\)</span>的出度，是从x开始的边的数量，入度<span class=\"math inline\">\\(k^{in}\\)</span>是以x结束的边的数量。 有向网络的进度和出度分布通常彼此不同。</p>\n<p>一般来说，如果一个网络的高度节点倾向于与高度节点连接，而低度节点倾向于与低度节点连接，那么它被认为是同配assortative的（如果情况相反，那就是异配的)。 该度-度相关性可以由最近邻节点门的平均度[64,65]或皮尔逊系数的变体称为分类系数[66,67]来表征。 分类系数<span class=\"math inline\">\\(r\\)</span>在<span class=\"math inline\">\\(-1≤r≤1\\)</span>的范围内。如果<span class=\"math inline\">\\(r&gt; 0\\)</span>，网络是同配的; 如果<span class=\"math inline\">\\(r &lt;0\\)</span>，则网络是异配的。 请注意，该系数对度非均匀性（heterogeneous degree ）敏感。 例如，无论网络的连接模式如何，r在具有非常非均匀性度分布的网络（例如，因特网）中将为负值[68]。</p>\n<p>连接两个节点的路径中的边数被称为路径的长度，两个节点之间的距离被定义为连接它们的最短路径的长度。 网络的直径是所有节点对之间的最大距离，平均距离是所有节点对上的平均距离平均值<span class=\"math display\">\\[\\bar d = \\frac{1}{N(N-1)}\\sum_{x \\neq y}d_{x,y} \\quad \\quad \\quad (3) \\]</span>其中<span class=\"math inline\">\\(d_{x,y}\\)</span>是<span class=\"math inline\">\\(x\\)</span>和<span class=\"math inline\">\\(y\\)</span>之间的距离.许多真实网络显示出所谓的小世界现象：它们的平均距离不会比网络大小的对数增长得快[70,71]。</p>\n<p>三元聚类在社会互动系统中的重要性的认知已经超过100多年[72]。 在社交网络分析中[73]，这种聚类称为传递性，定义为网络中三角形总数与相连节点的三元组总数之比的三倍。 1998年，Watts和Strogatz [71]提出了一个类似的指数来量化三元聚类，称为聚类系数。 对于给定的节点<span class=\"math inline\">\\(x\\)</span>，该系数被定义为<span class=\"math inline\">\\(x\\)</span>的邻居之间边的数量与邻居对的数量的比率，<span class=\"math display\">\\[c_x=\\frac{e_x}{\\frac{1}{2}k_x(k_x)-1} \\quad \\quad \\quad (4) \\]</span>其中<span class=\"math inline\">\\(e_x\\)</span>表示节点<span class=\"math inline\">\\(x\\)</span>的<span class=\"math inline\">\\(k_x\\)</span>个邻居之间的边数量（该定义仅在<span class=\"math inline\">\\(k_x&gt; 1\\)</span>时有意义）。 网络聚类系数被定义为<span class=\"math inline\">\\(k_x&gt; 1\\)</span>的所有<span class=\"math inline\">\\(x\\)</span>的<span class=\"math inline\">\\(c_x\\)</span>的平均值。也可以将聚类系数定义为网络中三角形数<span class=\"math inline\">\\(\\times 3\\)</span>与连接的三元组顶点数之比，有时也被称为“传递三元组的分数(‘fraction of transitive triples’)”[7]。 请注意，这两个定义可以给出完全不同的结果。</p>\n<p>图1说明了简单无向网络的上述定义。 有关网络测量的更多信息，我们鼓励读者去参考关于网络特征的文章[74]。</p>\n<p><img src=\"/images/fig1.png\" /> 图1. 一个拥有6个节点7条边的简单无向网络，节点的度分别为<span class=\"math inline\">\\(k_1=1,k_2=k_5=3,k_3=k_4=k_6=2\\)</span>,对应的节点的度分布<span class=\"math inline\">\\(p(1)=\\frac{1}{6},p(2)=\\frac{1}{2},p(3)=\\frac{1}{3}\\)</span>,网络的直径和平均平均距离为<span class=\"math inline\">\\(d_{max}=3,d=1.6\\)</span>,聚类系数为<span class=\"math inline\">\\(c_2=\\frac{1}{6},c_3=c_4=0,c_5=\\frac{1}{3},c_6=1\\)</span>,平均聚类系数为<span class=\"math inline\">\\(C=0.3\\)</span></p>\n<h4 id=\"二部图和超图\">2. 二部图和超图</h4>\n<p>如果一个网络<span class=\"math inline\">\\(G(V,E)\\)</span>满足分割为<span class=\"math inline\">\\((V_1,V_2)\\)</span>后，<span class=\"math inline\">\\(V_1\\cup V_2=V\\)</span>并且<span class=\"math inline\">\\(V_1\\cap V_2=\\emptyset\\)</span>，每一条边由一个<span class=\"math inline\">\\(V_1\\)</span>和一个<span class=\"math inline\">\\(V_2\\)</span>中的节点连接而成,那么这就是一个二部图。许多真实系统自然地被模拟为二部图，比如，由化学物质和化学反应组成的代谢网络[75]，由行为和行为者组成的协作网络[76]，由个人电脑和电话号码[77]的互联网电话网络等等。我们专注于一类特殊的二分网络，称为基于网络的用户商品网络[53]，它们代表在线服务网站中的用户和商品之间的相互影响，例如在Delicious.com中的书签集合以及在amazon.com上购买的书籍。我们将在后面看到，这些网络描述了推荐系统的基本结构。 基于Web的用户商品网络是逐渐演进的，其中节点和链接逐渐被添加。 相比之下，这不可能发生在例如作者合作网络（例如，在发布之后无法将作者添加到科学论文）。</p>\n<p>大多数的基于web的用户商品网络有着共同的结构属性，他们的（object-degree）商品度分布遵循幂律式形式$P(k)k^{-} $,对于互联网电影数据库（IMDb）来说 <span class=\"math inline\">\\(\\gamma \\approx 1.6\\)</span>[78],音乐共享站点audioscrobbler.com的 <span class=\"math inline\">\\(\\gamma \\approx 1.8\\)</span> [79]，对于电子商务网站amazon.com [53] <span class=\"math inline\">\\(\\gamma \\approx 2.3\\)</span>；对于书签共享网站delicious.com来说 <span class=\"math inline\">\\(\\gamma \\approx 2.5\\)</span>。用户度分布的形式通常在指数和幂律之间[53]，并且可以很好地拟合Weibull分布分布[27]（文献中也称为拉伸指数分布[80]）<span class=\"math display\">\\[P(k)=k^{\\mu-1}exp[-(k/k_0)^\\mu] \\quad \\quad \\quad (5) \\]</span>其中<span class=\"math inline\">\\(k_0\\)</span>是常数，<span class=\"math inline\">\\(\\mu\\)</span>是拉伸指数。 用户和商品之间的连接（边）表现出一种异配（disassortative）混合模式[53,78]。 二部图定义的简单扩展是所谓的多部图。对于一个r-partite的图，他存在r个节点集合<span class=\"math inline\">\\(V_1,V_2...V_r\\)</span>，并<span class=\"math inline\">\\(V=V_1 \\cup V_2 \\cup...\\cup V_r,V_i\\cap V_j=\\emptyset ,其中i\\neq j\\)</span>，并且对于所有的节点集合<span class=\"math inline\">\\(V_i\\)</span>，不存在同一集合的节点之间的边。多部网络已经在协作标签系统（文献也称众分类法Folksonomies）[81-84]中找到了应用，用户可以在其中为在线资源分配标签，例如flickr.com中的照片，CiteULike.com中的参考文献和delicious.com中的书签等在线资源分配标签。</p>\n<p>请注意，三部网络表示形式中丢失了一些信息。例如，给定一条连接资源和标签的边，我们不知道哪个用户（或用户们）对此边有贡献。对于这个问题，超图[85]可以用来给出协作标签系统的完整结构的精确表示。在超图<span class=\"math inline\">\\(H(V,E)\\)</span>中，超集<span class=\"math inline\">\\(E\\)</span>是<span class=\"math inline\">\\(V\\)</span>的幂集的子集，即V的所有子集的集合。 因此，边<span class=\"math inline\">\\(e\\)</span>可以连接多个节点。 类似于普通网络，超图中的节点度被定义为与节点相邻的超节点的数量，并且两个节点之间的距离被定义为连接这些节点的最小数量的超边。 聚类系数[82,86]和社区结构[86,87]也可以按照普通网络中的定义进行定义和量化。 请注意，超图和二分网络之间存在一对一的对应关系。给定超图<span class=\"math inline\">\\(H（V，E）\\)</span>，相应的二分网络<span class=\"math inline\">\\(G（V^\\prime，E^\\prime）\\)</span>包含两个节点集，如<span class=\"math inline\">\\(V^\\prime= V\\cup E\\)</span>，而<span class=\"math inline\">\\(x \\in V\\)</span>与<span class=\"math inline\">\\(Y \\in E\\)</span>连接，当且仅当<span class=\"math inline\">\\(x \\in Y\\)</span>（参见图2作为说明）。</p>\n<p><img src=\"/images/fig2.png\" />图2. 超图（a）和二分网络（b）之间的一一对应的图示。 有三个超边，X = {1,2,4}，Y = {4,5,6}和Z = {2,3,5,6}。</p>\n<p>超图已经在铁磁动力学[88,89]，人口分层[90]，蜂窝网络[91]，学术团队形成[92]等许多领域中得到应用。 在这里，我们更关心协作标签系统的超图表示[86,93,94]，其中每个超边连接三个节点（由图3中的三角形表示），用户 <span class=\"math inline\">\\(u\\)</span> ，资源 <span class=\"math inline\">\\(r\\)</span> 和标签 <span class=\"math inline\">\\(t\\)</span> ， 表示用户 <span class=\"math inline\">\\(u\\)</span> 把标签 <span class=\"math inline\">\\(t\\)</span> 给了资源 <span class=\"math inline\">\\(r\\)</span> 。 资源可以由许多用户收集，并且由用户给出几个标签，标签可以与许多资源相关联，这就导致了小世界超图[86,94]（图3显示了基本单元和广泛的描述）此外，协同标签系统的超图已被证明是高度集群化的，它具有长尾度分布和社区结构[86,94]。[94]可以找到超图的演变模型。</p>\n<p><img src=\"/images/fig3.png\" />图3. 协同标签网络的超图。 （左）一个类似三角形的超边[93]，其中包含三种类型的顶点，一个蓝色圆圈，一个绿色矩形和一个棕色三角形，分别表示用户，资源和标签。 （右）描述由两个用户组成，四个资源和三个标签的超图。 以用户<span class=\"math inline\">\\(U_2\\)</span>和资源<span class=\"math inline\">\\(R_1\\)</span>为例，测量值表示为：（i）<span class=\"math inline\">\\(U_2\\)</span>已经参与在六个超边，这意味着它的超度是6; （ii）<span class=\"math inline\">\\(U_2\\)</span>直接连接到三个资源和三个标签。 按照公式 （6），认为它最大可能有<span class=\"math inline\">\\(3 * 3 = 9\\)</span> 超边。 因此，其聚类系数等于<span class=\"math inline\">\\(6/9=0.667\\)</span>，其中6是其超度; 相对而言，如定义按式（7），其聚类系数为<span class=\"math inline\">\\(D_h(U2)= \\frac {12-6} {6-4} = 0.75\\)</span>; （iii）从<span class=\"math inline\">\\(U_2\\)</span>到<span class=\"math inline\">\\(R_1\\)</span>的最短路径为<span class=\"math inline\">\\(U_2-T_1-R_1\\)</span>，表示<span class=\"math inline\">\\(U2\\)</span>与<span class=\"math inline\">\\(R_1\\)</span>之间的距离为2</p>\n<p>一般来说，以复杂科学角度的评估超图可以从以下几点展开（图3给出这些的详细描述）：</p>\n<ol style=\"list-style-type: decimal\">\n<li>超度：超图中的节点的度可以自然地定义为与其相邻的超边的数量。</li>\n<li>超度分布：定义为每个超度占据的比例，其中超度定义为常规节点参与的超边的数量。</li>\n<li><p>聚类系数：定义为节点的实际超边数量与可能的超边数量的比例[82]。 例如，用户的聚类系数<span class=\"math inline\">\\(C_u\\)</span>定义为<span class=\"math display\">\\[C_u=\\frac{k_0}{R_uT_u} \\quad \\quad \\quad （6）\\]</span>其中<span class=\"math inline\">\\(k_u\\)</span>是用户<span class=\"math inline\">\\(u\\)</span>的超度，<span class=\"math inline\">\\(R_u\\)</span>是用户<span class=\"math inline\">\\(u\\)</span>收集的资源的数量，<span class=\"math inline\">\\(T_u\\)</span>是用户<span class=\"math inline\">\\(u\\)</span>拥有的标签的数量。一个较大的<span class=\"math inline\">\\(C_u\\)</span>表示你有更相似的资源主题，这也可能表明你更专注于个性化或特殊的话题，而较小的<span class=\"math inline\">\\(C_u\\)</span>可能表明他/他有更多的兴趣。也可以用类似的定义来衡量资源和标签的聚类系数。 Zlati¢等人提出了一种名为超边密度的指标[86]。以用户节点<span class=\"math inline\">\\(u\\)</span>为例，它们将<span class=\"math inline\">\\(u\\)</span>的协调数(the coordination number)定义为 <span class=\"math inline\">\\(z(u)= R_u + T_u\\)</span>。对于一个给定的<span class=\"math inline\">\\(k(u)\\)</span>，配对数最大为 <span class=\"math inline\">\\(Z_{max}(u)=2K(u)\\)</span> ，对于 <span class=\"math inline\">\\(n(n-1)&lt;k(u)&lt;n^2\\)</span> 情况最小值是 <span class=\"math inline\">\\(Z_{min}(u)=2n\\)</span> ，对于 <span class=\"math inline\">\\(n^2&lt;k(u)&lt;n(n+1)\\)</span> 情况最小值是 <span class=\"math inline\">\\(Z_{min}(u)=2n+1\\)</span> ，显然，一个局部树结构导致最大协调数，而最大重叠对应于最小协调数。 因此，他们将超边密度定义为[86]：<span class=\"math display\">\\[D_h(u)=\\frac{Z_{max}(u)-Z(u)}{Z_{max}(u)-Z_{min}(u)} \\quad ,\\quad 0 \\le D_h(u) \\le 1 \\quad \\quad \\quad （7）\\]</span> 资源和标签的超边密度定义是相同的。实证分析表明，这两个指标都表现出高聚类行为[82,86]。 协同标签网络超图的研究刚刚展开，如何正确量化聚类行为，节点之间的相关性和相似性以及社区结构仍然是一个开放的问题。</p></li>\n<li><p>平均距离：定义为整个网络中两个随机节点之间的平均最短路径长度。</p></li>\n</ol>\n<h4 id=\"推荐系统\">3. 推荐系统</h4>\n<p>推荐系统使用输入数据来预测其用户的潜在未来的喜好和兴趣。用户过去的评价通常是输入数据的重要组成部分。令<span class=\"math inline\">\\(M\\)</span>为用户数，令<span class=\"math inline\">\\(N\\)</span>为可评估和推荐的所有对象的数量。请注意，对象只是一个通用术语，可以表示书籍，电影或任何其他类型的消费内容。为了保持与标准术语的一致性，我们有时使用具有相同含义的词-“项目”。为了使符号更清楚，我们在枚举用户现在索引为拉丁字母 <span class=\"math inline\">\\(i\\)</span> 和 <span class=\"math inline\">\\(j\\)</span> ,以及枚举对象索引时限制为希腊字母 <span class=\"math inline\">\\(\\alpha\\)</span> 和 <span class=\"math inline\">\\(\\beta\\)</span>。用户 <span class=\"math inline\">\\(i\\)</span> 对对象 <span class=\"math inline\">\\(\\alpha\\)</span> 的评价/打分表示为<span class=\"math inline\">\\(r_{i\\alpha}\\)</span>。这个评估通常是以整数评分量表（比如亚马逊的五星级制）-在这种情况下，我们会认为是一个显明的评级。请注意，二进制评级（如/不喜欢或好/坏）的常见情况也属于此类别。当只存在收集对象（如在书签共享系统中）或简单地消费（如在没有评级系统的在线报纸或杂志），或者当“喜欢”是唯一可能的表达（如在Facebook上）时，我们只有一元评级。在这种情况下，<span class=\"math inline\">\\(r_{i\\alpha}=1\\)</span> 表示收集/消耗/喜欢的对象，<span class=\"math inline\">\\(r_{i\\alpha}=0\\)</span> 表示不存在的评估（参见图4）。推测用户对评级的置信区间是一个重要的工作，特别是对于二元或一元评级。用户的访问行为信息可能带来一些帮助，例如，可以通过观看电视节目的时间来估计用户的置信区间(喜好程度)，并且借助于该信息，可以提高推荐质量[95]。即使我们有明确的评级，这并不意味着我们知道用户如何并为什么做出这样的打分-他们是否具有数值上的评分标准，或者只是使用其来表现排序？最近的证据[96]在一定程度上是支持后者的。</p>\n<p><img src=\"/images/fig4.png\" />图4. 由五个用户和四本书组成的推荐系统的图示。 每个推荐系统包含的用户和对象之间的基本信息都可以由二部图来表示。 该图还展示了在推荐算法的设计中经常被利用的一些附加信息，包括用户信息，对象的属性和对象内容。</p>\n<p>推荐系统的目标是为用户提供个性化的“推荐”对象。 因此，可以对那些用户不知道的对象预测用户的评价或者是计算推荐分数。 被预测为高评价或高推荐分数的对象便构成了呈现给目标用户的推荐列表。 推荐系统有着广泛的性能指标体系（见第3.4节）。 推荐系统的惯用分类如下[15]：</p>\n<ol style=\"list-style-type: decimal\">\n<li>基于内容的推荐：推荐的对象是内容类似于目标用户先前喜欢的对象内容的对象。 我们在4.2.3节叙述。</li>\n<li>协同推荐：根据大量用户过去的评估，选择推荐对象。 在表2中给出一个例子。它们可以分为：\n<ul>\n<li>基于记忆的协同过滤：推荐对象来自于与目标用户有相似偏好的用户喜欢的（user-base），或者是和目标用户之前喜欢的对象相似的对象（item-base）。我们将在第四章节（标准的基于相似的方法）和第七章节（引入社交网络的方法）来具体的阐述。</li>\n<li>基于模型的协同过滤：推荐对象选自训练好的识别输入数据的模式的模型，我们将在第五章（降维方法）和第六章（基于信息传播理论的方法）具体来阐述。</li>\n</ul></li>\n<li>混合方法：这类算法通过结合协同方法和基于内容的方法或者是混合多种不同的协同方法。我们将在8.4章节来具体的阐述</li>\n</ol>\n<h4 id=\"推荐系统评估指标\">4. 推荐系统评估指标</h4>\n<p><em>其实可以参考看 2012 吕琳媛 <a href=\"http://blog.sciencenet.cn/home.php?mod=attachment&amp;id=20078\" target=\"_blank\" rel=\"noopener\">推荐系统评价指标综述</a></em></p>\n<p>给定目标用户<span class=\"math inline\">\\(i\\)</span>，推荐系统将对所有<span class=\"math inline\">\\(i\\)</span>未收集的对象进行排序，并推荐排名最高的对象。 为了评估推荐算法，数据通常分为两部分：训练集<span class=\"math inline\">\\(E^T\\)</span>和测试组<span class=\"math inline\">\\(E^P\\)</span>。 训练集被视为已知信息，但是不允许使用来自测试组的信息来推荐。在本节中，我们简要回顾了用于衡量推荐质量的基本指标。如何选择特定指标（或指标）来评估推荐性能，这取决于系统应该实现的目标。当然，任何推荐系统的最终评估是由用户的判断决定的。</p>\n<ol style=\"list-style-type: decimal\">\n<li>精度指标类</li>\n</ol>\n<p><strong><em>评分精度指标:</em></strong> 推荐系统的主要目的是预测用户未来的喜好和兴趣。 存在许多指标来评估推荐的各个方面性能。 两个著名的指标：均值绝对误差（MAE）和均方根误差（RMSE）用于测量预测评分与真实评分的接近程度。 如果$ r_{i}$ 是用户<span class=\"math inline\">\\(i\\)</span> 对对象 <span class=\"math inline\">\\(α\\)</span> 的真实评分，则<span class=\"math inline\">\\(\\widetilde r_{i\\alpha}\\)</span> 是预测的评分，<span class=\"math inline\">\\(E^P\\)</span>是隐藏的用户商品评分的集合，MAE和RMSE被定义为<span class=\"math display\">\\[MAE = \\frac{1}{|E^p|} \\sum_{(i,\\alpha)\\in E^p} |r_{i\\alpha} - \\widetilde r_{i\\alpha}| \\quad \\quad \\quad (8) \\]</span> <span class=\"math display\">\\[RMSE = \\lgroup \\frac{1}{|E^p|} \\sum_{(i,\\alpha)\\in E^p} (r_{i\\alpha} - \\widetilde r_{i\\alpha})^2 \\rgroup ^{1/2} \\quad \\quad \\quad (9) \\]</span> 较低的MAE和RMSE对意味着较高的预测精度。 由于RMSE在求和之前对误差进行平方，所以往往会更大程度地惩罚大错误。 由于这些指标平等对待所有评分，无论他们在推荐列表中的位置如何，所以它们对于某些常见任务，如找到可能被用户偏好的的少量对象（Finding Good Objects）来说并不是最佳的。 然而，由于其简单性，RMSE和MAE被广泛用于推荐系统的评估。</p>\n<p><strong><em>评级和排名相关性:</em></strong> 评估预测精度的另一种方法是计算预测值和真实值之间的相关性。 有三个着名的相关性测度，即皮尔逊相关系数(the Pearson product-moment correlation)[97]，斯伯曼/斯皮尔曼相关系数 (the Spearman correlation)[98] 和 肯德尔相关系数(Kendall’s Tau )[99]。 Pearson相关性测量两组评分之间线性相关性的程度。它被定义为</p>\n<p><span class=\"math display\">\\[PCC = \\frac{\\sum_{a}(\\widetilde r_{\\alpha} - \\bar{\\widetilde r} )(r_\\alpha - \\bar r)}{\\sqrt{\\sum_\\alpha(\\widetilde r_{\\alpha}- \\bar{\\widetilde r} )^2}  {\\sqrt{\\sum_\\alpha(r_\\alpha - \\bar r)^2}}}\\]</span></p>\n<p>其中<span class=\"math inline\">\\(r_\\alpha\\)</span> 和 <span class=\"math inline\">\\(\\widetilde r_\\alpha\\)</span> 分布死真实的和预测的评分。Spearman相关系数 <span class=\"math inline\">\\(\\rho\\)</span> 以与Pearson相同的方式定义，除了<span class=\"math inline\">\\(r_\\alpha\\)</span> 和<span class=\"math inline\">\\(\\widetilde r_\\alpha\\)</span> 被各个对象的排序代替。与Spearman相似，Kendall也评估了评分排名一致性程度。它被定义为 <span class=\"math inline\">\\(\\tau = (C-D)/(C+D)\\)</span>其中C是系统以正确的排序顺序预测的对象的数量，D是系统以错误的顺序预测的不一致的数量。当真实和预测的排名相同时，<span class=\"math inline\">\\(\\tau = 1\\)</span>，当它们完全相反时，<span class=\"math inline\">\\(\\tau = -1\\)</span>。 当真实排名或预测排名有并列情况出现时，在[13]中提出了Kendall的的变体， <span class=\"math display\">\\[\\tau = \\frac {(C-D)}{\\sqrt{(C+D+S_T)(C+D+S_P)}}\\]</span>其中<span class=\"math inline\">\\(S_T\\)</span>是真实评分中相同的对象的数量，<span class=\"math inline\">\\(S_P\\)</span>是预测评分相同的对象的数量。Kendall 指标对连续有序对象的任何位置交换给予相等的权重，无论它在哪里发生。 但是，不同地点的交换，例如在1号到2号之间，100到101号之间的交换可能会有不同的影响。 因此，可以对真实排名的顶部给予对象更大的权重来改进指标。与Kendall类似，最初由Yao[100]提出来的归一化基于距离的性能指标（NDPM）用来比较两种不同的弱排序，它是基于统计矛盾对<span class=\"math inline\">\\(C^-\\)</span>(2个排序不一致)和兼容对<span class=\"math inline\">\\(C^u\\)</span>(一个排序是平局，另外一个排序是在所有对象中明显偏向其中一个),值得注意的是，这些预测评分关联性指标都是只关注于预测排序值而不关注具体的预测评分值，所以它们都不适用于那些旨在为用户提供精确预测评分值的系统。假如用<span class=\"math inline\">\\(C\\)</span>表示用户实际评分中具有严格偏好差别的商品对个数，则NDMP指标定义为：<span class=\"math display\">\\[NDPM=\\frac{2C^-+C^u}{2C}\\]</span></p>\n<p><strong><em>分类准确度:</em></strong> 分类指标适用于诸如“寻找好对象”这样的任务，特别是当仅有隐含评分可用时（即，我们知道哪些对象受到用户的青睐，而不是他们具体喜欢多少）。当给出排序的对象列表时，推荐的阈值是不明确的或可变的。为了评估这种系统，一个受欢迎的指标是AUC（Area ROC Curve），其中ROC代表接收者操作特征曲线[101]（关于如何绘制ROC曲线见[13]）。 AUC尝试测量推荐系统如何能够成功地将相关对象（用户所赞赏的）与无关对象（所有其他对象）区分开来。计算AUC的最简单方法是将相关对象推荐的概率与不相关对象的概率进行比较。对于n个独立比较（每个比较指的是选择一个相关的和一个不相关的对象），如果有<span class=\"math inline\">\\(n^\\prime\\)</span>次相关对象分数高于不相关对象，<span class=\"math inline\">\\(n^{\\prime\\prime}\\)</span>次不相关对象和相关对象分数一致，根据[102]<span class=\"math display\">\\[AUC=\\frac{n^\\prime+0.5n^{\\prime\\prime}}{n} \\quad \\quad \\quad (13) \\]</span>如果所有的相关对象比不相关对象的分数高那么 <span class=\"math inline\">\\(AUC=1\\)</span>，意味着一个完美的推荐系统。对于一个随机排序的推荐列表 <span class=\"math inline\">\\(AUC=0.5\\)</span>,因此，AUC超过0.5的程度表示推荐算法识别相关对象的能力。类似于AUC是[103]中提出的所谓的排名分数。 对于给定的用户，我们测量该用户推荐列表中相关对象的相对排名：当有<span class=\"math inline\">\\(o\\)</span>个对象被推荐时，具有排名r的相关对象具有相对排名<span class=\"math inline\">\\(r/o\\)</span>。 通过对所有用户及其相关对象进行平均，我们获得平均排名得分RS-排名得分越小，算法的准确性越高，反之亦然。</p>\n<p>由于真正的用户通常仅关注推荐列表的顶部，所以更实际的方法是考虑漂亮在top-L位置前用户相关的对象的数量。基于此，精准率和召回率是最受欢迎的指标。 对于目标用户<span class=\"math inline\">\\(i\\)</span>，推荐的精确度和召回率$P_i(L) $ 和 <span class=\"math inline\">\\(R_i(L)\\)</span>被定义为<span class=\"math display\">\\[P_i(L)=\\frac{d_i(L)}{L} \\quad , \\quad  R_i(L)=\\frac{d_i(L)}{D_i}  \\quad \\quad \\quad (14)\\]</span>其中<span class=\"math inline\">\\(d_i(L)\\)</span>指在长度为L的推荐列表中相关的项目数量，<span class=\"math inline\">\\(D_i\\)</span>是所有的相关项目总数，对所有拥有至少一个相关对象的所有用户的精度和回召率做平均，我们可以得到平均精度和平均回召率<span class=\"math inline\">\\(P(L),R(L)\\)</span>，这些指标可以通过对随机产生的推荐结果进行对比，于是就有了增强版本的精度和回召率指标<span class=\"math display\">\\[e_P(L)=P(L)\\frac{MN}{D} \\quad , \\quad e_R(L)=R(L)\\frac{N}{L} \\quad \\quad \\quad (15)\\]</span>其中<span class=\"math inline\">\\(M\\)</span>和<span class=\"math inline\">\\(N\\)</span>分别是用户和商品的数量，<span class=\"math inline\">\\(D\\)</span>是所有相关商品的数量,通常精度回随着推荐列表长度L增加而下降，召回率随着L的增加而增长，我们可以把他们组合成一个和L弱相关的指标<span class=\"math inline\">\\(F_1\\)</span>-score。<span class=\"math display\">\\[F_1(L)=\\frac{2PR}{P+R}\\quad \\quad \\quad (16)\\]</span>许多其他组合精度和召回率的指标被用在信息检索的有效性，但是很少用在推荐系统中:平均精度，深度精度，R精度，互惠等级[106]，二进制偏好度量[107]。 每个组合指数的详细介绍和讨论可以在[108]中找到。</p>\n<ol start=\"2\" style=\"list-style-type: decimal\">\n<li>基于排序加权的指标</li>\n</ol>\n<p>现实生活中用户的耐心往往是有限的，一个人不太可能会不厌其烦地检查推荐列表中的所有商品，所以用户体验的满意度往往会受到用户喜欢的商品在推荐列表中位置的影响，这里介绍3个具有代表性的评价指标，更详细的信息参见文献[13]。</p>\n<p><strong><em>半衰期效用指标(half-life utility)[109]</em></strong> 是在用户浏览商品的概率与该商品在推荐列表中的具体排序值呈指数递减的假设下提出的，它度量的是推荐系统对一个用户的实用性也即是用户真实评分和系统默认评分值的差别。用户<span class=\"math inline\">\\(i\\)</span>的期望效用定义为：<span class=\"math display\">\\[HL_i=\\sum^n_\\alpha\\frac{max(r_{i\\alpha}-d,0)}{2^{(o_{i\\alpha}-1)/(h-1)}} \\quad \\quad \\quad (17)\\]</span> 推荐结果按照数<span class=\"math inline\">\\(\\widetilde r_{i\\alpha}\\)</span>降序排列，<span class=\"math inline\">\\(r_{i\\alpha}\\)</span>表示用户<span class=\"math inline\">\\(i\\)</span>对商品<span class=\"math inline\">\\(\\alpha\\)</span>的实际评分，而<span class=\"math inline\">\\(o_{i\\alpha}\\)</span>为商品<span class=\"math inline\">\\(\\alpha\\)</span>在用户<span class=\"math inline\">\\(i\\)</span>的推荐列表中的排名；<span class=\"math inline\">\\(d\\)</span>为默认评分(如说平均评分值)；<span class=\"math inline\">\\(h\\)</span>为系统的半衰期，也即是有50%的概率用户会浏览的推荐列表的位置。显然，当用户喜欢的商品都被放在推荐列表的前面时，该用户的半衰期效用指标达到最大值。通过计算有用户<span class=\"math inline\">\\(HL_i\\)</span>值的平均值，我们就得到了系统的整体效果。</p>\n<p><strong><em>折扣累计利润(discounted cumulative gain，DCG)[110]</em></strong> 对于长度为L的推荐列表，DGG定义为<span class=\"math display\">\\[DGG(b) = \\sum^b_n r_n+\\sum^L_{n=b+1}\\frac{r_n}{log_bn} \\quad \\quad \\quad (18)\\]</span>，其中<span class=\"math inline\">\\(r_n\\)</span>指排序中第n个项目的用户是否喜欢，<span class=\"math inline\">\\(r_n=1\\)</span>代表喜欢，<span class=\"math inline\">\\(r_n=0\\)</span>代表不喜欢，b是自由参数多设为2；DGG的主要思想是用户喜欢的商品被排在推荐列表前面比排在后面会更大程度上增加用户体验。</p>\n<p><strong><em>排序偏差准确率（Rank-biased precision）[108]</em></strong> 这个指标假设用户往往先浏览排在推荐列表的首位商品然后依次以概率<span class=\"math inline\">\\(p\\)</span>浏览下一个，以<span class=\"math inline\">\\(1-p\\)</span>的概率不再看此推荐列表。对于一个长队为L的推荐来说，RBP定义为<span class=\"math display\">\\[RBP=(1-p)\\sum^L_{n=1}r_nP^{n-1} \\quad \\quad \\quad (19)\\]</span>其中<span class=\"math inline\">\\(r_n\\)</span>和DCG相同,RBP和DCG类似，唯一的不同在于RBP把推荐列表中商品的浏览概率按等比数列递减，而DCG则是按照log调和级数形式。</p>\n<ol start=\"3\" style=\"list-style-type: decimal\">\n<li>多样性和新奇</li>\n</ol>\n<p>即便给用户成功推荐一个用户喜欢的项目，但是当项目是众人皆知（流行的）对用户来说的价值也是微乎其微。为了补充上面精度指标，几种多样性和新颖性指标 [35,39,111]在最近被提出，我在这里做一个介绍。</p>\n<p><strong><em>多样性</em></strong> 推荐系统的多样性是指被推荐项目之间的差异程度，在推荐系统中，多样性体现在以下两个层次，用户间的多样性(inter-user diversity)，衡量推荐系统对不同用户推荐不同商品的能力；另一个是用户内的多样性(intra-user diversity)，衡量推荐系统对一个用户推荐商品的多样性。用户间的多样性通过考虑用户推荐列表的种类来定义。对于用户i，j，可以用汉明距离来评估推荐列表的前L个项目差异性。<span class=\"math display\">\\[H_{ij}=1 - \\frac{Q_{ij}(L)}{L} \\quad \\quad \\quad (20)\\]</span>其中<span class=\"math inline\">\\(Q_{ij}(L)\\)</span>是用户<span class=\"math inline\">\\(i,j\\)</span>之间前<span class=\"math inline\">\\(L\\)</span>个推荐商品中相同商品的数量，如果2个列表完全一致<span class=\"math inline\">\\(Q_{ij}(L)=0\\)</span>，如果没有任何重叠则为<span class=\"math inline\">\\(Q_{ij}(L)=1\\)</span>。所有用户对的<span class=\"math inline\">\\(H_{ij}\\)</span>值的平均值就是系统的<span class=\"math inline\">\\(H(L)\\)</span>值，该值越大，则推荐系统给用户推荐的多样性越好</p>\n<p>将用户<span class=\"math inline\">\\(i\\)</span>的推荐商品表示为<span class=\"math inline\">\\(\\{o_1，o_2，...，o_L\\}\\)</span>，可以使用这些商品的相似度<span class=\"math inline\">\\(（o_\\alpha，o_\\beta）\\)</span>来测量用户内多样性（这种相似性可以直接从评分或对象元数据获取）[113]。 用户<span class=\"math inline\">\\(i\\)</span>推荐商品的平均相似度，<span class=\"math display\">\\[I_i(L)=\\frac{1}{L(L-1)} \\sum_{\\alpha \\neq \\beta } s(o_\\alpha，o_\\beta) \\quad \\quad \\quad (21)\\]</span>，同样，我们可以通过平均所有用户值来获得系统的用户内的多样性值<span class=\"math inline\">\\(I(L)\\)</span>，该值越小说明用户内的多样性越好。值得注意的是，通过避免推荐过度相似的对象，用户内推荐列表多样性可用于增强和改进推荐列表[37]。 可以通过在推荐列表[111]中引入对象排名的折扣函数来获得等级敏感版本。通过引入关于商品排序的折扣函数就可以获得排序敏感的版本(The rank-sensitive version can be obtained by introducing a discount function of the object’s rank in recommendation list [111].)[111]。</p>\n<p><strong><em>新颖性和惊喜性</em></strong> 推荐系统中的新颖性是指推荐对象与用户以前看过的不同之处。 量化算法产生新颖和意想不到的结果的能力的最简单的方法是测量推荐对象的平均受欢迎程度<span class=\"math display\">\\[N(L)=\\frac{1}{ML}\\sum^m_{i =1}\\sum_{\\alpha \\in O^i_R}K_\\alpha  \\quad \\quad \\quad (22)\\]</span>其中<span class=\"math inline\">\\(O^i_R\\)</span>是用户<span class=\"math inline\">\\(i\\)</span>的推荐列表,<span class=\"math inline\">\\(K_\\alpha\\)</span>是商品<span class=\"math inline\">\\(\\alpha\\)</span>的度(商品的流行性)，低流行性意味着推荐结果的高新颖性。另外一个可以用来评估推荐结果的惊喜性的指标通过计算自信息(self-information)[114]。对于一个商品<span class=\"math inline\">\\(\\alpha\\)</span>，一个随机选取的用户选到他的概率为$k_/ M $,所以自信息定义为 <span class=\"math display\">\\[U_\\alpha = \\log_2(M/K_\\alpha)  \\quad \\quad \\quad (23)\\]</span>可以通过将观察限制到目标用户，即计算目标用户的top-L商品的平均自我信息来定义基于用户相关的新颖性指标变体。对所有用户进行平均，我们获得了平均top-L惊喜值<span class=\"math inline\">\\(U(L)\\)</span>。通过类似的结果公式，在[111]中提出了一种基于发现的新颖性，通过考虑对象是随机用户已知或熟悉的概率。</p>\n<ol start=\"4\" style=\"list-style-type: decimal\">\n<li>覆盖率</li>\n</ol>\n<p>覆盖率指标是指算法向用户推荐的商品能够覆盖全部商品的比例。将所有推荐列表的前L个位置中的不同对象的总数表示为<span class=\"math inline\">\\(N_d\\)</span>，则<span class=\"math inline\">\\(L\\)</span>相关的覆盖率指标定义为<span class=\"math display\">\\[COV(L)=N_d/N\\]</span>低覆盖率表示该算法可以访问并仅推荐少量不同对象（通常是最受欢迎的），这往往导致很少的不同商品。相反，覆盖率较高的算法更有可能提供不同的推荐[115]。从这个观点来看，覆盖率也可以被认为是一种多样性度量。此外，覆盖率有助于更好地评估精度指标的结果[116]：推荐流行的对象可能具有高精度但低覆盖率。一个好的推荐算法应该将同时具有高精度和覆盖率。</p>\n<p>评估推荐系统的特定指标的选取取决于系统需要实现的目标。在实践中，可以为新的和有经验的用户分别指定不同的目标，这进一步使评估过程复杂化。为了更好的概述，表3总结了推荐系统评估指标。</p>\n<p>Table3. 推荐系统指标摘要。第三列表示度量的偏好（例如，更小的MAE意味着更高的评级精度）。第四列描述度量的范围。最后两列显示该度量是否从排名获得，以及是否取决于推荐列表L的长度。</p>\n<table>\n<thead>\n<tr class=\"header\">\n<th>名字</th>\n<th>符号</th>\n<th>偏好</th>\n<th>范围</th>\n<th>是否与排名相关</th>\n<th>是否依赖长度L</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td>MAE</td>\n<td><span class=\"math inline\">\\(MAE\\)</span></td>\n<td>Small</td>\n<td>Rating accuracy</td>\n<td>No</td>\n<td>No</td>\n</tr>\n<tr class=\"even\">\n<td>RMSE</td>\n<td><span class=\"math inline\">\\(RMSE\\)</span></td>\n<td>Small</td>\n<td>Rating accuracy</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr class=\"odd\">\n<td>Pearson</td>\n<td><span class=\"math inline\">\\(PCC\\)</span></td>\n<td>Large</td>\n<td>Rating correlation</td>\n<td>No</td>\n<td>No</td>\n</tr>\n<tr class=\"even\">\n<td>Spearman</td>\n<td><span class=\"math inline\">\\(\\rho\\)</span></td>\n<td>Large</td>\n<td>Rating correlation</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr class=\"odd\">\n<td>Kendall’s Tau</td>\n<td><span class=\"math inline\">\\(\\tau\\)</span></td>\n<td>Large</td>\n<td>Rating correlation</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr class=\"even\">\n<td>NDPM</td>\n<td><span class=\"math inline\">\\(NDPM\\)</span></td>\n<td>Small</td>\n<td>Ranking correlation</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr class=\"odd\">\n<td>Precision</td>\n<td><span class=\"math inline\">\\(P(L)\\)</span></td>\n<td>Large</td>\n<td>Classification accuracy</td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr class=\"even\">\n<td>Recall</td>\n<td><span class=\"math inline\">\\(R(L)\\)</span></td>\n<td>Large</td>\n<td>Classification accuracy</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr class=\"odd\">\n<td>F1-score</td>\n<td><span class=\"math inline\">\\(F1(L)\\)</span></td>\n<td>Large</td>\n<td>Classification</td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr class=\"even\">\n<td>AUC</td>\n<td><span class=\"math inline\">\\(AUC\\)</span></td>\n<td>Large</td>\n<td>accuracy Classification</td>\n<td>No</td>\n<td>No</td>\n</tr>\n<tr class=\"odd\">\n<td>Ranking score</td>\n<td><span class=\"math inline\">\\(RS\\)</span></td>\n<td>Small</td>\n<td>accuracy Ranking</td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr class=\"even\">\n<td>Half-life utility</td>\n<td><span class=\"math inline\">\\(HL(L)\\)</span></td>\n<td>Large</td>\n<td>accuracy Satisfaction</td>\n<td>No</td>\n<td>No</td>\n</tr>\n<tr class=\"odd\">\n<td>Discounted Cumulative Gain</td>\n<td><span class=\"math inline\">\\(DCG(b, L)\\)</span></td>\n<td>Large</td>\n<td>Satisfaction and precision</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr class=\"even\">\n<td>Rank-biased Precision</td>\n<td><span class=\"math inline\">\\(RBP(p,L)\\)</span></td>\n<td>Large</td>\n<td>Satisfaction and precision</td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr class=\"odd\">\n<td>Hamming distance</td>\n<td><span class=\"math inline\">\\(H(L)\\)</span></td>\n<td>Large</td>\n<td>Inter-diversity</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr class=\"even\">\n<td>Intra-similarity</td>\n<td><span class=\"math inline\">\\(I(L)\\)</span></td>\n<td>Small</td>\n<td>Intra-diversity</td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr class=\"odd\">\n<td>Popularity</td>\n<td><span class=\"math inline\">\\(N(L)\\)</span></td>\n<td>Small</td>\n<td>Surprisal and novelty</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n<tr class=\"even\">\n<td>Self-information</td>\n<td><span class=\"math inline\">\\(U(L)\\)</span></td>\n<td>Large</td>\n<td>Unexpectedness</td>\n<td>Yes</td>\n<td>No</td>\n</tr>\n<tr class=\"odd\">\n<td>Coverag</td>\n<td><span class=\"math inline\">\\(COV(L)\\)</span></td>\n<td>Large</td>\n<td>Coverage and diversity</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n</tbody>\n</table>\n<div class=\"figure\">\n<img src=\"/images/Summary-recommendation-metrics.png\" />\n\n</div>\n<h3 id=\"基于相似的方法\">基于相似的方法</h3>\n<h3 id=\"降维技术\">降维技术</h3>\n<h3 id=\"基于传播的方法\">基于传播的方法</h3>\n<h3 id=\"社交过滤\">社交过滤</h3>\n<h3 id=\"元方法\">元方法</h3>\n<h3 id=\"性能评估\">性能评估</h3>\n<h3 id=\"展望\">展望</h3>\n"},{"title":"jce问题","_content":"##简介\n\nnifi是一个开箱即可用的软件，但是如果要在生成环境中使用，就需要对nifi进行相应的配置。在上一篇文章中，提到nifi同时支持单机和集群部署，本文将分别介绍2中模式下该如何配置和部署nifi(nifi-1.3.0)。nifi的配置文件都位于目录\n\n##standalone\n\n\n\n##cluster","source":"_drafts/jce问题.md","raw":"---\ntitle: jce问题\ntags:\n---\n##简介\n\nnifi是一个开箱即可用的软件，但是如果要在生成环境中使用，就需要对nifi进行相应的配置。在上一篇文章中，提到nifi同时支持单机和集群部署，本文将分别介绍2中模式下该如何配置和部署nifi(nifi-1.3.0)。nifi的配置文件都位于目录\n\n##standalone\n\n\n\n##cluster","slug":"jce问题","published":0,"date":"2017-09-28T10:52:58.725Z","updated":"2017-09-28T10:52:58.725Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8cgqo7u000o3szyd2j7ee77","content":"<h2 id=\"简介\">简介</h2>\n<p>nifi是一个开箱即可用的软件，但是如果要在生成环境中使用，就需要对nifi进行相应的配置。在上一篇文章中，提到nifi同时支持单机和集群部署，本文将分别介绍2中模式下该如何配置和部署nifi(nifi-1.3.0)。nifi的配置文件都位于目录</p>\n<h2 id=\"standalone\">standalone</h2>\n<h2 id=\"cluster\">cluster</h2>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"简介\">简介</h2>\n<p>nifi是一个开箱即可用的软件，但是如果要在生成环境中使用，就需要对nifi进行相应的配置。在上一篇文章中，提到nifi同时支持单机和集群部署，本文将分别介绍2中模式下该如何配置和部署nifi(nifi-1.3.0)。nifi的配置文件都位于目录</p>\n<h2 id=\"standalone\">standalone</h2>\n<h2 id=\"cluster\">cluster</h2>\n"},{"title":"kibana timestamp问题","date":"2017-05-27T09:05:47.000Z","_content":"\n##1.问题描述\n\nnifi产生的日志通过nifi处理器写入到elasticsearch中，然后在kibana中查找，发现时间总是对不上，按照网上的方案改写了kibana的tz参数为UTC，时间对了，但是最近的15分钟等操作是不对的\n\n##2.解决方案\n指导思想：存储数据和显示数据分离\n在写入elasticsearch之前对nifi采用logback产生的日志做一个jolt，为timestamp加一个 +08:00\n","source":"_drafts/kibana-timestamp问题.md","raw":"---\ntitle: kibana timestamp问题\ndate: 2017-05-27 17:05:47\ntags: 笔记\ncategories: ELK\n---\n\n##1.问题描述\n\nnifi产生的日志通过nifi处理器写入到elasticsearch中，然后在kibana中查找，发现时间总是对不上，按照网上的方案改写了kibana的tz参数为UTC，时间对了，但是最近的15分钟等操作是不对的\n\n##2.解决方案\n指导思想：存储数据和显示数据分离\n在写入elasticsearch之前对nifi采用logback产生的日志做一个jolt，为timestamp加一个 +08:00\n","slug":"kibana-timestamp问题","published":0,"updated":"2017-09-28T10:52:58.723Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8cgqo7v000q3szy5q8ifxwo","content":"<h2 id=\"问题描述\">1.问题描述</h2>\n<p>nifi产生的日志通过nifi处理器写入到elasticsearch中，然后在kibana中查找，发现时间总是对不上，按照网上的方案改写了kibana的tz参数为UTC，时间对了，但是最近的15分钟等操作是不对的</p>\n<h2 id=\"解决方案\">2.解决方案</h2>\n<p>指导思想：存储数据和显示数据分离 在写入elasticsearch之前对nifi采用logback产生的日志做一个jolt，为timestamp加一个 +08:00</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"问题描述\">1.问题描述</h2>\n<p>nifi产生的日志通过nifi处理器写入到elasticsearch中，然后在kibana中查找，发现时间总是对不上，按照网上的方案改写了kibana的tz参数为UTC，时间对了，但是最近的15分钟等操作是不对的</p>\n<h2 id=\"解决方案\">2.解决方案</h2>\n<p>指导思想：存储数据和显示数据分离 在写入elasticsearch之前对nifi采用logback产生的日志做一个jolt，为timestamp加一个 +08:00</p>\n"},{"title":"maxwell同步binlog","_content":"","source":"_drafts/maxwell同步binlog.md","raw":"---\ntitle: maxwell同步binlog\ntags:\n---\n","slug":"maxwell同步binlog","published":0,"date":"2017-09-28T10:52:58.725Z","updated":"2017-09-28T10:52:58.725Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8cgqo7x000t3szy30u0he1v","content":"\n","site":{"data":{}},"excerpt":"","more":"\n"},{"title":"nifi部署","_content":"","source":"_drafts/nifi部署.md","raw":"---\ntitle: nifi部署\ntags:\n---\n","slug":"nifi部署","published":0,"date":"2017-09-28T10:52:58.724Z","updated":"2017-09-28T10:52:58.724Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8cgqo7y000w3szy82mf93oa","content":"\n","site":{"data":{}},"excerpt":"","more":"\n"},{"title":"superset简介","_content":"","source":"_drafts/superset简介.md","raw":"---\ntitle: superset简介\ntags:\n---\n","slug":"superset简介","published":0,"date":"2017-09-28T10:52:58.723Z","updated":"2017-09-28T10:52:58.723Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8cgqo7z00103szyeecrd4lb","content":"\n","site":{"data":{}},"excerpt":"","more":"\n"},{"title":"复杂网络简介","_content":"\n\n###复杂网络(network,graph)是什么\n###基本指标\n* 度\n###社区发现\n###应用\n","source":"_drafts/复杂网络简介.md","raw":"---\ntitle: 复杂网络简介\ntags:\n---\n\n\n###复杂网络(network,graph)是什么\n###基本指标\n* 度\n###社区发现\n###应用\n","slug":"复杂网络简介","published":0,"date":"2017-09-28T10:52:58.724Z","updated":"2017-09-28T10:52:58.724Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8cgqo8000123szy8f805fbu","content":"<h3 id=\"复杂网络networkgraph是什么\">复杂网络(network,graph)是什么</h3>\n<h3 id=\"基本指标\">基本指标</h3>\n<ul>\n<li>度 ###社区发现 ###应用</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"复杂网络networkgraph是什么\">复杂网络(network,graph)是什么</h3>\n<h3 id=\"基本指标\">基本指标</h3>\n<ul>\n<li>度 ###社区发现 ###应用</li>\n</ul>\n"},{"title":"ElasticSearch","date":"2020-03-29T03:03:31.000Z","_content":"\n## 倒排\n\n## Lucene\n## 分布式\n## Elasticsearch\n","source":"_posts/ElasticSearch.md","raw":"---\ntitle: ElasticSearch\ndate: 2020-03-29 11:03:31\ntags:\n---\n\n## 倒排\n\n## Lucene\n## 分布式\n## Elasticsearch\n","slug":"ElasticSearch","published":1,"updated":"2020-03-29T03:06:02.353Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8cgqo8100133szy80iw075r","content":"<h2 id=\"倒排\">倒排</h2>\n<h2 id=\"lucene\">Lucene</h2>\n<h2 id=\"分布式\">分布式</h2>\n<h2 id=\"elasticsearch\">Elasticsearch</h2>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"倒排\">倒排</h2>\n<h2 id=\"lucene\">Lucene</h2>\n<h2 id=\"分布式\">分布式</h2>\n<h2 id=\"elasticsearch\">Elasticsearch</h2>\n"},{"title":"tf-idf 计算查询语句和文档的相关性","date":"2017-04-20T09:17:46.000Z","_content":"## 1. 背景\n\n### 1.1 搜索检索问题\n\n在互联网中，用户越来越多的依赖通过搜索关键词来获得想要的相关内容，如何快速准确为用户提供相应的结果成为一个重要的课题\n\n用户的搜索行为通常可以简化为从一个数据集合中查询一个子集的过程，举个栗子：首先限制数据集合为英文集合（主要是英文分词比较好办，中文等一些语言还需要设计到分词的算法），然后从这些英文集合中搜索一些英文文档，将问题简化一下就是计算“查询的英文文档”和全部的“英文数据集合”中各个文档的相关性\n\n接下来我们用更加具体化的方式来说明一下这个问题，首先我们有一个文档数据集合$D$，用户的搜索语句为$q=w_1,w_2,...,w_n$,其中$w_i$代表具体的单词，接下来我们期望给用户返回一个数据$D$的子集 $D^*$，对于任何一个 $d \\in D^*$，最大化概率 $$P(d|q,D)$$ 上面的思想是通过引入概率和统计的方式计算出具体的数值，同时还有一些基于向量的方案来优化检索的过程\n\n### 1.2 Ad-Hoc检索算法\n\n在介绍TF—IDF算法之前我们先来探讨一些已有的模型，首先是如同上面提出的基于统计的最直接的方法，这种方法受欢迎并有效，比如（Berger & Lafferty, 1999)提出检索时结合用户的偏好概率框架从而提高查询结果的匹配度的。该模型假设用户有一个确定需求信息$G$，而这个需求信息可以近似的由一系列的单词组合$q$代表，通过近似的将$G$转换为$q$并将贝叶斯公式带入公式（1）中，在给定语句$q$的情况下返回合适的文档情景中该模型能够得到比较好的结果。\n\n利用基于向量的模型来处理检索问题也能够获得好的结果，(Berry, Dumais & OíBrien, 1994)提出通过LSI（潜在语义检索）矩阵来处理查询检索，本质上，该算法是创建了一个降维过的向量空间来获得文档的$n$维空间表达式。当查询的发生的时候通过计算查询向量和文档集合中的其他文档向量的余弦相似度，然后返回那些相似度比较大的文档。文章作者的实验结果显示该算法在查询检索中性能非常好，甚至能够应用在夸语言的文档查询检索(Littman & Keim 1997)。如果某些条件得到满足（在特定的场景下），他们认为LSI能够扩展应用到2种语言以上。\n\n我们接下来我们要详细的测试的算法是词频逆词频（TF-IDF），这种基于权重的模式可以认为是统计方式的一种，尽管事实上他的结果是确定的。词频逆词频是一个相当古老的权重模式，简单有效的特点使得他在众多方法中更加受欢迎（Salton & Buckley, 1988），在本文中我们通过the LDCís United Nations Parallel Text Corpus.英语文档集合来测试TF-IDF算法，探究该算法的优缺点作为未来算法的一个起点\n\n## 2. TF-IDF概述\n\n现在我们来看一下TF-IDF的结构和实现。首先我们将介绍算法的数学背景，并检查其相对于每个变量的行为。 然后提供实现的算法。\n\n### 2.1 数学框架\n\n在进行之前，我们将对TF-IDF进行快速非正式的解释。本质上，TF-IDF通过确定特定文档中的单词的相对频率与该单词在整个文档语料库中的反比例相比较起作用。 直观地，该计算确定给定单词在特定文档中的相关性。 在一个单一或一小组文件中不常见的单词往往比普通单词（如冠词和介词）具有更高的TF-IDF值。不同的情景下实现的TF-IDF有一些微小不同的地方，但是总体上计算的方式如下。给定一个稳定集合$D$，一个单词 $w$ 和一个文档 $d \\in D$,我们计算$$\\mathcal{W}_d=f_{w,d}*log(\\frac{|D|}{f_{w,D}})$$其中 $f_{w,d}$ 等于词 $w$ 在文档 $d$ 中出现的次数，$|D|$是文档全集的大小, $f_{w,D}$ 是词 $w$ 在全集中出现的次数(Salton & Buckley, 1988, Berger, et al, 2000)。根据$f_{w,d}$，$|D|$和$f_{w,D}$，每个单词都会出现不同的情况，这些正是我们接下来主要测试的地方。\n假设$|D|\\thicksim f_{w,d}$,即语料库的大小大接近于$w$在集合$D$的频率，对于一些非常小的常数$c$，满足$1 < log(\\frac{|D|}{f_{w,D}}) < c$, 那么$w$将会比$f_{w,d}$小但是仍然是正的,这意味着$w$在整个语料库中比较常见，但在整个$D$句中仍然保持一定的重要性，例如TF-IDF在《新约》中的测试“Jesus”，就会是这种情况，与我们更加相关的例子在联合国文档的语料中“united”的结果可以预期到也是这种情况。对于非常常见的词语也是如此，例如冠词，代词和介词，它们本身在查询中没有任何相关的含义（除非用户明确要求含有这样的常用单词的文档）。 因此，这样的常用词得到非常低的TF-IDF分数，使得它们在搜索中基本上可以忽略不计。\n最后，我们假设$f_{w,d}$非常大，$f_{w,D}$很小，那么$log(\\frac{|D|}{f_{w,D}})$将会变得相当大，所以$w_d$同样会很大，这个使我们感兴趣的情况，因为具有高$w_d$的词意味着$w$是$d$中的重要词，而在$D$中不常见。这个词被认为具有很大的有辨识力的,所以当查询包含单词$w$，返回的高$w_d$文档$d$很大可能满足用户。\n\n### 2.2 为TF-IDF编码\n\nTF-IDF的代码很简单，给定一个由单词$w_i$集合组合成的查询$q$，对每个文档$d\\in D$，计算每个单词$w_i$的$w_{i,d}$。最简单的方法是通过遍历文档集合并求和$f_{w,d}$和$f_{w,D}$。一旦完成，我们可以很容易地根据前面提到的数学框架计算$w_{i,d}$。 一旦找到所有$w_{i,d}$，我们返回一个包含满足最大化以下等式文档 $d$ 的集合$D^*$：$$\\sum_i{w_{i,d}}（3）$$无论是用户还是系统都可以预先设定查询返回的文档集合$D^*$的任意大小，并根据等式（3）以递减的顺序返回文档。\n这是实现TF-IDF的传统方法。 我们将在后面的部分讨论该算法的扩展，以及根据我们自己的结果分析TF-IDF。\n\n## 3. 实验\n\n### 3.1 数据搜集和规则化\n\n我们从《 LDC‘s United Nations Parallel Text Corpus》语料集合上搜集了1400文件，对TF-IDF进行测试，这些文件是从联合国1988年数据库的大量文件中任意收集的。这些文件是用SGML文本格式编码的，为了测试TF-IDF的鲁棒性，我们决定留下格式化标签导致的嘈杂的数据，并且强制区分大小写加大噪声。由于某些限制，我们不得不将用于执行信息检索的查询数量限制为86。我们根据计算公式3来计算这些查询的TF-IDF值，然后返回最大化（3）公式的前100个文档，这些文档根据权重的大小依次递减排序，为了对比我们的结果，我们同时测试暴力的方法（更加的朴素）\n\n### 3.2 实验结果\n\n## 4. 结论 \n\n## 参考文档\n\n[1]: 1231","source":"_posts/tf-idf-计算查询语句和文档的相关性.md","raw":"---\ntitle: tf-idf 计算查询语句和文档的相关性\ndate: 2017-04-20 17:17:46\ntags: 翻译\ncategories: 算法\n---\n## 1. 背景\n\n### 1.1 搜索检索问题\n\n在互联网中，用户越来越多的依赖通过搜索关键词来获得想要的相关内容，如何快速准确为用户提供相应的结果成为一个重要的课题\n\n用户的搜索行为通常可以简化为从一个数据集合中查询一个子集的过程，举个栗子：首先限制数据集合为英文集合（主要是英文分词比较好办，中文等一些语言还需要设计到分词的算法），然后从这些英文集合中搜索一些英文文档，将问题简化一下就是计算“查询的英文文档”和全部的“英文数据集合”中各个文档的相关性\n\n接下来我们用更加具体化的方式来说明一下这个问题，首先我们有一个文档数据集合$D$，用户的搜索语句为$q=w_1,w_2,...,w_n$,其中$w_i$代表具体的单词，接下来我们期望给用户返回一个数据$D$的子集 $D^*$，对于任何一个 $d \\in D^*$，最大化概率 $$P(d|q,D)$$ 上面的思想是通过引入概率和统计的方式计算出具体的数值，同时还有一些基于向量的方案来优化检索的过程\n\n### 1.2 Ad-Hoc检索算法\n\n在介绍TF—IDF算法之前我们先来探讨一些已有的模型，首先是如同上面提出的基于统计的最直接的方法，这种方法受欢迎并有效，比如（Berger & Lafferty, 1999)提出检索时结合用户的偏好概率框架从而提高查询结果的匹配度的。该模型假设用户有一个确定需求信息$G$，而这个需求信息可以近似的由一系列的单词组合$q$代表，通过近似的将$G$转换为$q$并将贝叶斯公式带入公式（1）中，在给定语句$q$的情况下返回合适的文档情景中该模型能够得到比较好的结果。\n\n利用基于向量的模型来处理检索问题也能够获得好的结果，(Berry, Dumais & OíBrien, 1994)提出通过LSI（潜在语义检索）矩阵来处理查询检索，本质上，该算法是创建了一个降维过的向量空间来获得文档的$n$维空间表达式。当查询的发生的时候通过计算查询向量和文档集合中的其他文档向量的余弦相似度，然后返回那些相似度比较大的文档。文章作者的实验结果显示该算法在查询检索中性能非常好，甚至能够应用在夸语言的文档查询检索(Littman & Keim 1997)。如果某些条件得到满足（在特定的场景下），他们认为LSI能够扩展应用到2种语言以上。\n\n我们接下来我们要详细的测试的算法是词频逆词频（TF-IDF），这种基于权重的模式可以认为是统计方式的一种，尽管事实上他的结果是确定的。词频逆词频是一个相当古老的权重模式，简单有效的特点使得他在众多方法中更加受欢迎（Salton & Buckley, 1988），在本文中我们通过the LDCís United Nations Parallel Text Corpus.英语文档集合来测试TF-IDF算法，探究该算法的优缺点作为未来算法的一个起点\n\n## 2. TF-IDF概述\n\n现在我们来看一下TF-IDF的结构和实现。首先我们将介绍算法的数学背景，并检查其相对于每个变量的行为。 然后提供实现的算法。\n\n### 2.1 数学框架\n\n在进行之前，我们将对TF-IDF进行快速非正式的解释。本质上，TF-IDF通过确定特定文档中的单词的相对频率与该单词在整个文档语料库中的反比例相比较起作用。 直观地，该计算确定给定单词在特定文档中的相关性。 在一个单一或一小组文件中不常见的单词往往比普通单词（如冠词和介词）具有更高的TF-IDF值。不同的情景下实现的TF-IDF有一些微小不同的地方，但是总体上计算的方式如下。给定一个稳定集合$D$，一个单词 $w$ 和一个文档 $d \\in D$,我们计算$$\\mathcal{W}_d=f_{w,d}*log(\\frac{|D|}{f_{w,D}})$$其中 $f_{w,d}$ 等于词 $w$ 在文档 $d$ 中出现的次数，$|D|$是文档全集的大小, $f_{w,D}$ 是词 $w$ 在全集中出现的次数(Salton & Buckley, 1988, Berger, et al, 2000)。根据$f_{w,d}$，$|D|$和$f_{w,D}$，每个单词都会出现不同的情况，这些正是我们接下来主要测试的地方。\n假设$|D|\\thicksim f_{w,d}$,即语料库的大小大接近于$w$在集合$D$的频率，对于一些非常小的常数$c$，满足$1 < log(\\frac{|D|}{f_{w,D}}) < c$, 那么$w$将会比$f_{w,d}$小但是仍然是正的,这意味着$w$在整个语料库中比较常见，但在整个$D$句中仍然保持一定的重要性，例如TF-IDF在《新约》中的测试“Jesus”，就会是这种情况，与我们更加相关的例子在联合国文档的语料中“united”的结果可以预期到也是这种情况。对于非常常见的词语也是如此，例如冠词，代词和介词，它们本身在查询中没有任何相关的含义（除非用户明确要求含有这样的常用单词的文档）。 因此，这样的常用词得到非常低的TF-IDF分数，使得它们在搜索中基本上可以忽略不计。\n最后，我们假设$f_{w,d}$非常大，$f_{w,D}$很小，那么$log(\\frac{|D|}{f_{w,D}})$将会变得相当大，所以$w_d$同样会很大，这个使我们感兴趣的情况，因为具有高$w_d$的词意味着$w$是$d$中的重要词，而在$D$中不常见。这个词被认为具有很大的有辨识力的,所以当查询包含单词$w$，返回的高$w_d$文档$d$很大可能满足用户。\n\n### 2.2 为TF-IDF编码\n\nTF-IDF的代码很简单，给定一个由单词$w_i$集合组合成的查询$q$，对每个文档$d\\in D$，计算每个单词$w_i$的$w_{i,d}$。最简单的方法是通过遍历文档集合并求和$f_{w,d}$和$f_{w,D}$。一旦完成，我们可以很容易地根据前面提到的数学框架计算$w_{i,d}$。 一旦找到所有$w_{i,d}$，我们返回一个包含满足最大化以下等式文档 $d$ 的集合$D^*$：$$\\sum_i{w_{i,d}}（3）$$无论是用户还是系统都可以预先设定查询返回的文档集合$D^*$的任意大小，并根据等式（3）以递减的顺序返回文档。\n这是实现TF-IDF的传统方法。 我们将在后面的部分讨论该算法的扩展，以及根据我们自己的结果分析TF-IDF。\n\n## 3. 实验\n\n### 3.1 数据搜集和规则化\n\n我们从《 LDC‘s United Nations Parallel Text Corpus》语料集合上搜集了1400文件，对TF-IDF进行测试，这些文件是从联合国1988年数据库的大量文件中任意收集的。这些文件是用SGML文本格式编码的，为了测试TF-IDF的鲁棒性，我们决定留下格式化标签导致的嘈杂的数据，并且强制区分大小写加大噪声。由于某些限制，我们不得不将用于执行信息检索的查询数量限制为86。我们根据计算公式3来计算这些查询的TF-IDF值，然后返回最大化（3）公式的前100个文档，这些文档根据权重的大小依次递减排序，为了对比我们的结果，我们同时测试暴力的方法（更加的朴素）\n\n### 3.2 实验结果\n\n## 4. 结论 \n\n## 参考文档\n\n[1]: 1231","slug":"tf-idf-计算查询语句和文档的相关性","published":1,"updated":"2017-09-28T10:52:58.658Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8cgqo8200153szyac6fb6lq","content":"<h2 id=\"背景\">1. 背景</h2>\n<h3 id=\"搜索检索问题\">1.1 搜索检索问题</h3>\n<p>在互联网中，用户越来越多的依赖通过搜索关键词来获得想要的相关内容，如何快速准确为用户提供相应的结果成为一个重要的课题</p>\n<p>用户的搜索行为通常可以简化为从一个数据集合中查询一个子集的过程，举个栗子：首先限制数据集合为英文集合（主要是英文分词比较好办，中文等一些语言还需要设计到分词的算法），然后从这些英文集合中搜索一些英文文档，将问题简化一下就是计算“查询的英文文档”和全部的“英文数据集合”中各个文档的相关性</p>\n<p>接下来我们用更加具体化的方式来说明一下这个问题，首先我们有一个文档数据集合<span class=\"math inline\">\\(D\\)</span>，用户的搜索语句为<span class=\"math inline\">\\(q=w_1,w_2,...,w_n\\)</span>,其中<span class=\"math inline\">\\(w_i\\)</span>代表具体的单词，接下来我们期望给用户返回一个数据<span class=\"math inline\">\\(D\\)</span>的子集 <span class=\"math inline\">\\(D^*\\)</span>，对于任何一个 <span class=\"math inline\">\\(d \\in D^*\\)</span>，最大化概率 <span class=\"math display\">\\[P(d|q,D)\\]</span> 上面的思想是通过引入概率和统计的方式计算出具体的数值，同时还有一些基于向量的方案来优化检索的过程</p>\n<h3 id=\"ad-hoc检索算法\">1.2 Ad-Hoc检索算法</h3>\n<p>在介绍TF—IDF算法之前我们先来探讨一些已有的模型，首先是如同上面提出的基于统计的最直接的方法，这种方法受欢迎并有效，比如（Berger &amp; Lafferty, 1999)提出检索时结合用户的偏好概率框架从而提高查询结果的匹配度的。该模型假设用户有一个确定需求信息<span class=\"math inline\">\\(G\\)</span>，而这个需求信息可以近似的由一系列的单词组合<span class=\"math inline\">\\(q\\)</span>代表，通过近似的将<span class=\"math inline\">\\(G\\)</span>转换为<span class=\"math inline\">\\(q\\)</span>并将贝叶斯公式带入公式（1）中，在给定语句<span class=\"math inline\">\\(q\\)</span>的情况下返回合适的文档情景中该模型能够得到比较好的结果。</p>\n<p>利用基于向量的模型来处理检索问题也能够获得好的结果，(Berry, Dumais &amp; OíBrien, 1994)提出通过LSI（潜在语义检索）矩阵来处理查询检索，本质上，该算法是创建了一个降维过的向量空间来获得文档的<span class=\"math inline\">\\(n\\)</span>维空间表达式。当查询的发生的时候通过计算查询向量和文档集合中的其他文档向量的余弦相似度，然后返回那些相似度比较大的文档。文章作者的实验结果显示该算法在查询检索中性能非常好，甚至能够应用在夸语言的文档查询检索(Littman &amp; Keim 1997)。如果某些条件得到满足（在特定的场景下），他们认为LSI能够扩展应用到2种语言以上。</p>\n<p>我们接下来我们要详细的测试的算法是词频逆词频（TF-IDF），这种基于权重的模式可以认为是统计方式的一种，尽管事实上他的结果是确定的。词频逆词频是一个相当古老的权重模式，简单有效的特点使得他在众多方法中更加受欢迎（Salton &amp; Buckley, 1988），在本文中我们通过the LDCís United Nations Parallel Text Corpus.英语文档集合来测试TF-IDF算法，探究该算法的优缺点作为未来算法的一个起点</p>\n<h2 id=\"tf-idf概述\">2. TF-IDF概述</h2>\n<p>现在我们来看一下TF-IDF的结构和实现。首先我们将介绍算法的数学背景，并检查其相对于每个变量的行为。 然后提供实现的算法。</p>\n<h3 id=\"数学框架\">2.1 数学框架</h3>\n<p>在进行之前，我们将对TF-IDF进行快速非正式的解释。本质上，TF-IDF通过确定特定文档中的单词的相对频率与该单词在整个文档语料库中的反比例相比较起作用。 直观地，该计算确定给定单词在特定文档中的相关性。 在一个单一或一小组文件中不常见的单词往往比普通单词（如冠词和介词）具有更高的TF-IDF值。不同的情景下实现的TF-IDF有一些微小不同的地方，但是总体上计算的方式如下。给定一个稳定集合<span class=\"math inline\">\\(D\\)</span>，一个单词 <span class=\"math inline\">\\(w\\)</span> 和一个文档 <span class=\"math inline\">\\(d \\in D\\)</span>,我们计算<span class=\"math display\">\\[\\mathcal{W}_d=f_{w,d}*log(\\frac{|D|}{f_{w,D}})\\]</span>其中 <span class=\"math inline\">\\(f_{w,d}\\)</span> 等于词 <span class=\"math inline\">\\(w\\)</span> 在文档 <span class=\"math inline\">\\(d\\)</span> 中出现的次数，<span class=\"math inline\">\\(|D|\\)</span>是文档全集的大小, <span class=\"math inline\">\\(f_{w,D}\\)</span> 是词 <span class=\"math inline\">\\(w\\)</span> 在全集中出现的次数(Salton &amp; Buckley, 1988, Berger, et al, 2000)。根据<span class=\"math inline\">\\(f_{w,d}\\)</span>，<span class=\"math inline\">\\(|D|\\)</span>和<span class=\"math inline\">\\(f_{w,D}\\)</span>，每个单词都会出现不同的情况，这些正是我们接下来主要测试的地方。 假设<span class=\"math inline\">\\(|D|\\thicksim f_{w,d}\\)</span>,即语料库的大小大接近于<span class=\"math inline\">\\(w\\)</span>在集合<span class=\"math inline\">\\(D\\)</span>的频率，对于一些非常小的常数<span class=\"math inline\">\\(c\\)</span>，满足<span class=\"math inline\">\\(1 &lt; log(\\frac{|D|}{f_{w,D}}) &lt; c\\)</span>, 那么<span class=\"math inline\">\\(w\\)</span>将会比<span class=\"math inline\">\\(f_{w,d}\\)</span>小但是仍然是正的,这意味着<span class=\"math inline\">\\(w\\)</span>在整个语料库中比较常见，但在整个<span class=\"math inline\">\\(D\\)</span>句中仍然保持一定的重要性，例如TF-IDF在《新约》中的测试“Jesus”，就会是这种情况，与我们更加相关的例子在联合国文档的语料中“united”的结果可以预期到也是这种情况。对于非常常见的词语也是如此，例如冠词，代词和介词，它们本身在查询中没有任何相关的含义（除非用户明确要求含有这样的常用单词的文档）。 因此，这样的常用词得到非常低的TF-IDF分数，使得它们在搜索中基本上可以忽略不计。 最后，我们假设<span class=\"math inline\">\\(f_{w,d}\\)</span>非常大，<span class=\"math inline\">\\(f_{w,D}\\)</span>很小，那么<span class=\"math inline\">\\(log(\\frac{|D|}{f_{w,D}})\\)</span>将会变得相当大，所以<span class=\"math inline\">\\(w_d\\)</span>同样会很大，这个使我们感兴趣的情况，因为具有高<span class=\"math inline\">\\(w_d\\)</span>的词意味着<span class=\"math inline\">\\(w\\)</span>是<span class=\"math inline\">\\(d\\)</span>中的重要词，而在<span class=\"math inline\">\\(D\\)</span>中不常见。这个词被认为具有很大的有辨识力的,所以当查询包含单词<span class=\"math inline\">\\(w\\)</span>，返回的高<span class=\"math inline\">\\(w_d\\)</span>文档<span class=\"math inline\">\\(d\\)</span>很大可能满足用户。</p>\n<h3 id=\"为tf-idf编码\">2.2 为TF-IDF编码</h3>\n<p>TF-IDF的代码很简单，给定一个由单词<span class=\"math inline\">\\(w_i\\)</span>集合组合成的查询<span class=\"math inline\">\\(q\\)</span>，对每个文档<span class=\"math inline\">\\(d\\in D\\)</span>，计算每个单词<span class=\"math inline\">\\(w_i\\)</span>的<span class=\"math inline\">\\(w_{i,d}\\)</span>。最简单的方法是通过遍历文档集合并求和<span class=\"math inline\">\\(f_{w,d}\\)</span>和<span class=\"math inline\">\\(f_{w,D}\\)</span>。一旦完成，我们可以很容易地根据前面提到的数学框架计算<span class=\"math inline\">\\(w_{i,d}\\)</span>。 一旦找到所有<span class=\"math inline\">\\(w_{i,d}\\)</span>，我们返回一个包含满足最大化以下等式文档 <span class=\"math inline\">\\(d\\)</span> 的集合<span class=\"math inline\">\\(D^*\\)</span>：<span class=\"math display\">\\[\\sum_i{w_{i,d}}（3）\\]</span>无论是用户还是系统都可以预先设定查询返回的文档集合<span class=\"math inline\">\\(D^*\\)</span>的任意大小，并根据等式（3）以递减的顺序返回文档。 这是实现TF-IDF的传统方法。 我们将在后面的部分讨论该算法的扩展，以及根据我们自己的结果分析TF-IDF。</p>\n<h2 id=\"实验\">3. 实验</h2>\n<h3 id=\"数据搜集和规则化\">3.1 数据搜集和规则化</h3>\n<p>我们从《 LDC‘s United Nations Parallel Text Corpus》语料集合上搜集了1400文件，对TF-IDF进行测试，这些文件是从联合国1988年数据库的大量文件中任意收集的。这些文件是用SGML文本格式编码的，为了测试TF-IDF的鲁棒性，我们决定留下格式化标签导致的嘈杂的数据，并且强制区分大小写加大噪声。由于某些限制，我们不得不将用于执行信息检索的查询数量限制为86。我们根据计算公式3来计算这些查询的TF-IDF值，然后返回最大化（3）公式的前100个文档，这些文档根据权重的大小依次递减排序，为了对比我们的结果，我们同时测试暴力的方法（更加的朴素）</p>\n<h3 id=\"实验结果\">3.2 实验结果</h3>\n<h2 id=\"结论\">4. 结论</h2>\n<h2 id=\"参考文档\">参考文档</h2>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"背景\">1. 背景</h2>\n<h3 id=\"搜索检索问题\">1.1 搜索检索问题</h3>\n<p>在互联网中，用户越来越多的依赖通过搜索关键词来获得想要的相关内容，如何快速准确为用户提供相应的结果成为一个重要的课题</p>\n<p>用户的搜索行为通常可以简化为从一个数据集合中查询一个子集的过程，举个栗子：首先限制数据集合为英文集合（主要是英文分词比较好办，中文等一些语言还需要设计到分词的算法），然后从这些英文集合中搜索一些英文文档，将问题简化一下就是计算“查询的英文文档”和全部的“英文数据集合”中各个文档的相关性</p>\n<p>接下来我们用更加具体化的方式来说明一下这个问题，首先我们有一个文档数据集合<span class=\"math inline\">\\(D\\)</span>，用户的搜索语句为<span class=\"math inline\">\\(q=w_1,w_2,...,w_n\\)</span>,其中<span class=\"math inline\">\\(w_i\\)</span>代表具体的单词，接下来我们期望给用户返回一个数据<span class=\"math inline\">\\(D\\)</span>的子集 <span class=\"math inline\">\\(D^*\\)</span>，对于任何一个 <span class=\"math inline\">\\(d \\in D^*\\)</span>，最大化概率 <span class=\"math display\">\\[P(d|q,D)\\]</span> 上面的思想是通过引入概率和统计的方式计算出具体的数值，同时还有一些基于向量的方案来优化检索的过程</p>\n<h3 id=\"ad-hoc检索算法\">1.2 Ad-Hoc检索算法</h3>\n<p>在介绍TF—IDF算法之前我们先来探讨一些已有的模型，首先是如同上面提出的基于统计的最直接的方法，这种方法受欢迎并有效，比如（Berger &amp; Lafferty, 1999)提出检索时结合用户的偏好概率框架从而提高查询结果的匹配度的。该模型假设用户有一个确定需求信息<span class=\"math inline\">\\(G\\)</span>，而这个需求信息可以近似的由一系列的单词组合<span class=\"math inline\">\\(q\\)</span>代表，通过近似的将<span class=\"math inline\">\\(G\\)</span>转换为<span class=\"math inline\">\\(q\\)</span>并将贝叶斯公式带入公式（1）中，在给定语句<span class=\"math inline\">\\(q\\)</span>的情况下返回合适的文档情景中该模型能够得到比较好的结果。</p>\n<p>利用基于向量的模型来处理检索问题也能够获得好的结果，(Berry, Dumais &amp; OíBrien, 1994)提出通过LSI（潜在语义检索）矩阵来处理查询检索，本质上，该算法是创建了一个降维过的向量空间来获得文档的<span class=\"math inline\">\\(n\\)</span>维空间表达式。当查询的发生的时候通过计算查询向量和文档集合中的其他文档向量的余弦相似度，然后返回那些相似度比较大的文档。文章作者的实验结果显示该算法在查询检索中性能非常好，甚至能够应用在夸语言的文档查询检索(Littman &amp; Keim 1997)。如果某些条件得到满足（在特定的场景下），他们认为LSI能够扩展应用到2种语言以上。</p>\n<p>我们接下来我们要详细的测试的算法是词频逆词频（TF-IDF），这种基于权重的模式可以认为是统计方式的一种，尽管事实上他的结果是确定的。词频逆词频是一个相当古老的权重模式，简单有效的特点使得他在众多方法中更加受欢迎（Salton &amp; Buckley, 1988），在本文中我们通过the LDCís United Nations Parallel Text Corpus.英语文档集合来测试TF-IDF算法，探究该算法的优缺点作为未来算法的一个起点</p>\n<h2 id=\"tf-idf概述\">2. TF-IDF概述</h2>\n<p>现在我们来看一下TF-IDF的结构和实现。首先我们将介绍算法的数学背景，并检查其相对于每个变量的行为。 然后提供实现的算法。</p>\n<h3 id=\"数学框架\">2.1 数学框架</h3>\n<p>在进行之前，我们将对TF-IDF进行快速非正式的解释。本质上，TF-IDF通过确定特定文档中的单词的相对频率与该单词在整个文档语料库中的反比例相比较起作用。 直观地，该计算确定给定单词在特定文档中的相关性。 在一个单一或一小组文件中不常见的单词往往比普通单词（如冠词和介词）具有更高的TF-IDF值。不同的情景下实现的TF-IDF有一些微小不同的地方，但是总体上计算的方式如下。给定一个稳定集合<span class=\"math inline\">\\(D\\)</span>，一个单词 <span class=\"math inline\">\\(w\\)</span> 和一个文档 <span class=\"math inline\">\\(d \\in D\\)</span>,我们计算<span class=\"math display\">\\[\\mathcal{W}_d=f_{w,d}*log(\\frac{|D|}{f_{w,D}})\\]</span>其中 <span class=\"math inline\">\\(f_{w,d}\\)</span> 等于词 <span class=\"math inline\">\\(w\\)</span> 在文档 <span class=\"math inline\">\\(d\\)</span> 中出现的次数，<span class=\"math inline\">\\(|D|\\)</span>是文档全集的大小, <span class=\"math inline\">\\(f_{w,D}\\)</span> 是词 <span class=\"math inline\">\\(w\\)</span> 在全集中出现的次数(Salton &amp; Buckley, 1988, Berger, et al, 2000)。根据<span class=\"math inline\">\\(f_{w,d}\\)</span>，<span class=\"math inline\">\\(|D|\\)</span>和<span class=\"math inline\">\\(f_{w,D}\\)</span>，每个单词都会出现不同的情况，这些正是我们接下来主要测试的地方。 假设<span class=\"math inline\">\\(|D|\\thicksim f_{w,d}\\)</span>,即语料库的大小大接近于<span class=\"math inline\">\\(w\\)</span>在集合<span class=\"math inline\">\\(D\\)</span>的频率，对于一些非常小的常数<span class=\"math inline\">\\(c\\)</span>，满足<span class=\"math inline\">\\(1 &lt; log(\\frac{|D|}{f_{w,D}}) &lt; c\\)</span>, 那么<span class=\"math inline\">\\(w\\)</span>将会比<span class=\"math inline\">\\(f_{w,d}\\)</span>小但是仍然是正的,这意味着<span class=\"math inline\">\\(w\\)</span>在整个语料库中比较常见，但在整个<span class=\"math inline\">\\(D\\)</span>句中仍然保持一定的重要性，例如TF-IDF在《新约》中的测试“Jesus”，就会是这种情况，与我们更加相关的例子在联合国文档的语料中“united”的结果可以预期到也是这种情况。对于非常常见的词语也是如此，例如冠词，代词和介词，它们本身在查询中没有任何相关的含义（除非用户明确要求含有这样的常用单词的文档）。 因此，这样的常用词得到非常低的TF-IDF分数，使得它们在搜索中基本上可以忽略不计。 最后，我们假设<span class=\"math inline\">\\(f_{w,d}\\)</span>非常大，<span class=\"math inline\">\\(f_{w,D}\\)</span>很小，那么<span class=\"math inline\">\\(log(\\frac{|D|}{f_{w,D}})\\)</span>将会变得相当大，所以<span class=\"math inline\">\\(w_d\\)</span>同样会很大，这个使我们感兴趣的情况，因为具有高<span class=\"math inline\">\\(w_d\\)</span>的词意味着<span class=\"math inline\">\\(w\\)</span>是<span class=\"math inline\">\\(d\\)</span>中的重要词，而在<span class=\"math inline\">\\(D\\)</span>中不常见。这个词被认为具有很大的有辨识力的,所以当查询包含单词<span class=\"math inline\">\\(w\\)</span>，返回的高<span class=\"math inline\">\\(w_d\\)</span>文档<span class=\"math inline\">\\(d\\)</span>很大可能满足用户。</p>\n<h3 id=\"为tf-idf编码\">2.2 为TF-IDF编码</h3>\n<p>TF-IDF的代码很简单，给定一个由单词<span class=\"math inline\">\\(w_i\\)</span>集合组合成的查询<span class=\"math inline\">\\(q\\)</span>，对每个文档<span class=\"math inline\">\\(d\\in D\\)</span>，计算每个单词<span class=\"math inline\">\\(w_i\\)</span>的<span class=\"math inline\">\\(w_{i,d}\\)</span>。最简单的方法是通过遍历文档集合并求和<span class=\"math inline\">\\(f_{w,d}\\)</span>和<span class=\"math inline\">\\(f_{w,D}\\)</span>。一旦完成，我们可以很容易地根据前面提到的数学框架计算<span class=\"math inline\">\\(w_{i,d}\\)</span>。 一旦找到所有<span class=\"math inline\">\\(w_{i,d}\\)</span>，我们返回一个包含满足最大化以下等式文档 <span class=\"math inline\">\\(d\\)</span> 的集合<span class=\"math inline\">\\(D^*\\)</span>：<span class=\"math display\">\\[\\sum_i{w_{i,d}}（3）\\]</span>无论是用户还是系统都可以预先设定查询返回的文档集合<span class=\"math inline\">\\(D^*\\)</span>的任意大小，并根据等式（3）以递减的顺序返回文档。 这是实现TF-IDF的传统方法。 我们将在后面的部分讨论该算法的扩展，以及根据我们自己的结果分析TF-IDF。</p>\n<h2 id=\"实验\">3. 实验</h2>\n<h3 id=\"数据搜集和规则化\">3.1 数据搜集和规则化</h3>\n<p>我们从《 LDC‘s United Nations Parallel Text Corpus》语料集合上搜集了1400文件，对TF-IDF进行测试，这些文件是从联合国1988年数据库的大量文件中任意收集的。这些文件是用SGML文本格式编码的，为了测试TF-IDF的鲁棒性，我们决定留下格式化标签导致的嘈杂的数据，并且强制区分大小写加大噪声。由于某些限制，我们不得不将用于执行信息检索的查询数量限制为86。我们根据计算公式3来计算这些查询的TF-IDF值，然后返回最大化（3）公式的前100个文档，这些文档根据权重的大小依次递减排序，为了对比我们的结果，我们同时测试暴力的方法（更加的朴素）</p>\n<h3 id=\"实验结果\">3.2 实验结果</h3>\n<h2 id=\"结论\">4. 结论</h2>\n<h2 id=\"参考文档\">参考文档</h2>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"ck8cgqo7200003szye8lnellf","category_id":"ck8cgqo7f00043szydcxbc84l","_id":"ck8cgqo7o000f3szy3et4enh8"},{"post_id":"ck8cgqo7d00023szy5jaa4ay9","category_id":"ck8cgqo7l000a3szy2pg111pj","_id":"ck8cgqo7t000l3szyhtfwgk6n"},{"post_id":"ck8cgqo7i00063szycgwh3ly9","category_id":"ck8cgqo7o000g3szy510bdt0i","_id":"ck8cgqo7w000s3szy2byfdmj0"},{"post_id":"ck8cgqo7j00083szy6suegqo8","category_id":"ck8cgqo7l000a3szy2pg111pj","_id":"ck8cgqo7z000y3szy36zohv0b"},{"post_id":"ck8cgqo7v000q3szy5q8ifxwo","category_id":"ck8cgqo7y000v3szy5nh25iaf","_id":"ck8cgqo8300163szy4mzuebol"},{"post_id":"ck8cgqo8200153szyac6fb6lq","category_id":"ck8cgqo7f00043szydcxbc84l","_id":"ck8cgqo8400183szybe3v03iq"}],"PostTag":[{"post_id":"ck8cgqo7200003szye8lnellf","tag_id":"ck8cgqo7h00053szy22z89tle","_id":"ck8cgqo7m000c3szyf09q3o2z"},{"post_id":"ck8cgqo7d00023szy5jaa4ay9","tag_id":"ck8cgqo7l000b3szy8kl5ge50","_id":"ck8cgqo7s000j3szybtwwhqcp"},{"post_id":"ck8cgqo7i00063szycgwh3ly9","tag_id":"ck8cgqo7l000b3szy8kl5ge50","_id":"ck8cgqo7v000p3szyg208hthd"},{"post_id":"ck8cgqo7j00083szy6suegqo8","tag_id":"ck8cgqo7l000b3szy8kl5ge50","_id":"ck8cgqo7x000u3szy6yd46hxy"},{"post_id":"ck8cgqo7v000q3szy5q8ifxwo","tag_id":"ck8cgqo7l000b3szy8kl5ge50","_id":"ck8cgqo7z000x3szy3642gf5w"},{"post_id":"ck8cgqo7m000d3szygne08whg","tag_id":"ck8cgqo7w000r3szy0bxphsxj","_id":"ck8cgqo8000113szy8brg2tse"},{"post_id":"ck8cgqo7s000k3szya3x6bchs","tag_id":"ck8cgqo7z000z3szydydcdcx2","_id":"ck8cgqo8200143szyfd9g0oo4"},{"post_id":"ck8cgqo8200153szyac6fb6lq","tag_id":"ck8cgqo8300173szy9ac98byw","_id":"ck8cgqo8400193szyay5y4b3n"}],"Tag":[{"name":"Lucene","_id":"ck8cgqo7h00053szy22z89tle"},{"name":"笔记","_id":"ck8cgqo7l000b3szy8kl5ge50"},{"name":"pilosa","_id":"ck8cgqo7w000r3szy0bxphsxj"},{"name":"推荐系统","_id":"ck8cgqo7z000z3szydydcdcx2"},{"name":"翻译","_id":"ck8cgqo8300173szy9ac98byw"}]}}